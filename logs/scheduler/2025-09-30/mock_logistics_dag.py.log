[2025-09-30T18:12:06.996+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:12:06.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:12:06.999+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:06.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:12:09.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:12:09.398+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:09.396+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:12:09.456+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:09.455+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:12:09.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.519 seconds
[2025-09-30T18:12:39.709+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:12:39.713+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:12:39.721+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:39.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:12:40.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:12:40.994+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:40.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:12:41.040+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:41.040+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:12:41.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.368 seconds
[2025-09-30T18:13:11.396+0000] {processor.py:157} INFO - Started process (PID=803) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:13:11.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:13:11.400+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:11.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:13:11.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:13:11.931+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:11.930+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:13:11.964+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:11.963+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:13:11.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.600 seconds
[2025-09-30T18:13:42.051+0000] {processor.py:157} INFO - Started process (PID=1110) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:13:42.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:13:42.056+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:42.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:13:42.545+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:13:42.580+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:42.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:13:42.610+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:42.610+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:13:42.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.588 seconds
[2025-09-30T18:14:12.959+0000] {processor.py:157} INFO - Started process (PID=1417) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:14:12.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:14:12.963+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:12.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:14:13.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:14:13.519+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:13.518+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:14:13.563+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:13.563+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:14:13.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.634 seconds
[2025-09-30T18:14:43.767+0000] {processor.py:157} INFO - Started process (PID=1724) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:14:43.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:14:43.770+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:43.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:14:44.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:14:44.282+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:44.282+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:14:44.312+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:44.312+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:14:44.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.572 seconds
[2025-09-30T18:15:14.633+0000] {processor.py:157} INFO - Started process (PID=2031) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:15:14.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:15:14.637+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:14.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:15:15.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:15:15.164+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:15.163+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:15:15.198+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:15.198+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:15:15.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.596 seconds
[2025-09-30T18:15:45.461+0000] {processor.py:157} INFO - Started process (PID=2338) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:15:45.463+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:15:45.464+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:45.464+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:15:46.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:15:46.048+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:46.047+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:15:46.086+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:46.086+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:15:46.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.656 seconds
[2025-09-30T18:16:16.325+0000] {processor.py:157} INFO - Started process (PID=2645) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:16:16.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:16:16.330+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:16.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:16:16.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:16:16.885+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:16.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:16:16.915+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:16.915+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:16:16.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-09-30T18:16:47.467+0000] {processor.py:157} INFO - Started process (PID=2952) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:16:47.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:16:47.469+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:47.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:16:47.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:16:47.993+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:47.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:16:48.037+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:48.037+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:16:48.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.721 seconds
[2025-09-30T18:17:18.649+0000] {processor.py:157} INFO - Started process (PID=3267) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:17:18.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:17:18.651+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:18.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:17:19.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:17:19.211+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:19.211+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:17:19.245+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:19.245+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:17:19.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.625 seconds
[2025-09-30T18:17:49.846+0000] {processor.py:157} INFO - Started process (PID=3574) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:17:49.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:17:49.849+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:49.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:17:50.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:17:50.360+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:50.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:17:50.511+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:50.511+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:17:50.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.690 seconds
[2025-09-30T18:18:20.660+0000] {processor.py:157} INFO - Started process (PID=3881) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:18:20.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:18:20.663+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:20.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:18:21.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:18:21.234+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:21.233+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:18:21.263+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:21.263+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:18:21.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.630 seconds
[2025-09-30T18:18:51.706+0000] {processor.py:157} INFO - Started process (PID=4188) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:18:51.707+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:18:51.707+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:51.707+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:18:52.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:18:52.194+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:52.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:18:52.351+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:52.351+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:18:52.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.677 seconds
[2025-09-30T18:19:22.703+0000] {processor.py:157} INFO - Started process (PID=4495) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:19:22.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:19:22.705+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:22.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:19:23.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:19:23.273+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:23.272+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:19:23.300+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:23.300+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:19:23.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.622 seconds
[2025-09-30T18:19:53.746+0000] {processor.py:157} INFO - Started process (PID=4802) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:19:53.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:19:53.748+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:53.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:19:54.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:19:54.333+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:54.332+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:19:54.363+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:54.362+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:19:54.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.641 seconds
[2025-09-30T18:20:24.822+0000] {processor.py:157} INFO - Started process (PID=5109) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:20:24.823+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:20:24.824+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:24.824+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:20:25.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:20:25.405+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:25.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:20:25.432+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:25.432+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:20:25.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.635 seconds
[2025-09-30T18:20:55.624+0000] {processor.py:157} INFO - Started process (PID=5416) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:20:55.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:20:55.626+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:55.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:20:56.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:20:56.322+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:56.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:20:56.351+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:56.350+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:20:56.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.753 seconds
[2025-09-30T18:21:26.720+0000] {processor.py:157} INFO - Started process (PID=5723) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:21:26.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:21:26.722+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:26.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:21:27.297+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:21:27.319+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:27.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:21:27.345+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:27.345+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:21:27.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.654 seconds
[2025-09-30T18:21:57.610+0000] {processor.py:157} INFO - Started process (PID=6045) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:21:57.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:21:57.611+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:57.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:21:58.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:21:58.219+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:58.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:21:58.254+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:58.254+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:21:58.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.669 seconds
[2025-09-30T18:22:28.835+0000] {processor.py:157} INFO - Started process (PID=6344) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:22:28.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:22:28.837+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:28.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:22:29.419+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:22:29.442+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:29.441+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:22:29.472+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:29.472+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:22:29.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.661 seconds
[2025-09-30T18:23:00.330+0000] {processor.py:157} INFO - Started process (PID=6651) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:23:00.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:23:00.332+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:00.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:23:00.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:23:00.972+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:00.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:23:01.000+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:01.000+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:23:01.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.695 seconds
[2025-09-30T18:23:31.305+0000] {processor.py:157} INFO - Started process (PID=6958) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:23:31.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:23:31.307+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:31.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:23:32.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:23:32.116+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:32.115+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:23:32.150+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:32.150+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:23:32.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.873 seconds
[2025-09-30T18:24:16.929+0000] {processor.py:157} INFO - Started process (PID=7272) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:24:16.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:24:16.936+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:24:16.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:24:19.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:24:19.812+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:24:19.811+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:24:20.004+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:24:20.004+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:33:39.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 3.171 seconds
[2025-09-30T18:34:10.056+0000] {processor.py:157} INFO - Started process (PID=7581) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:34:10.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:34:10.060+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:10.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:34:10.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:34:11.202+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:11.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:34:11.227+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:11.227+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:34:11.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.197 seconds
[2025-09-30T18:34:41.394+0000] {processor.py:157} INFO - Started process (PID=7896) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:34:41.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:34:41.396+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:41.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:34:41.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:34:42.021+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:42.020+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:34:42.051+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:42.051+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:34:42.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.695 seconds
[2025-09-30T18:35:12.770+0000] {processor.py:157} INFO - Started process (PID=8195) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:35:12.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:35:12.774+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:12.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:35:13.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:35:13.403+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:13.403+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:35:13.436+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:13.436+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:35:13.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.694 seconds
[2025-09-30T18:35:43.617+0000] {processor.py:157} INFO - Started process (PID=8502) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:35:43.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:35:43.621+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:43.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:35:44.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:35:44.215+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:44.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:35:44.254+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:44.254+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:35:44.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.667 seconds
[2025-09-30T18:36:14.780+0000] {processor.py:157} INFO - Started process (PID=8809) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:36:14.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:36:14.782+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:14.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:36:15.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:36:15.586+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:36:46.273+0000] {processor.py:157} INFO - Started process (PID=9116) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:36:46.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:36:46.277+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:46.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:36:46.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:36:47.202+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:47.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:36:47.230+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:47.230+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:36:47.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.985 seconds
[2025-09-30T18:37:17.839+0000] {processor.py:157} INFO - Started process (PID=9423) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:37:17.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:37:17.844+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:17.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:37:18.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:37:19.249+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:37:49.396+0000] {processor.py:157} INFO - Started process (PID=9743) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:37:49.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:37:49.398+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:49.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:37:49.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:37:50.317+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:50.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:37:50.347+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:50.346+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:37:50.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.975 seconds
[2025-09-30T18:38:20.430+0000] {processor.py:157} INFO - Started process (PID=10042) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:38:20.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:38:20.435+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:20.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:38:20.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:38:21.385+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:21.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:38:21.417+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:21.417+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:38:21.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.012 seconds
[2025-09-30T18:38:51.948+0000] {processor.py:157} INFO - Started process (PID=10357) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:38:51.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:38:51.949+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:51.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:38:52.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:38:52.450+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:52.450+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:38:52.480+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:52.480+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:38:52.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.557 seconds
[2025-09-30T18:39:22.775+0000] {processor.py:157} INFO - Started process (PID=10666) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:39:22.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:39:22.778+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:22.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:39:23.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:39:23.345+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:23.344+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:39:23.375+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:23.375+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:39:23.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.624 seconds
[2025-09-30T18:39:53.442+0000] {processor.py:157} INFO - Started process (PID=10973) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:39:53.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:39:53.444+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:53.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:39:53.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:39:54.151+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:54.151+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:39:54.188+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:54.188+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:39:54.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.774 seconds
[2025-09-30T18:40:25.266+0000] {processor.py:157} INFO - Started process (PID=11283) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:40:25.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:40:25.268+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:25.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:40:25.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:40:25.707+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:25.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:40:25.736+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:25.736+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:40:25.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.500 seconds
[2025-09-30T18:40:56.362+0000] {processor.py:157} INFO - Started process (PID=11582) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:40:56.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:40:56.364+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:56.364+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:40:56.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:40:56.916+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:56.915+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:40:56.947+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:56.946+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:40:56.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.609 seconds
[2025-09-30T18:41:27.697+0000] {processor.py:157} INFO - Started process (PID=11889) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:41:27.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:41:27.702+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:27.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:41:28.151+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:41:28.178+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:28.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:41:28.209+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:28.209+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:41:28.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.538 seconds
[2025-09-30T18:41:58.536+0000] {processor.py:157} INFO - Started process (PID=12196) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:41:58.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:41:58.541+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:58.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:41:58.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:41:59.011+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:59.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:41:59.041+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:59.041+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:41:59.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.531 seconds
[2025-09-30T18:42:29.128+0000] {processor.py:157} INFO - Started process (PID=12500) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:42:29.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:42:29.130+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:29.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:42:29.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:42:30.232+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:43:00.592+0000] {processor.py:157} INFO - Started process (PID=12807) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:43:00.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:43:00.594+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:00.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:43:01.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:43:01.077+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:01.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:43:01.115+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:01.115+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:43:01.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.670 seconds
[2025-09-30T18:43:32.072+0000] {processor.py:157} INFO - Started process (PID=13119) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:43:32.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:43:32.073+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:32.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:43:32.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:43:32.654+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:32.654+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:43:32.684+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:32.684+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:43:32.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.638 seconds
[2025-09-30T18:44:03.269+0000] {processor.py:157} INFO - Started process (PID=13426) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:44:03.271+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:44:03.272+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:03.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:44:03.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:44:04.313+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:04.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:44:04.345+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:04.345+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:44:04.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.208 seconds
[2025-09-30T18:44:34.533+0000] {processor.py:157} INFO - Started process (PID=13733) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:44:34.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:44:34.535+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:34.535+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:44:34.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:44:35.013+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:35.011+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:44:35.176+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:35.176+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:44:35.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.668 seconds
[2025-09-30T18:45:05.731+0000] {processor.py:157} INFO - Started process (PID=14040) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:45:05.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:45:05.734+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:05.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:45:06.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:45:06.337+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:06.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:45:06.364+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:06.364+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:45:06.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.657 seconds
[2025-09-30T18:45:36.821+0000] {processor.py:157} INFO - Started process (PID=14347) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:45:36.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:45:36.823+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:36.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:45:37.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:45:37.431+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:37.429+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:45:37.457+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:37.457+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:45:37.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.664 seconds
[2025-09-30T18:46:08.032+0000] {processor.py:157} INFO - Started process (PID=14654) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:46:08.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:46:08.036+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:08.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:46:08.604+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:46:09.111+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:09.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:46:09.139+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:09.139+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:46:09.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.136 seconds
[2025-09-30T18:46:39.512+0000] {processor.py:157} INFO - Started process (PID=14966) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:46:39.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:46:39.516+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:39.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:46:40.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:46:40.106+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:40.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:46:40.134+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:40.133+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:46:40.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.648 seconds
[2025-09-30T18:47:10.511+0000] {processor.py:157} INFO - Started process (PID=15271) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:47:10.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:47:10.513+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:10.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:47:11.069+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:47:11.469+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:11.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:47:11.498+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:11.498+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:47:11.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.014 seconds
[2025-09-30T18:47:42.139+0000] {processor.py:157} INFO - Started process (PID=15587) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:47:42.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:47:42.141+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:42.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:47:42.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:47:42.721+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:42.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:47:42.749+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:42.749+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:47:42.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.633 seconds
[2025-09-30T18:48:13.577+0000] {processor.py:157} INFO - Started process (PID=15894) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:48:13.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:48:13.579+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:13.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:48:14.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:48:14.145+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:14.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:48:14.171+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:14.170+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:48:14.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.618 seconds
[2025-09-30T18:48:44.813+0000] {processor.py:157} INFO - Started process (PID=16201) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:48:44.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:48:44.815+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:44.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:48:45.374+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:48:45.497+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:45.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:48:45.531+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:45.531+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:48:45.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.744 seconds
[2025-09-30T18:49:15.961+0000] {processor.py:157} INFO - Started process (PID=16508) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:49:15.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:49:15.963+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:15.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:49:16.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:49:17.691+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:17.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:49:17.719+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:17.719+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:49:17.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.784 seconds
[2025-09-30T18:49:48.625+0000] {processor.py:157} INFO - Started process (PID=16815) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:49:48.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:49:48.627+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:48.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:49:49.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:49:49.579+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:49.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:49:49.640+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:49.640+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:49:49.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.087 seconds
[2025-09-30T18:50:19.824+0000] {processor.py:157} INFO - Started process (PID=17122) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:50:19.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:50:19.827+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:19.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:50:20.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:50:20.849+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:50:51.043+0000] {processor.py:157} INFO - Started process (PID=17429) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:50:51.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:50:51.045+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:51.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:50:51.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:50:52.484+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:51:22.616+0000] {processor.py:157} INFO - Started process (PID=17736) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:51:22.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:51:22.620+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:22.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:51:23.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:51:23.456+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:23.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:51:23.483+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:23.483+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:51:23.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.891 seconds
[2025-09-30T18:51:53.711+0000] {processor.py:157} INFO - Started process (PID=18043) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:51:53.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:51:53.713+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:53.713+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:51:54.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:51:54.366+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:54.365+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:51:54.397+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:54.397+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:51:54.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.711 seconds
[2025-09-30T18:52:24.796+0000] {processor.py:157} INFO - Started process (PID=18350) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:52:24.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:52:24.798+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:24.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:52:25.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:52:25.874+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:25.873+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:52:25.907+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:25.907+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:52:25.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.141 seconds
[2025-09-30T18:52:56.529+0000] {processor.py:157} INFO - Started process (PID=18662) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:52:56.530+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:52:56.531+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:56.531+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:52:57.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:52:57.167+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:57.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:52:57.195+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:57.195+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:52:57.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.697 seconds
[2025-09-30T18:53:27.308+0000] {processor.py:157} INFO - Started process (PID=18967) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:53:27.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:53:27.311+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:27.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:53:27.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:53:27.854+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:27.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:53:27.880+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:27.880+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:53:27.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.595 seconds
[2025-09-30T18:53:58.254+0000] {processor.py:157} INFO - Started process (PID=19271) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:53:58.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:53:58.257+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:58.257+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:53:58.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:53:59.824+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:59.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:53:59.855+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:59.855+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:53:59.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.632 seconds
[2025-09-30T18:54:30.044+0000] {processor.py:157} INFO - Started process (PID=19583) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:54:30.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:54:30.046+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:30.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:54:30.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:54:31.045+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:31.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:54:31.073+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:31.073+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:54:31.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.054 seconds
[2025-09-30T18:55:01.824+0000] {processor.py:157} INFO - Started process (PID=19890) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:55:01.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:55:01.828+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:01.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:55:02.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:55:02.478+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:02.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:55:02.507+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:02.507+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:55:02.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.710 seconds
[2025-09-30T18:55:33.236+0000] {processor.py:157} INFO - Started process (PID=20197) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:55:33.238+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:55:33.240+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:33.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:55:33.806+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:55:34.492+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:34.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:55:34.520+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:34.519+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:55:34.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.308 seconds
[2025-09-30T18:56:04.720+0000] {processor.py:157} INFO - Started process (PID=20519) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:56:04.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:56:04.722+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:04.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:56:05.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:56:05.300+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:05.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:56:05.326+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:05.326+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:56:05.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.629 seconds
[2025-09-30T18:56:35.379+0000] {processor.py:157} INFO - Started process (PID=20824) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:56:35.380+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:56:35.381+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:35.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:56:35.926+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:56:36.320+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:36.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:56:36.359+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:36.358+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:56:36.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.010 seconds
[2025-09-30T18:57:06.536+0000] {processor.py:157} INFO - Started process (PID=21133) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:57:06.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:57:06.538+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:06.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:57:06.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:57:07.000+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:07.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:57:07.030+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:07.030+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:57:07.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.519 seconds
[2025-09-30T18:57:37.146+0000] {processor.py:157} INFO - Started process (PID=21438) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:57:37.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:57:37.148+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:37.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:57:37.600+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:57:38.492+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:58:08.676+0000] {processor.py:157} INFO - Started process (PID=21747) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:58:08.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:58:08.678+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:08.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:58:09.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:58:09.167+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:09.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:58:09.197+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:09.197+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:58:09.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.546 seconds
[2025-09-30T18:58:39.517+0000] {processor.py:157} INFO - Started process (PID=22054) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:58:39.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:58:39.520+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:39.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:58:40.042+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:58:41.131+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:59:11.635+0000] {processor.py:157} INFO - Started process (PID=22376) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:59:11.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:59:11.640+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:11.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:59:12.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:59:12.637+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:12.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:59:12.668+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:12.667+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:59:12.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.057 seconds
[2025-09-30T18:59:43.600+0000] {processor.py:157} INFO - Started process (PID=22715) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:59:43.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T18:59:43.602+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:43.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:59:44.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T18:59:44.080+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:44.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:59:44.111+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:44.111+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T18:59:44.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.539 seconds
[2025-09-30T19:00:14.757+0000] {processor.py:157} INFO - Started process (PID=23022) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:00:14.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:00:14.759+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:14.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:00:15.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:00:15.582+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:15.582+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:00:15.613+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:15.613+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:00:15.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.881 seconds
[2025-09-30T19:00:46.311+0000] {processor.py:157} INFO - Started process (PID=23334) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:00:46.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:00:46.313+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:46.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:00:46.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:00:46.932+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:46.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:00:46.963+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:46.963+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:00:46.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.680 seconds
[2025-09-30T19:01:17.257+0000] {processor.py:157} INFO - Started process (PID=23644) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:01:17.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:01:17.259+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:17.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:01:17.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:01:17.715+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:17.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:01:17.746+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:17.746+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:01:17.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.514 seconds
[2025-09-30T19:01:48.536+0000] {processor.py:157} INFO - Started process (PID=23953) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:01:48.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:01:48.539+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:48.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:01:48.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:01:48.998+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:48.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:01:49.030+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:49.029+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:01:49.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.521 seconds
[2025-09-30T19:02:19.547+0000] {processor.py:157} INFO - Started process (PID=24270) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:02:19.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:02:19.549+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:19.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:02:20.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:02:20.740+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:02:50.866+0000] {processor.py:157} INFO - Started process (PID=24590) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:02:50.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:02:50.868+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:50.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:02:51.300+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:02:52.148+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:03:22.316+0000] {processor.py:157} INFO - Started process (PID=24899) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:03:22.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:03:22.318+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:22.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:03:22.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:03:23.234+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:23.234+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:03:23.262+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:23.262+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:03:23.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.972 seconds
[2025-09-30T19:03:54.130+0000] {processor.py:157} INFO - Started process (PID=25211) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:03:54.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:03:54.132+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:54.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:03:54.720+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:03:56.057+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:04:26.758+0000] {processor.py:157} INFO - Started process (PID=25523) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:04:26.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:04:26.760+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:26.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:04:27.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:04:27.331+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:27.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:04:27.357+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:27.357+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:04:27.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.623 seconds
[2025-09-30T19:04:58.032+0000] {processor.py:157} INFO - Started process (PID=25830) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:04:58.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:04:58.034+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:58.034+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:04:58.584+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:04:58.607+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:58.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:04:58.635+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:58.634+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:04:58.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.628 seconds
[2025-09-30T19:05:29.020+0000] {processor.py:157} INFO - Started process (PID=26137) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:05:29.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:05:29.022+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:29.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:05:29.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:05:29.595+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:29.595+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:05:29.624+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:29.624+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:05:29.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.630 seconds
[2025-09-30T19:05:59.832+0000] {processor.py:157} INFO - Started process (PID=26444) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:05:59.833+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:05:59.834+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:59.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:06:00.447+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:06:00.471+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:00.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:06:00.498+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:00.498+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:06:00.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.691 seconds
[2025-09-30T19:06:30.867+0000] {processor.py:157} INFO - Started process (PID=26756) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:06:30.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:06:30.869+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:30.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:06:31.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:06:31.470+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:31.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:06:31.499+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:31.499+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:06:31.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.656 seconds
[2025-09-30T19:07:01.649+0000] {processor.py:157} INFO - Started process (PID=27071) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:07:01.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:07:01.651+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:01.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:07:02.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:07:02.756+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:02.756+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:07:02.783+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:02.783+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:07:02.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.157 seconds
[2025-09-30T19:07:32.927+0000] {processor.py:157} INFO - Started process (PID=27383) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:07:32.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:07:32.929+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:32.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:07:33.501+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:07:33.524+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:33.524+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:07:33.551+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:33.551+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:07:33.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.649 seconds
[2025-09-30T19:08:03.694+0000] {processor.py:157} INFO - Started process (PID=27687) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:08:03.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:08:03.696+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:03.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:08:04.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:08:04.748+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:04.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:08:04.776+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:04.776+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:08:04.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.106 seconds
[2025-09-30T19:08:35.308+0000] {processor.py:157} INFO - Started process (PID=28004) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:08:35.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:08:35.313+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:35.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:08:35.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:08:35.856+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:35.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:08:35.882+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:35.882+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:08:35.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.596 seconds
[2025-09-30T19:09:06.000+0000] {processor.py:157} INFO - Started process (PID=28311) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:09:06.001+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:09:06.002+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:06.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:09:06.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:09:06.960+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:06.960+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:09:06.988+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:06.988+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:09:07.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.011 seconds
[2025-09-30T19:09:37.266+0000] {processor.py:157} INFO - Started process (PID=28618) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:09:37.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:09:37.272+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:37.272+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:09:37.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:09:37.955+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:37.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:09:37.982+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:37.982+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:09:38.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.740 seconds
[2025-09-30T19:10:08.055+0000] {processor.py:157} INFO - Started process (PID=28925) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:10:08.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:10:08.058+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:08.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:10:08.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:10:08.632+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:08.631+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:10:08.658+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:08.658+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:10:08.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.628 seconds
[2025-09-30T19:10:38.990+0000] {processor.py:157} INFO - Started process (PID=29232) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:10:38.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:10:38.992+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:38.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:10:39.544+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:10:39.876+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:11:10.276+0000] {processor.py:157} INFO - Started process (PID=29539) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:11:10.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:11:10.278+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:10.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:11:10.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:11:11.073+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:11.073+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:11:11.100+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:11.100+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:11:11.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.848 seconds
[2025-09-30T19:11:41.454+0000] {processor.py:157} INFO - Started process (PID=29864) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:11:41.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:11:41.456+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:41.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:11:41.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:11:42.015+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:42.014+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:11:42.042+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:42.042+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:11:42.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.611 seconds
[2025-09-30T19:12:12.732+0000] {processor.py:157} INFO - Started process (PID=30168) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:12:12.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:12:12.734+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:12.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:12:13.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:12:13.319+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:13.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:12:13.347+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:13.347+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:12:13.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.641 seconds
[2025-09-30T19:12:44.260+0000] {processor.py:157} INFO - Started process (PID=30475) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:12:44.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:12:44.262+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:44.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:12:44.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:12:44.846+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:44.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:12:44.873+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:44.873+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:12:44.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.637 seconds
[2025-09-30T19:13:15.109+0000] {processor.py:157} INFO - Started process (PID=30782) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:13:15.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:13:15.111+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:15.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:13:15.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:13:15.707+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:15.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:13:15.734+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:15.734+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:13:15.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.651 seconds
[2025-09-30T19:13:45.846+0000] {processor.py:157} INFO - Started process (PID=31101) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:13:45.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:13:45.848+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:45.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:13:46.372+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:13:46.563+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:46.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:13:46.591+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:46.591+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:13:46.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.768 seconds
[2025-09-30T19:14:16.764+0000] {processor.py:157} INFO - Started process (PID=31408) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:14:16.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:14:16.766+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:16.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:14:17.303+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:14:17.914+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:17.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:14:17.940+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:17.939+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:14:17.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.200 seconds
[2025-09-30T19:14:48.237+0000] {processor.py:157} INFO - Started process (PID=31715) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:14:48.238+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:14:48.239+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:48.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:14:48.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:14:48.858+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:48.857+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:14:48.887+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:48.887+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:14:48.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.674 seconds
[2025-09-30T19:15:19.019+0000] {processor.py:157} INFO - Started process (PID=32022) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:15:19.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:15:19.022+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:19.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:15:19.463+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:15:19.489+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:19.489+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:15:19.521+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:19.520+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:15:19.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.527 seconds
[2025-09-30T19:15:49.780+0000] {processor.py:157} INFO - Started process (PID=32327) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:15:49.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:15:49.782+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:49.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:15:50.258+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:15:50.296+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:50.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:15:50.363+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:50.362+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:15:50.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.611 seconds
[2025-09-30T19:16:20.555+0000] {processor.py:157} INFO - Started process (PID=32636) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:16:20.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:16:20.557+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:20.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:16:20.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:16:21.383+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:21.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:16:21.413+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:21.413+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:16:21.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.886 seconds
[2025-09-30T19:16:51.527+0000] {processor.py:157} INFO - Started process (PID=32943) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:16:51.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:16:51.529+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:51.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:16:51.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:16:51.996+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:51.995+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:16:52.030+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:52.030+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:16:52.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.532 seconds
[2025-09-30T19:17:22.775+0000] {processor.py:157} INFO - Started process (PID=33250) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:17:22.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:17:22.778+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:22.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:17:23.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:17:23.274+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:23.273+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:17:23.306+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:23.306+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:17:23.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.557 seconds
[2025-09-30T19:17:53.835+0000] {processor.py:157} INFO - Started process (PID=33557) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:17:53.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:17:53.837+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:53.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:17:54.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:17:54.338+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:54.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:17:54.368+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:54.367+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:17:54.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.560 seconds
[2025-09-30T19:18:25.308+0000] {processor.py:157} INFO - Started process (PID=33864) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:18:25.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:18:25.310+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:25.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:18:25.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:18:26.173+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:26.172+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:18:26.204+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:26.204+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:18:26.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.924 seconds
[2025-09-30T19:18:57.162+0000] {processor.py:157} INFO - Started process (PID=34176) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:18:57.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:18:57.165+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:57.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:18:57.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:18:57.622+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:57.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:18:57.651+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:57.650+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:18:57.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.512 seconds
[2025-09-30T19:19:27.797+0000] {processor.py:157} INFO - Started process (PID=34488) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:19:27.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:19:27.799+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:27.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:19:28.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:19:28.245+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:28.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:19:28.388+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:28.388+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:19:28.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-09-30T19:19:58.595+0000] {processor.py:157} INFO - Started process (PID=34803) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:19:58.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:19:58.597+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:58.597+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:19:59.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:19:59.028+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:59.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:19:59.059+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:59.059+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:19:59.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.608 seconds
[2025-09-30T19:20:29.380+0000] {processor.py:157} INFO - Started process (PID=35102) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:20:29.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:20:29.382+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:29.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:20:29.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:20:29.947+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:29.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:20:29.972+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:29.972+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:20:29.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-09-30T19:21:00.950+0000] {processor.py:157} INFO - Started process (PID=35419) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:21:00.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:21:00.952+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:00.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:21:01.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:21:01.520+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:01.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:21:01.546+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:01.546+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:21:01.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.620 seconds
[2025-09-30T19:21:31.719+0000] {processor.py:157} INFO - Started process (PID=35724) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:21:31.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:21:31.721+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:31.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:21:32.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:21:33.575+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:22:04.364+0000] {processor.py:157} INFO - Started process (PID=36033) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:22:04.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:22:04.366+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:04.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:22:04.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:22:05.097+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:05.097+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:22:05.126+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:05.126+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:22:05.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.788 seconds
[2025-09-30T19:22:35.321+0000] {processor.py:157} INFO - Started process (PID=36340) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:22:35.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:22:35.322+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:35.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:22:35.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:22:36.157+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:36.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:22:36.184+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:36.184+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:22:36.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.888 seconds
[2025-09-30T19:23:06.635+0000] {processor.py:157} INFO - Started process (PID=36647) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:23:06.636+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:23:06.637+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:06.637+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:23:07.159+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:23:07.503+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:07.501+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:23:07.530+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:07.530+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:23:07.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.920 seconds
[2025-09-30T19:23:38.000+0000] {processor.py:157} INFO - Started process (PID=36954) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:23:38.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:23:38.003+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:38.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:23:38.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:23:38.552+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:38.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:23:38.579+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:38.579+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:23:38.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.604 seconds
[2025-09-30T19:24:08.770+0000] {processor.py:157} INFO - Started process (PID=37261) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:24:08.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:24:08.772+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:08.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:24:09.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:24:09.313+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:09.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:24:09.338+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:09.338+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:24:09.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.591 seconds
[2025-09-30T19:24:39.883+0000] {processor.py:157} INFO - Started process (PID=37568) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:24:39.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:24:39.887+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:39.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:24:40.447+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:24:40.479+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:40.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:24:40.516+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:40.516+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:24:40.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.666 seconds
[2025-09-30T19:25:11.399+0000] {processor.py:157} INFO - Started process (PID=37875) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:25:11.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:25:11.401+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:11.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:25:11.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:25:11.953+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:11.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:25:11.985+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:11.985+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:25:12.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-09-30T19:25:45.530+0000] {processor.py:157} INFO - Started process (PID=38180) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:25:45.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:25:45.533+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:45.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:25:46.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:25:46.395+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:46.394+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:25:46.449+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:46.449+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:25:46.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.962 seconds
[2025-09-30T19:26:17.253+0000] {processor.py:157} INFO - Started process (PID=38491) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:26:17.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:26:17.255+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:17.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:26:17.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:26:18.891+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:26:49.309+0000] {processor.py:157} INFO - Started process (PID=38815) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:26:49.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:26:49.311+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:49.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:26:49.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:26:50.899+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:27:20.949+0000] {processor.py:157} INFO - Started process (PID=39128) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:27:20.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:27:20.951+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:20.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:27:21.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:27:21.935+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:21.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:27:21.961+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:21.961+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:27:21.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.039 seconds
[2025-09-30T19:27:52.242+0000] {processor.py:157} INFO - Started process (PID=39417) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:27:52.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:27:52.244+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:52.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:27:52.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:27:52.811+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:52.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:27:52.837+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:52.837+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:27:52.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.619 seconds
[2025-09-30T19:28:23.997+0000] {processor.py:157} INFO - Started process (PID=39719) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:28:23.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:28:24.000+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:24.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:28:24.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:28:24.551+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:24.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:28:24.582+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:24.582+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:28:24.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.610 seconds
[2025-09-30T19:28:54.645+0000] {processor.py:157} INFO - Started process (PID=40028) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:28:54.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:28:54.648+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:54.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:28:55.536+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:28:55.570+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:55.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:28:55.615+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:55.615+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:28:55.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.004 seconds
[2025-09-30T19:29:25.831+0000] {processor.py:157} INFO - Started process (PID=40333) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:29:25.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:29:25.834+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:25.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:29:26.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:29:26.447+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:26.447+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:29:26.474+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:26.474+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:29:26.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.669 seconds
[2025-09-30T19:29:56.599+0000] {processor.py:157} INFO - Started process (PID=40635) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:29:56.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:29:56.601+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:56.601+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:29:57.109+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:29:57.576+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:57.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:29:57.601+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:57.601+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:29:57.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.025 seconds
[2025-09-30T19:30:28.125+0000] {processor.py:157} INFO - Started process (PID=40953) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:30:28.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:30:28.127+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:28.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:30:28.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:30:28.960+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:28.959+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:30:28.991+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:28.990+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:30:29.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.895 seconds
[2025-09-30T19:30:59.231+0000] {processor.py:157} INFO - Started process (PID=41253) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:30:59.232+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:30:59.233+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:59.233+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:30:59.650+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:30:59.676+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:59.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:30:59.706+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:59.705+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:30:59.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.501 seconds
[2025-09-30T19:31:30.521+0000] {processor.py:157} INFO - Started process (PID=41557) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:31:30.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:31:30.523+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:30.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:31:31.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:31:31.052+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:31.052+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:31:31.083+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:31.083+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:31:31.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.587 seconds
[2025-09-30T19:32:01.273+0000] {processor.py:157} INFO - Started process (PID=41862) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:32:01.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:32:01.275+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:01.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:32:01.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:32:01.971+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:01.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:32:02.003+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:02.003+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:32:02.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.756 seconds
[2025-09-30T19:32:32.831+0000] {processor.py:157} INFO - Started process (PID=42174) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:32:32.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:32:32.833+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:32.832+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:32:33.273+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:32:33.298+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:33.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:32:33.328+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:33.328+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:32:33.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.530 seconds
[2025-09-30T19:33:03.999+0000] {processor.py:157} INFO - Started process (PID=42486) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:33:04.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:33:04.001+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:04.001+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:33:04.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:33:04.453+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:04.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:33:04.482+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:04.481+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:33:04.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.506 seconds
[2025-09-30T19:33:34.542+0000] {processor.py:157} INFO - Started process (PID=42782) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:33:34.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:33:34.547+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:34.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:33:34.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:33:35.233+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:35.233+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:33:35.264+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:35.264+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:33:35.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.748 seconds
[2025-09-30T19:34:05.758+0000] {processor.py:157} INFO - Started process (PID=43089) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:34:05.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:34:05.761+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:05.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:34:06.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:34:06.228+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:06.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:34:06.257+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:06.256+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:34:06.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.524 seconds
[2025-09-30T19:34:36.356+0000] {processor.py:157} INFO - Started process (PID=43396) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:34:36.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:34:36.358+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:36.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:34:36.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:34:36.807+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:36.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:34:36.836+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:36.835+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:34:36.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.504 seconds
[2025-09-30T19:35:07.100+0000] {processor.py:157} INFO - Started process (PID=43703) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:35:07.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:35:07.101+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:07.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:35:07.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:35:08.361+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:35:38.723+0000] {processor.py:157} INFO - Started process (PID=44013) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:35:38.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:35:38.725+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:38.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:35:39.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:35:39.275+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:39.163+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:35:39.310+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:39.310+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:35:39.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.613 seconds
[2025-09-30T19:36:09.480+0000] {processor.py:157} INFO - Started process (PID=44322) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:36:09.481+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:36:09.482+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:09.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:36:10.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:36:10.034+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:10.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:36:10.059+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:10.059+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:36:10.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.604 seconds
[2025-09-30T19:36:40.767+0000] {processor.py:157} INFO - Started process (PID=44629) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:36:40.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:36:40.769+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:40.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:36:41.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:36:41.370+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:41.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:36:41.396+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:41.395+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:36:41.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.652 seconds
[2025-09-30T19:37:11.885+0000] {processor.py:157} INFO - Started process (PID=44944) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:37:11.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:37:11.887+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:11.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:37:12.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:37:12.456+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:12.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:37:12.483+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:12.483+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:37:12.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.624 seconds
[2025-09-30T19:37:42.710+0000] {processor.py:157} INFO - Started process (PID=45246) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:37:42.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:37:42.712+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:42.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:37:43.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:37:44.301+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:38:14.412+0000] {processor.py:157} INFO - Started process (PID=45563) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:38:14.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:38:14.414+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:14.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:38:14.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:38:15.416+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:15.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:38:15.443+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:15.443+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:38:15.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.056 seconds
[2025-09-30T19:38:45.765+0000] {processor.py:157} INFO - Started process (PID=45885) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:38:45.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:38:45.767+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:45.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:38:46.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:38:46.632+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:46.631+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:38:46.659+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:46.659+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:38:46.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.923 seconds
[2025-09-30T19:39:16.974+0000] {processor.py:157} INFO - Started process (PID=46197) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:39:16.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:39:16.976+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:16.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:39:17.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:39:17.526+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:17.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:39:17.553+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:17.553+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:39:17.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.603 seconds
[2025-09-30T19:39:47.948+0000] {processor.py:157} INFO - Started process (PID=46509) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:39:47.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:39:47.950+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:47.950+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:39:48.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:39:48.511+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:48.510+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:39:48.539+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:48.539+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:39:48.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.617 seconds
[2025-09-30T19:40:18.798+0000] {processor.py:157} INFO - Started process (PID=46816) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:40:18.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:40:18.800+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:18.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:40:19.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:40:19.398+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:19.397+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:40:19.426+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:19.426+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:40:19.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.651 seconds
[2025-09-30T19:40:50.102+0000] {processor.py:157} INFO - Started process (PID=47132) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:40:50.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:40:50.104+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:50.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:40:50.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:40:50.681+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:50.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:40:50.712+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:50.712+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:40:50.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.634 seconds
[2025-09-30T19:41:20.783+0000] {processor.py:157} INFO - Started process (PID=47427) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:41:20.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:41:20.786+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:20.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:41:21.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:41:21.746+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:21.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:41:21.786+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:21.786+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:41:21.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.031 seconds
[2025-09-30T19:41:51.868+0000] {processor.py:157} INFO - Started process (PID=47736) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:41:51.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-30T19:41:51.870+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:51.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:41:52.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-30T19:41:52.565+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:52.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:41:52.592+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:52.592+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-30T09:00:00+00:00, run_after=2025-10-01T09:00:00+00:00
[2025-09-30T19:41:52.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.748 seconds
