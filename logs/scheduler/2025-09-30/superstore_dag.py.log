[2025-09-30T18:12:09.594+0000] {processor.py:157} INFO - Started process (PID=205) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:12:09.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:12:09.603+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:09.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:12:12.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:12:13.323+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:13.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:12:13.562+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:13.562+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:12:13.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 4.115 seconds
[2025-09-30T18:12:44.484+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:12:44.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:12:44.503+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:44.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:12:47.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:12:47.486+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:47.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:12:47.649+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:47.648+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:12:47.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 3.252 seconds
[2025-09-30T18:13:18.070+0000] {processor.py:157} INFO - Started process (PID=826) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:13:18.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:13:18.072+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:18.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:13:18.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:13:18.603+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:18.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:13:18.633+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:18.633+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:13:18.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.588 seconds
[2025-09-30T18:13:48.694+0000] {processor.py:157} INFO - Started process (PID=1133) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:13:48.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:13:48.696+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:48.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:13:49.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:13:49.222+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:49.222+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:13:49.255+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:49.255+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:13:49.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.588 seconds
[2025-09-30T18:14:19.657+0000] {processor.py:157} INFO - Started process (PID=1440) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:14:19.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:14:19.661+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:19.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:14:20.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:14:20.144+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:20.143+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:14:20.173+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:20.173+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:14:20.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.544 seconds
[2025-09-30T18:14:50.403+0000] {processor.py:157} INFO - Started process (PID=1747) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:14:50.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:14:50.406+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:50.406+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:14:50.918+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:14:50.943+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:50.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:14:50.974+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:50.974+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:14:50.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.596 seconds
[2025-09-30T18:15:21.284+0000] {processor.py:157} INFO - Started process (PID=2054) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:15:21.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:15:21.287+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:21.287+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:15:21.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:15:21.781+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:21.780+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:15:21.812+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:21.812+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:15:21.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.554 seconds
[2025-09-30T18:15:52.185+0000] {processor.py:157} INFO - Started process (PID=2361) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:15:52.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:15:52.190+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:52.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:15:52.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:15:52.678+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:52.678+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:15:52.714+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:52.714+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:15:52.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.561 seconds
[2025-09-30T18:16:22.828+0000] {processor.py:157} INFO - Started process (PID=2668) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:16:22.830+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:16:22.832+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:22.832+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:16:23.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:16:23.367+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:23.366+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:16:23.402+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:23.401+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:16:23.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.600 seconds
[2025-09-30T18:16:53.563+0000] {processor.py:157} INFO - Started process (PID=2995) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:16:53.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:16:53.565+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:53.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:16:54.022+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:16:54.047+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:54.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:16:54.076+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:54.076+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:16:54.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.537 seconds
[2025-09-30T18:17:24.598+0000] {processor.py:157} INFO - Started process (PID=3302) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:17:24.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:17:24.604+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:24.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:17:25.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:17:25.287+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:25.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:17:25.569+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:25.569+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:17:25.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.032 seconds
[2025-09-30T18:17:56.224+0000] {processor.py:157} INFO - Started process (PID=3614) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:17:56.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:17:56.227+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:56.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:17:56.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:17:56.771+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:56.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:17:56.809+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:56.809+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:17:56.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.620 seconds
[2025-09-30T18:18:27.418+0000] {processor.py:157} INFO - Started process (PID=3921) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:18:27.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:18:27.420+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:27.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:18:27.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:18:27.949+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:27.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:18:28.143+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:28.143+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:18:28.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.767 seconds
[2025-09-30T18:18:58.925+0000] {processor.py:157} INFO - Started process (PID=4243) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:18:58.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:18:58.927+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:58.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:18:59.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:18:59.538+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:59.537+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:18:59.568+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:59.568+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:18:59.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.671 seconds
[2025-09-30T18:19:29.766+0000] {processor.py:157} INFO - Started process (PID=4570) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:19:29.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:19:29.767+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:29.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:19:30.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:19:30.360+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:30.360+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:19:30.388+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:30.388+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:19:30.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.651 seconds
[2025-09-30T18:20:00.534+0000] {processor.py:157} INFO - Started process (PID=4897) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:20:00.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:20:00.536+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:00.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:20:01.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:20:01.163+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:01.163+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:20:01.191+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:01.191+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:20:01.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.680 seconds
[2025-09-30T18:20:32.139+0000] {processor.py:157} INFO - Started process (PID=5204) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:20:32.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:20:32.141+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:32.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:20:32.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:20:32.725+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:32.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:20:32.754+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:32.754+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:20:32.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.639 seconds
[2025-09-30T18:21:02.824+0000] {processor.py:157} INFO - Started process (PID=5531) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:21:02.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:21:02.827+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:02.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:21:03.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:21:03.471+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:03.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:21:03.506+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:03.506+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:21:03.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.712 seconds
[2025-09-30T18:21:33.811+0000] {processor.py:157} INFO - Started process (PID=5853) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:21:33.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:21:33.813+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:33.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:21:34.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:21:34.472+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:34.471+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:21:34.506+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:34.506+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:21:34.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.726 seconds
[2025-09-30T18:22:04.605+0000] {processor.py:157} INFO - Started process (PID=6170) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:22:04.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:22:04.607+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:04.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:22:05.156+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:22:05.179+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:05.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:22:05.206+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:05.206+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:22:05.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.626 seconds
[2025-09-30T18:22:36.031+0000] {processor.py:157} INFO - Started process (PID=6477) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:22:36.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:22:36.033+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:36.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:22:36.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:22:36.620+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:36.620+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:22:36.646+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:36.646+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:22:36.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.639 seconds
[2025-09-30T18:23:06.902+0000] {processor.py:157} INFO - Started process (PID=6789) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:23:06.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:23:06.905+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:06.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:23:07.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:23:07.686+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:07.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:23:07.724+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:07.724+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:23:07.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.855 seconds
[2025-09-30T18:23:38.410+0000] {processor.py:157} INFO - Started process (PID=7104) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:23:38.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:23:38.413+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:38.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:23:39.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:23:39.711+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:39.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:23:39.896+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:39.896+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:23:40.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.636 seconds
[2025-09-30T18:33:39.499+0000] {processor.py:157} INFO - Started process (PID=7295) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:33:39.501+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:33:39.503+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:33:39.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:33:42.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:33:42.987+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:33:42.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:33:43.061+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:33:43.061+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:33:43.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 3.619 seconds
[2025-09-30T18:34:14.033+0000] {processor.py:157} INFO - Started process (PID=7629) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:34:14.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:34:14.035+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:14.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:34:14.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:34:15.510+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:34:46.446+0000] {processor.py:157} INFO - Started process (PID=7941) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:34:46.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:34:46.448+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:46.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:34:47.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:34:47.074+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:47.074+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:34:47.106+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:47.106+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:34:47.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.684 seconds
[2025-09-30T18:35:17.434+0000] {processor.py:157} INFO - Started process (PID=8256) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:35:17.435+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:35:17.436+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:17.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:35:17.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:35:17.983+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:17.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:35:18.010+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:18.010+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:35:18.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.599 seconds
[2025-09-30T18:35:48.411+0000] {processor.py:157} INFO - Started process (PID=8560) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:35:48.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:35:48.412+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:48.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:35:48.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:35:49.213+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:49.213+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:35:49.241+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:49.241+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:35:49.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.862 seconds
[2025-09-30T18:36:20.242+0000] {processor.py:157} INFO - Started process (PID=8877) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:36:20.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:36:20.245+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:20.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:36:20.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:36:20.835+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:20.834+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:36:20.861+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:20.861+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:36:20.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.648 seconds
[2025-09-30T18:36:51.070+0000] {processor.py:157} INFO - Started process (PID=9194) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:36:51.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:36:51.072+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:51.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:36:51.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:36:51.638+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:51.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:36:51.666+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:51.665+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:36:51.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.624 seconds
[2025-09-30T18:37:21.889+0000] {processor.py:157} INFO - Started process (PID=9489) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:37:21.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:37:21.892+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:21.892+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:37:22.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:37:22.678+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:22.678+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:37:22.707+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:22.707+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:37:22.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.847 seconds
[2025-09-30T18:37:52.860+0000] {processor.py:157} INFO - Started process (PID=9801) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:37:52.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:37:52.861+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:52.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:37:53.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:37:53.337+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:53.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:37:53.368+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:53.368+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:37:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.533 seconds
[2025-09-30T18:38:24.193+0000] {processor.py:157} INFO - Started process (PID=10103) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:38:24.194+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:38:24.195+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:24.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:38:24.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:38:24.762+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:24.761+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:38:24.793+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:24.793+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:38:24.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.628 seconds
[2025-09-30T18:38:55.306+0000] {processor.py:157} INFO - Started process (PID=10415) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:38:55.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:38:55.308+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:55.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:38:55.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:38:56.209+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:56.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:38:56.241+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:56.241+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:38:56.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.963 seconds
[2025-09-30T18:39:26.699+0000] {processor.py:157} INFO - Started process (PID=10737) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:39:26.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:39:26.701+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:26.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:39:27.125+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:39:27.154+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:27.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:39:27.188+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:27.188+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:39:27.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.520 seconds
[2025-09-30T18:39:57.855+0000] {processor.py:157} INFO - Started process (PID=11041) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:39:57.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:39:57.857+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:57.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:39:58.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:39:58.807+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:58.807+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:39:58.838+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:58.838+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:39:58.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.009 seconds
[2025-09-30T18:40:29.710+0000] {processor.py:157} INFO - Started process (PID=11363) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:40:29.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:40:29.712+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:29.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:40:30.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:40:31.033+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:41:01.964+0000] {processor.py:157} INFO - Started process (PID=11703) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:41:01.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:41:01.966+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:01.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:41:02.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:41:02.462+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:02.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:41:02.492+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:02.492+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:41:02.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.555 seconds
[2025-09-30T18:41:39.908+0000] {processor.py:157} INFO - Started process (PID=11999) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:41:39.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:41:39.910+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:39.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:41:40.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:41:40.379+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:40.378+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:41:40.410+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:40.410+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:41:40.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.527 seconds
[2025-09-30T18:42:10.989+0000] {processor.py:157} INFO - Started process (PID=12311) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:42:10.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:42:10.991+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:10.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:42:11.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:42:11.773+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:11.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:42:11.808+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:11.808+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:42:11.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.844 seconds
[2025-09-30T18:42:42.522+0000] {processor.py:157} INFO - Started process (PID=12618) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:42:42.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:42:42.524+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:42.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:42:42.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:42:43.728+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:43.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:42:43.759+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:43.759+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:42:43.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.263 seconds
[2025-09-30T18:43:14.312+0000] {processor.py:157} INFO - Started process (PID=12940) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:43:14.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:43:14.314+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:14.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:43:14.744+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:43:14.770+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:14.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:43:14.799+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:14.799+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:43:14.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.512 seconds
[2025-09-30T18:43:45.645+0000] {processor.py:157} INFO - Started process (PID=13247) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:43:45.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:43:45.647+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:45.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:43:46.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:43:46.488+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:46.487+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:43:46.626+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:46.626+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:43:46.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.008 seconds
[2025-09-30T18:44:16.691+0000] {processor.py:157} INFO - Started process (PID=13554) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:44:16.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:44:16.693+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:16.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:44:17.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:44:18.023+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:44:48.221+0000] {processor.py:157} INFO - Started process (PID=13874) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:44:48.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:44:48.223+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:48.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:44:48.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:44:49.677+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:49.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:44:49.829+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:49.828+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:44:49.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.639 seconds
[2025-09-30T18:45:20.378+0000] {processor.py:157} INFO - Started process (PID=14193) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:45:20.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:45:20.380+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:20.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:45:20.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:45:21.455+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:45:51.569+0000] {processor.py:157} INFO - Started process (PID=14508) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:45:51.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:45:51.571+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:51.571+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:45:52.120+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:45:52.617+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:52.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:45:52.644+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:52.644+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:45:52.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.100 seconds
[2025-09-30T18:46:23.043+0000] {processor.py:157} INFO - Started process (PID=14815) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:46:23.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:46:23.045+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:23.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:46:23.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:46:23.599+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:23.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:46:23.626+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:23.626+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:46:23.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.606 seconds
[2025-09-30T18:46:54.178+0000] {processor.py:157} INFO - Started process (PID=15122) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:46:54.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:46:54.182+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:54.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:46:54.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:46:54.757+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:54.756+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:46:54.786+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:54.786+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:46:54.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.635 seconds
[2025-09-30T18:47:25.092+0000] {processor.py:157} INFO - Started process (PID=15426) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:47:25.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:47:25.094+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:25.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:47:25.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:47:25.676+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:25.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:47:25.703+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:25.703+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:47:25.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.637 seconds
[2025-09-30T18:47:55.906+0000] {processor.py:157} INFO - Started process (PID=15746) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:47:55.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:47:55.907+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:55.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:47:56.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:47:56.524+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:56.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:47:56.551+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:56.551+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:47:56.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.668 seconds
[2025-09-30T18:48:27.038+0000] {processor.py:157} INFO - Started process (PID=16048) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:48:27.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:48:27.040+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:27.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:48:27.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:48:27.618+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:27.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:48:27.648+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:27.648+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:48:27.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.636 seconds
[2025-09-30T18:48:58.274+0000] {processor.py:157} INFO - Started process (PID=16355) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:48:58.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:48:58.280+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:58.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:48:58.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:48:59.656+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:49:30.528+0000] {processor.py:157} INFO - Started process (PID=16682) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:49:30.530+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:49:30.531+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:30.531+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:49:31.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:49:31.133+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:31.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:49:31.159+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:31.159+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:49:31.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.657 seconds
[2025-09-30T18:50:01.289+0000] {processor.py:157} INFO - Started process (PID=16989) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:50:01.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:50:01.291+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:01.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:50:01.842+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:50:01.867+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:01.867+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:50:01.895+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:01.895+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:50:01.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.630 seconds
[2025-09-30T18:50:32.327+0000] {processor.py:157} INFO - Started process (PID=17293) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:50:32.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:50:32.328+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:32.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:50:32.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:50:32.936+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:32.936+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:50:32.967+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:32.967+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:50:32.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.668 seconds
[2025-09-30T18:51:03.080+0000] {processor.py:157} INFO - Started process (PID=17600) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:51:03.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:51:03.082+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:03.081+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:51:03.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:51:04.085+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:04.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:51:04.114+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:04.114+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:51:04.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.058 seconds
[2025-09-30T18:51:34.921+0000] {processor.py:157} INFO - Started process (PID=17922) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:51:34.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:51:34.925+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:34.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:51:35.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:51:35.544+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:35.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:51:35.571+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:35.571+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:51:35.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.673 seconds
[2025-09-30T18:52:06.026+0000] {processor.py:157} INFO - Started process (PID=18229) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:52:06.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:52:06.028+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:06.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:52:06.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:52:06.966+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:52:37.162+0000] {processor.py:157} INFO - Started process (PID=18541) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:52:37.163+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:52:37.164+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:37.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:52:37.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:52:37.745+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:37.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:52:37.774+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:37.774+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:52:37.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.639 seconds
[2025-09-30T18:53:08.344+0000] {processor.py:157} INFO - Started process (PID=18848) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:53:08.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:53:08.346+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:08.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:53:08.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:53:10.004+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:10.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:53:10.032+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:10.032+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:53:10.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.715 seconds
[2025-09-30T18:53:40.167+0000] {processor.py:157} INFO - Started process (PID=19190) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:53:40.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:53:40.169+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:40.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:53:40.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:53:41.079+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:41.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:53:41.109+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:41.108+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:53:41.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.965 seconds
[2025-09-30T18:54:11.876+0000] {processor.py:157} INFO - Started process (PID=19502) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:54:11.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:54:11.879+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:11.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:54:12.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:54:12.526+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:12.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:54:12.553+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:12.553+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:54:12.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.702 seconds
[2025-09-30T18:54:43.430+0000] {processor.py:157} INFO - Started process (PID=19826) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:54:43.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:54:43.432+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:43.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:54:44.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:54:45.149+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:45.148+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:54:45.192+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:45.192+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:54:45.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.795 seconds
[2025-09-30T18:55:15.547+0000] {processor.py:157} INFO - Started process (PID=20151) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:55:15.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:55:15.549+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:15.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:55:16.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:55:16.434+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:55:46.971+0000] {processor.py:157} INFO - Started process (PID=20458) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:55:46.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:55:46.973+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:46.973+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:55:47.525+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:55:47.547+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:47.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:55:47.574+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:47.574+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:55:47.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.626 seconds
[2025-09-30T18:56:17.649+0000] {processor.py:157} INFO - Started process (PID=20765) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:56:17.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:56:17.651+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:17.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:56:18.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:56:18.528+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:18.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:56:18.555+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:18.555+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:56:18.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.930 seconds
[2025-09-30T18:56:49.978+0000] {processor.py:157} INFO - Started process (PID=21069) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:56:49.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:56:49.981+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:49.981+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:56:50.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:56:50.445+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:50.444+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:56:50.478+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:50.478+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:56:50.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.526 seconds
[2025-09-30T18:57:20.902+0000] {processor.py:157} INFO - Started process (PID=21364) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:57:20.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:57:20.904+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:20.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:57:21.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:57:21.745+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:21.744+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:57:21.784+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:21.784+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:57:21.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.908 seconds
[2025-09-30T18:57:52.497+0000] {processor.py:157} INFO - Started process (PID=21673) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:57:52.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:57:52.499+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:52.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:57:52.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:57:53.864+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:53.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:57:53.895+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:53.895+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:57:53.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.423 seconds
[2025-09-30T18:58:24.155+0000] {processor.py:157} INFO - Started process (PID=21985) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:58:24.156+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:58:24.157+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:24.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:58:24.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:58:24.705+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:24.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:58:24.737+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:24.737+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:58:24.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.612 seconds
[2025-09-30T18:58:55.297+0000] {processor.py:157} INFO - Started process (PID=22297) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:58:55.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:58:55.300+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:55.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:58:55.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:58:56.091+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:56.091+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:58:56.122+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:56.122+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:58:56.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.851 seconds
[2025-09-30T18:59:26.448+0000] {processor.py:157} INFO - Started process (PID=22604) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:59:26.449+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:59:26.450+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:26.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:59:26.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:59:26.915+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:26.914+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:59:26.945+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:26.945+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:59:26.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.521 seconds
[2025-09-30T18:59:57.598+0000] {processor.py:157} INFO - Started process (PID=22911) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:59:57.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T18:59:57.600+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:57.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:59:58.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T18:59:58.078+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:58.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:59:58.108+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:58.108+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T18:59:58.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.535 seconds
[2025-09-30T19:00:28.603+0000] {processor.py:157} INFO - Started process (PID=23231) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:00:28.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:00:28.605+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:28.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:00:29.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:00:29.358+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:29.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:00:29.389+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:29.389+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:00:29.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.812 seconds
[2025-09-30T19:00:59.850+0000] {processor.py:157} INFO - Started process (PID=23538) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:00:59.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:00:59.854+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:59.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:01:00.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:01:00.363+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:00.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:01:00.393+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:00.393+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:01:00.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.571 seconds
[2025-09-30T19:01:30.684+0000] {processor.py:157} INFO - Started process (PID=23845) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:01:30.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:01:30.686+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:30.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:01:31.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:01:31.192+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:31.191+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:01:31.221+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:31.221+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:01:31.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.561 seconds
[2025-09-30T19:02:01.887+0000] {processor.py:157} INFO - Started process (PID=24152) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:02:01.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:02:01.888+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:01.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:02:02.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:02:02.364+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:02.364+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:02:02.395+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:02.395+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:02:02.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.651 seconds
[2025-09-30T19:02:33.022+0000] {processor.py:157} INFO - Started process (PID=24459) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:02:33.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:02:33.024+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:33.024+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:02:33.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:02:33.568+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:33.567+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:02:33.598+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:33.598+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:02:33.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.603 seconds
[2025-09-30T19:03:03.938+0000] {processor.py:157} INFO - Started process (PID=24766) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:03:03.939+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:03:03.940+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:03.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:03:04.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:03:04.948+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:04.948+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:03:05.105+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:05.104+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:03:05.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.191 seconds
[2025-09-30T19:03:40.026+0000] {processor.py:157} INFO - Started process (PID=25028) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:03:40.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:03:40.028+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:40.027+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:03:40.633+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:03:40.656+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:40.655+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:03:40.684+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:40.684+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:03:40.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.687 seconds
[2025-09-30T19:04:11.795+0000] {processor.py:157} INFO - Started process (PID=25335) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:04:11.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:04:11.796+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:11.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:04:12.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:04:12.410+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:12.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:04:12.437+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:12.436+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:04:12.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.666 seconds
[2025-09-30T19:04:43.132+0000] {processor.py:157} INFO - Started process (PID=25642) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:04:43.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:04:43.134+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:43.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:04:43.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:04:43.692+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:43.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:04:43.727+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:43.726+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:04:43.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.622 seconds
[2025-09-30T19:05:14.005+0000] {processor.py:157} INFO - Started process (PID=25966) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:05:14.007+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:05:14.008+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:14.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:05:14.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:05:15.061+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:05:45.881+0000] {processor.py:157} INFO - Started process (PID=26273) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:05:45.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:05:45.882+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:45.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:05:46.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:05:46.482+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:46.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:05:46.517+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:46.517+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:05:46.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.665 seconds
[2025-09-30T19:06:17.053+0000] {processor.py:157} INFO - Started process (PID=26580) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:06:17.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:06:17.054+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:17.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:06:17.614+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:06:17.638+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:17.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:06:17.667+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:17.667+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:06:17.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.640 seconds
[2025-09-30T19:06:47.977+0000] {processor.py:157} INFO - Started process (PID=26902) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:06:47.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:06:47.979+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:47.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:06:48.580+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:06:48.748+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:48.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:06:48.783+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:48.783+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:06:48.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.835 seconds
[2025-09-30T19:07:19.756+0000] {processor.py:157} INFO - Started process (PID=27236) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:07:19.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:07:19.758+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:19.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:07:20.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:07:20.679+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:20.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:07:20.714+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:20.714+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:07:20.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.991 seconds
[2025-09-30T19:07:51.517+0000] {processor.py:157} INFO - Started process (PID=27543) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:07:51.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:07:51.519+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:51.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:07:52.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:07:52.045+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:52.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:07:52.072+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:52.071+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:07:52.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.578 seconds
[2025-09-30T19:08:22.133+0000] {processor.py:157} INFO - Started process (PID=27825) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:08:22.134+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:08:22.135+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:22.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:08:22.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:08:22.695+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:22.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:08:22.730+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:22.730+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:08:22.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.625 seconds
[2025-09-30T19:08:52.933+0000] {processor.py:157} INFO - Started process (PID=28132) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:08:52.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:08:52.936+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:52.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:08:53.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:08:53.911+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:53.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:08:53.939+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:53.939+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:08:53.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.031 seconds
[2025-09-30T19:09:24.036+0000] {processor.py:157} INFO - Started process (PID=28467) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:09:24.037+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:09:24.037+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:24.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:09:24.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:09:25.678+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:09:55.970+0000] {processor.py:157} INFO - Started process (PID=28776) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:09:55.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:09:55.973+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:55.973+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:09:56.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:09:56.569+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:56.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:09:56.596+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:56.595+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:09:56.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.650 seconds
[2025-09-30T19:10:26.842+0000] {processor.py:157} INFO - Started process (PID=29083) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:10:26.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:10:26.844+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:26.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:10:27.423+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:10:28.591+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:28.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:10:28.620+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:28.620+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:10:28.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.807 seconds
[2025-09-30T19:10:59.251+0000] {processor.py:157} INFO - Started process (PID=29411) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:10:59.252+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:10:59.253+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:59.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:10:59.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:10:59.835+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:59.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:10:59.863+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:59.863+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:10:59.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.637 seconds
[2025-09-30T19:11:30.416+0000] {processor.py:157} INFO - Started process (PID=29718) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:11:30.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:11:30.418+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:30.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:11:30.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:11:31.806+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:12:01.887+0000] {processor.py:157} INFO - Started process (PID=30037) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:12:01.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:12:01.889+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:01.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:12:02.441+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:12:02.464+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:02.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:12:02.491+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:02.491+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:12:02.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.630 seconds
[2025-09-30T19:12:32.732+0000] {processor.py:157} INFO - Started process (PID=30357) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:12:32.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:12:32.735+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:32.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:12:33.300+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:12:33.809+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:33.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:12:33.841+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:33.841+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:12:33.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.133 seconds
[2025-09-30T19:13:03.998+0000] {processor.py:157} INFO - Started process (PID=30681) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:13:03.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:13:04.000+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:04.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:13:04.532+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:13:05.036+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:13:35.145+0000] {processor.py:157} INFO - Started process (PID=30971) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:13:35.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:13:35.148+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:35.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:13:35.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:13:36.475+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:36.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:13:36.508+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:36.508+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:13:36.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.392 seconds
[2025-09-30T19:14:07.002+0000] {processor.py:157} INFO - Started process (PID=31280) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:14:07.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:14:07.005+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:07.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:14:07.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:14:07.566+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:07.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:14:07.594+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:07.593+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:14:07.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.616 seconds
[2025-09-30T19:14:38.225+0000] {processor.py:157} INFO - Started process (PID=31590) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:14:38.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:14:38.227+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:38.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:14:38.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:14:38.788+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:38.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:14:38.818+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:38.818+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:14:38.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.619 seconds
[2025-09-30T19:15:09.463+0000] {processor.py:157} INFO - Started process (PID=31894) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:15:09.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:15:09.466+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:09.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:15:09.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:15:09.922+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:09.921+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:15:09.951+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:09.951+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:15:09.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.519 seconds
[2025-09-30T19:15:40.535+0000] {processor.py:157} INFO - Started process (PID=32201) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:15:40.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:15:40.538+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:40.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:15:40.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:15:41.394+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:41.394+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:15:41.426+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:41.426+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:15:41.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.915 seconds
[2025-09-30T19:16:11.605+0000] {processor.py:157} INFO - Started process (PID=32516) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:16:11.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:16:11.607+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:11.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:16:12.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:16:12.141+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:16:42.247+0000] {processor.py:157} INFO - Started process (PID=32820) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:16:42.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:16:42.248+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:42.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:16:42.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:16:42.762+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:42.761+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:16:42.793+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:42.793+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:16:42.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.570 seconds
[2025-09-30T19:17:13.067+0000] {processor.py:157} INFO - Started process (PID=33140) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:17:13.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:17:13.069+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:13.068+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:17:13.485+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:17:14.514+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:14.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:17:14.544+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:14.544+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:17:14.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.503 seconds
[2025-09-30T19:17:44.776+0000] {processor.py:157} INFO - Started process (PID=33447) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:17:44.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:17:44.778+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:44.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:17:45.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:17:45.549+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:45.548+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:17:45.579+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:45.579+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:17:45.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.829 seconds
[2025-09-30T19:18:16.418+0000] {processor.py:157} INFO - Started process (PID=33761) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:18:16.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:18:16.420+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:16.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:18:16.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:18:16.948+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:16.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:18:16.990+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:16.990+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:18:17.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.600 seconds
[2025-09-30T19:18:47.139+0000] {processor.py:157} INFO - Started process (PID=34070) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:18:47.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:18:47.141+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:47.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:18:47.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:18:47.602+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:47.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:18:47.634+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:47.634+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:18:47.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.520 seconds
[2025-09-30T19:19:18.068+0000] {processor.py:157} INFO - Started process (PID=34370) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:19:18.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:19:18.070+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:18.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:19:18.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:19:18.828+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:18.828+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:19:18.859+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:18.859+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:19:18.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.817 seconds
[2025-09-30T19:19:50.527+0000] {processor.py:157} INFO - Started process (PID=34682) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:19:50.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:19:50.528+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:50.528+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:19:50.956+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:19:51.344+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:51.220+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:19:51.382+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:51.382+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:19:51.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.882 seconds
[2025-09-30T19:20:21.538+0000] {processor.py:157} INFO - Started process (PID=34996) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:20:21.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:20:21.540+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:21.540+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:20:22.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:20:22.258+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:22.257+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:20:22.284+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:22.284+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:20:22.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.773 seconds
[2025-09-30T19:20:52.816+0000] {processor.py:157} INFO - Started process (PID=35303) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:20:52.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:20:52.817+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:52.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:20:53.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:20:53.634+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:53.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:20:53.662+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:53.662+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:20:53.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.873 seconds
[2025-09-30T19:21:24.043+0000] {processor.py:157} INFO - Started process (PID=35620) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:21:24.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:21:24.045+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:24.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:21:24.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:21:24.596+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:24.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:21:24.623+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:24.623+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:21:24.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.603 seconds
[2025-09-30T19:21:54.747+0000] {processor.py:157} INFO - Started process (PID=35925) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:21:54.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:21:54.749+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:54.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:21:55.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:21:55.267+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:55.267+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:21:55.292+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:55.292+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:21:55.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.568 seconds
[2025-09-30T19:22:25.982+0000] {processor.py:157} INFO - Started process (PID=36232) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:22:25.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:22:25.984+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:25.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:22:26.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:22:26.699+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:26.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:22:26.726+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:26.726+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:22:26.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.771 seconds
[2025-09-30T19:22:57.294+0000] {processor.py:157} INFO - Started process (PID=36528) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:22:57.295+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:22:57.296+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:57.296+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:22:57.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:22:59.196+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:59.195+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:22:59.225+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:59.224+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:22:59.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.956 seconds
[2025-09-30T19:23:29.596+0000] {processor.py:157} INFO - Started process (PID=36853) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:23:29.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:23:29.598+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:29.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:23:30.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:23:30.157+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:30.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:23:30.183+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:30.183+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:23:30.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.611 seconds
[2025-09-30T19:24:00.499+0000] {processor.py:157} INFO - Started process (PID=37165) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:24:00.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:24:00.502+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:00.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:24:01.053+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:24:01.370+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:01.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:24:01.405+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:01.405+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:24:01.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.932 seconds
[2025-09-30T19:24:31.975+0000] {processor.py:157} INFO - Started process (PID=37475) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:24:31.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:24:31.976+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:31.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:24:32.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:24:33.222+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:25:03.771+0000] {processor.py:157} INFO - Started process (PID=37792) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:25:03.772+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:25:03.773+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:03.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:25:04.297+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:25:04.321+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:04.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:25:04.348+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:04.348+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:25:04.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.602 seconds
[2025-09-30T19:25:41.455+0000] {processor.py:157} INFO - Started process (PID=38094) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:25:41.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:25:41.459+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:41.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:25:42.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:25:43.571+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:43.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:25:43.615+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:43.615+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:25:43.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 2.211 seconds
[2025-09-30T19:26:14.403+0000] {processor.py:157} INFO - Started process (PID=38421) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:26:14.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:26:14.405+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:14.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:26:14.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:26:15.808+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:15.807+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:26:15.843+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:15.843+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:26:15.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.462 seconds
[2025-09-30T19:26:46.501+0000] {processor.py:157} INFO - Started process (PID=38733) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:26:46.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:26:46.503+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:46.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:26:47.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:26:47.452+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:47.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:26:47.484+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:47.484+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:26:47.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.006 seconds
[2025-09-30T19:27:18.192+0000] {processor.py:157} INFO - Started process (PID=39054) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:27:18.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:27:18.194+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:18.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:27:18.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:27:19.389+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:27:49.602+0000] {processor.py:157} INFO - Started process (PID=39369) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:27:49.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:27:49.605+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:49.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:27:50.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:27:50.633+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:28:21.470+0000] {processor.py:157} INFO - Started process (PID=39678) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:28:21.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:28:21.473+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:21.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:28:22.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:28:22.675+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:22.675+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:28:22.711+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:22.711+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:28:22.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.274 seconds
[2025-09-30T19:28:53.217+0000] {processor.py:157} INFO - Started process (PID=39990) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:28:53.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:28:53.220+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:53.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:28:53.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:28:54.594+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:29:24.709+0000] {processor.py:157} INFO - Started process (PID=40310) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:29:24.709+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:29:24.710+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:24.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:29:25.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:29:25.564+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:25.563+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:29:25.642+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:25.642+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:29:25.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.987 seconds
[2025-09-30T19:29:55.982+0000] {processor.py:157} INFO - Started process (PID=40617) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:29:55.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:29:55.984+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:55.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:29:56.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:29:56.520+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:56.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:29:56.546+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:56.546+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:29:56.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.587 seconds
[2025-09-30T19:30:26.608+0000] {processor.py:157} INFO - Started process (PID=40920) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:30:26.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:30:26.610+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:26.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:30:27.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:30:27.190+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:27.190+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:30:27.218+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:27.218+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:30:27.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.636 seconds
[2025-09-30T19:30:57.369+0000] {processor.py:157} INFO - Started process (PID=41227) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:30:57.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:30:57.372+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:57.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:30:58.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:30:59.141+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:59.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:30:59.174+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:59.173+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:30:59.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.832 seconds
[2025-09-30T19:31:29.498+0000] {processor.py:157} INFO - Started process (PID=41539) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:31:29.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:31:29.500+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:29.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:31:29.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:31:30.431+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:30.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:31:30.463+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:30.463+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:31:30.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.993 seconds
[2025-09-30T19:32:00.980+0000] {processor.py:157} INFO - Started process (PID=41851) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:32:00.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:32:00.982+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:00.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:32:01.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:32:01.504+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:01.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:32:01.538+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:01.537+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:32:01.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.593 seconds
[2025-09-30T19:32:31.797+0000] {processor.py:157} INFO - Started process (PID=42158) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:32:31.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:32:31.800+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:31.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:32:32.233+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:32:32.831+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:32.831+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:32:32.878+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:32.878+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:32:32.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.158 seconds
[2025-09-30T19:33:03.171+0000] {processor.py:157} INFO - Started process (PID=42470) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:33:03.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:33:03.177+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:03.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:33:03.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:33:04.548+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:04.548+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:33:04.583+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:04.582+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:33:04.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.444 seconds
[2025-09-30T19:33:35.317+0000] {processor.py:157} INFO - Started process (PID=42795) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:33:35.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:33:35.319+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:35.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:33:35.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:33:36.230+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:36.229+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:33:36.264+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:36.264+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:33:36.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.973 seconds
[2025-09-30T19:34:06.438+0000] {processor.py:157} INFO - Started process (PID=43112) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:34:06.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:34:06.440+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:06.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:34:06.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:34:06.938+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:06.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:34:06.967+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:06.967+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:34:06.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.556 seconds
[2025-09-30T19:34:37.922+0000] {processor.py:157} INFO - Started process (PID=43417) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:34:37.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:34:37.924+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:37.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:34:38.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:34:39.073+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:39.073+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:34:39.105+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:39.104+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:34:39.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.208 seconds
[2025-09-30T19:35:09.279+0000] {processor.py:157} INFO - Started process (PID=43731) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:35:09.280+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:35:09.281+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:09.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:35:09.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:35:09.740+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:09.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:35:09.876+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:09.876+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:35:09.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.622 seconds
[2025-09-30T19:35:40.336+0000] {processor.py:157} INFO - Started process (PID=44058) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:35:40.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:35:40.338+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:40.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:35:40.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:35:41.945+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:36:12.162+0000] {processor.py:157} INFO - Started process (PID=44390) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:36:12.163+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:36:12.164+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:12.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:36:12.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:36:13.387+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:13.386+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:36:13.425+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:13.425+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:36:13.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.299 seconds
[2025-09-30T19:36:43.541+0000] {processor.py:157} INFO - Started process (PID=44702) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:36:43.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:36:43.543+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:43.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:36:44.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:36:44.090+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:44.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:36:44.115+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:44.115+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:36:44.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.604 seconds
[2025-09-30T19:37:14.222+0000] {processor.py:157} INFO - Started process (PID=45007) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:37:14.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:37:14.224+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:14.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:37:14.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:37:16.091+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:16.091+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:37:16.118+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:16.118+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:37:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.922 seconds
[2025-09-30T19:37:46.259+0000] {processor.py:157} INFO - Started process (PID=45316) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:37:46.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:37:46.261+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:46.261+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:37:46.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:37:46.815+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:46.814+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:37:46.842+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:46.842+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:37:46.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.608 seconds
[2025-09-30T19:38:16.961+0000] {processor.py:157} INFO - Started process (PID=45623) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:38:16.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:38:16.963+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:16.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:38:17.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:38:17.577+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:17.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:38:17.604+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:17.603+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:38:17.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.665 seconds
[2025-09-30T19:38:48.108+0000] {processor.py:157} INFO - Started process (PID=45930) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:38:48.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:38:48.111+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:48.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:38:48.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:38:49.070+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:49.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:38:49.096+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:49.096+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:38:49.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.014 seconds
[2025-09-30T19:39:19.240+0000] {processor.py:157} INFO - Started process (PID=46237) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:39:19.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:39:19.241+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:19.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:39:19.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:39:20.292+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:20.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:39:20.322+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:20.322+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:39:20.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.105 seconds
[2025-09-30T19:39:50.823+0000] {processor.py:157} INFO - Started process (PID=46556) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:39:50.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:39:50.827+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:50.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:39:51.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:39:51.768+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:51.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:39:51.801+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:51.801+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:39:51.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.004 seconds
[2025-09-30T19:40:22.164+0000] {processor.py:157} INFO - Started process (PID=46868) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:40:22.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:40:22.166+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:22.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:40:22.730+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:40:23.088+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:23.087+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:40:23.114+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:23.113+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:40:23.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.973 seconds
[2025-09-30T19:40:53.718+0000] {processor.py:157} INFO - Started process (PID=47175) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:40:53.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:40:53.720+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:53.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:40:54.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:40:54.408+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:54.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:40:54.437+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:54.437+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:40:54.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.743 seconds
[2025-09-30T19:41:24.569+0000] {processor.py:157} INFO - Started process (PID=47487) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:41:24.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:41:24.571+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:24.571+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:41:25.125+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:41:25.900+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:25.900+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:41:25.928+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:25.928+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-09-30T00:00:00+00:00, run_after=2025-10-01T00:00:00+00:00
[2025-09-30T19:41:25.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.384 seconds
[2025-09-30T19:41:56.535+0000] {processor.py:157} INFO - Started process (PID=47799) to work on /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:41:56.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-09-30T19:41:56.538+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:56.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:41:57.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-09-30T19:41:57.346+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
