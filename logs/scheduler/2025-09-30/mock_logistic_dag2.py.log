[2025-09-30T18:12:06.987+0000] {processor.py:157} INFO - Started process (PID=179) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:12:06.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:12:06.993+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:06.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:12:09.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:12:09.401+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:09.400+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:12:09.455+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:09.455+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:12:09.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.537 seconds
[2025-09-30T18:12:39.689+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:12:39.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:12:39.694+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:39.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:12:40.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:12:40.913+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:40.912+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:12:40.970+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:12:40.970+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:12:41.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.322 seconds
[2025-09-30T18:13:11.386+0000] {processor.py:157} INFO - Started process (PID=800) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:13:11.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:13:11.389+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:11.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:13:11.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:13:11.904+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:11.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:13:11.946+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:11.946+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:13:11.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.597 seconds
[2025-09-30T18:13:42.039+0000] {processor.py:157} INFO - Started process (PID=1107) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:13:42.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:13:42.042+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:42.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:13:42.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:13:42.545+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:42.545+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:13:42.579+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:13:42.579+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:13:42.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.581 seconds
[2025-09-30T18:14:12.945+0000] {processor.py:157} INFO - Started process (PID=1414) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:14:12.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:14:12.948+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:12.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:14:13.455+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:14:13.501+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:13.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:14:13.540+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:13.540+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:14:13.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.631 seconds
[2025-09-30T18:14:43.759+0000] {processor.py:157} INFO - Started process (PID=1721) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:14:43.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:14:43.762+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:43.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:14:44.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:14:44.268+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:44.268+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:14:44.298+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:14:44.298+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:14:44.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.568 seconds
[2025-09-30T18:15:14.625+0000] {processor.py:157} INFO - Started process (PID=2028) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:15:14.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:15:14.627+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:14.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:15:15.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:15:15.146+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:15.145+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:15:15.181+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:15.181+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:15:15.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.586 seconds
[2025-09-30T18:15:45.451+0000] {processor.py:157} INFO - Started process (PID=2335) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:15:45.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:15:45.453+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:45.453+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:15:46.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:15:46.038+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:46.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:15:46.077+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:15:46.077+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:15:46.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.655 seconds
[2025-09-30T18:16:16.316+0000] {processor.py:157} INFO - Started process (PID=2642) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:16:16.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:16:16.319+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:16.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:16:16.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:16:16.875+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:16.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:16:16.907+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:16.907+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:16:16.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.620 seconds
[2025-09-30T18:16:47.457+0000] {processor.py:157} INFO - Started process (PID=2949) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:16:47.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:16:47.459+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:47.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:16:47.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:16:47.987+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:47.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:16:48.025+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:16:48.025+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:16:48.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.606 seconds
[2025-09-30T18:17:18.169+0000] {processor.py:157} INFO - Started process (PID=3256) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:17:18.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:17:18.175+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:18.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:17:18.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:17:19.112+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:18.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:17:19.146+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:19.146+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:17:19.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.012 seconds
[2025-09-30T18:17:49.281+0000] {processor.py:157} INFO - Started process (PID=3563) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:17:49.282+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:17:49.283+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:49.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:17:49.731+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:17:49.758+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:49.757+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:17:49.941+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:17:49.941+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:17:49.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.706 seconds
[2025-09-30T18:18:20.153+0000] {processor.py:157} INFO - Started process (PID=3870) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:18:20.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:18:20.155+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:20.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:18:20.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:18:20.983+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:20.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:18:21.015+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:21.015+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:18:21.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.888 seconds
[2025-09-30T18:18:51.108+0000] {processor.py:157} INFO - Started process (PID=4177) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:18:51.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:18:51.110+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:51.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:18:51.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:18:51.688+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:51.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:18:51.718+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:18:51.718+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:18:51.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.683 seconds
[2025-09-30T18:19:22.108+0000] {processor.py:157} INFO - Started process (PID=4484) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:19:22.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:19:22.110+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:22.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:19:22.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:19:22.680+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:22.576+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:19:22.713+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:22.713+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:19:22.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.666 seconds
[2025-09-30T18:19:53.181+0000] {processor.py:157} INFO - Started process (PID=4791) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:19:53.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:19:53.184+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:53.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:19:53.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:19:53.788+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:53.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:19:53.868+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:19:53.868+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:19:53.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.714 seconds
[2025-09-30T18:20:24.286+0000] {processor.py:157} INFO - Started process (PID=5098) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:20:24.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:20:24.288+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:24.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:20:24.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:20:24.858+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:24.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:20:24.948+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:24.947+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:20:24.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.687 seconds
[2025-09-30T18:20:55.177+0000] {processor.py:157} INFO - Started process (PID=5405) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:20:55.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:20:55.179+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:55.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:20:55.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:20:55.792+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:55.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:20:55.821+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:20:55.821+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:20:55.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.668 seconds
[2025-09-30T18:21:26.136+0000] {processor.py:157} INFO - Started process (PID=5712) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:21:26.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:21:26.138+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:26.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:21:26.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:21:26.702+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:26.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:21:26.730+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:26.729+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:21:26.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.649 seconds
[2025-09-30T18:21:57.247+0000] {processor.py:157} INFO - Started process (PID=6019) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:21:57.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:21:57.248+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:57.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:21:57.874+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:21:57.896+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:57.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:21:57.926+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:21:57.925+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:21:57.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.707 seconds
[2025-09-30T18:22:28.826+0000] {processor.py:157} INFO - Started process (PID=6341) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:22:28.827+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:22:28.828+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:28.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:22:29.402+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:22:29.425+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:29.424+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:22:29.454+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:22:29.454+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:22:29.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.656 seconds
[2025-09-30T18:23:00.321+0000] {processor.py:157} INFO - Started process (PID=6648) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:23:00.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:23:00.323+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:00.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:23:00.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:23:00.973+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:00.972+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:23:01.001+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:01.001+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:23:01.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.705 seconds
[2025-09-30T18:23:31.296+0000] {processor.py:157} INFO - Started process (PID=6955) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:23:31.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:23:31.298+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:31.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:23:32.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:23:32.093+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:32.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:23:32.129+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:23:32.129+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:23:32.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.864 seconds
[2025-09-30T18:24:16.916+0000] {processor.py:157} INFO - Started process (PID=7269) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:24:16.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:24:16.929+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:24:16.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:24:19.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:24:20.023+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:24:20.021+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:33:39.170+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:33:39.169+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:33:39.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 3.348 seconds
[2025-09-30T18:34:10.047+0000] {processor.py:157} INFO - Started process (PID=7578) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:34:10.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:34:10.051+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:10.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:34:10.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:34:10.626+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:10.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:34:10.654+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:10.654+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:34:10.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.630 seconds
[2025-09-30T18:34:40.867+0000] {processor.py:157} INFO - Started process (PID=7885) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:34:40.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:34:40.869+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:40.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:34:41.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:34:42.082+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:42.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:34:42.124+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:34:42.123+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:34:42.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.287 seconds
[2025-09-30T18:35:12.762+0000] {processor.py:157} INFO - Started process (PID=8192) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:35:12.763+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:35:12.764+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:12.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:35:13.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:35:13.396+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:13.395+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:35:13.434+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:13.434+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:35:13.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.702 seconds
[2025-09-30T18:35:43.608+0000] {processor.py:157} INFO - Started process (PID=8499) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:35:43.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:35:43.611+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:43.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:35:44.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:35:44.593+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:44.593+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:35:44.623+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:35:44.623+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:35:44.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.038 seconds
[2025-09-30T18:36:14.770+0000] {processor.py:157} INFO - Started process (PID=8806) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:36:14.772+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:36:14.772+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:14.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:36:15.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:36:15.534+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:15.534+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:36:15.560+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:15.560+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:36:15.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.823 seconds
[2025-09-30T18:36:46.263+0000] {processor.py:157} INFO - Started process (PID=9113) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:36:46.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:36:46.265+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:46.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:36:46.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:36:47.256+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:47.255+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:36:47.288+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:36:47.288+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:36:47.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.059 seconds
[2025-09-30T18:37:17.826+0000] {processor.py:157} INFO - Started process (PID=9420) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:37:17.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:37:17.829+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:17.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:37:18.433+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:37:18.458+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:18.457+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:37:18.485+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:18.485+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:37:18.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.686 seconds
[2025-09-30T18:37:48.767+0000] {processor.py:157} INFO - Started process (PID=9727) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:37:48.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:37:48.769+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:48.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:37:49.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:37:49.519+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:49.518+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:37:49.548+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:37:49.548+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:37:49.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.807 seconds
[2025-09-30T18:38:20.421+0000] {processor.py:157} INFO - Started process (PID=10039) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:38:20.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:38:20.424+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:20.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:38:20.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:38:20.898+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:20.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:38:20.930+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:20.929+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:38:20.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.537 seconds
[2025-09-30T18:38:51.070+0000] {processor.py:157} INFO - Started process (PID=10346) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:38:51.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:38:51.072+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:51.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:38:51.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:38:52.089+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:52.088+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:38:52.129+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:38:52.129+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:38:52.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.088 seconds
[2025-09-30T18:39:22.220+0000] {processor.py:157} INFO - Started process (PID=10653) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:39:22.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:39:22.222+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:22.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:39:22.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:39:22.686+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:22.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:39:22.719+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:22.719+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:39:22.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.528 seconds
[2025-09-30T18:39:52.901+0000] {processor.py:157} INFO - Started process (PID=10960) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:39:52.902+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:39:52.903+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:52.903+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:39:53.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:39:53.358+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:53.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:39:53.388+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:39:53.387+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:39:53.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.514 seconds
[2025-09-30T18:40:24.245+0000] {processor.py:157} INFO - Started process (PID=11267) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:40:24.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:40:24.247+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:24.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:40:24.684+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:40:25.578+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:25.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:40:25.608+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:25.608+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:40:25.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.389 seconds
[2025-09-30T18:40:56.354+0000] {processor.py:157} INFO - Started process (PID=11579) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:40:56.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:40:56.356+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:56.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:40:56.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:40:57.162+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:57.161+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:40:57.193+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:40:57.193+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:40:57.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.867 seconds
[2025-09-30T18:41:27.686+0000] {processor.py:157} INFO - Started process (PID=11886) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:41:27.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:41:27.688+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:27.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:41:28.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:41:28.436+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:28.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:41:28.469+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:28.469+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:41:28.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.813 seconds
[2025-09-30T18:41:58.527+0000] {processor.py:157} INFO - Started process (PID=12193) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:41:58.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:41:58.529+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:58.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:41:58.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:41:59.125+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:59.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:41:59.157+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:41:59.157+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:41:59.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.657 seconds
[2025-09-30T18:42:29.981+0000] {processor.py:157} INFO - Started process (PID=12511) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:42:29.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:42:29.983+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:29.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:42:30.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:42:31.431+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:31.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:42:31.460+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:42:31.460+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:42:31.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.504 seconds
[2025-09-30T18:43:01.718+0000] {processor.py:157} INFO - Started process (PID=12828) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:43:01.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:43:01.721+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:01.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:43:02.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:43:03.255+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:03.254+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:43:03.432+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:03.432+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:43:09.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 7.810 seconds
[2025-09-30T18:43:40.258+0000] {processor.py:157} INFO - Started process (PID=13144) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:43:40.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:43:40.259+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:40.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:43:40.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:43:40.728+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:40.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:43:40.759+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:43:40.759+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:43:40.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.527 seconds
[2025-09-30T18:44:10.986+0000] {processor.py:157} INFO - Started process (PID=13461) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:44:10.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:44:10.988+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:10.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:44:11.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:44:11.650+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:11.650+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:44:11.782+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:11.782+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:44:11.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.819 seconds
[2025-09-30T18:44:42.018+0000] {processor.py:157} INFO - Started process (PID=13771) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:44:42.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:44:42.020+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:42.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:44:42.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:44:42.629+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:42.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:44:42.661+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:44:42.661+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:44:42.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.672 seconds
[2025-09-30T18:45:12.745+0000] {processor.py:157} INFO - Started process (PID=14080) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:45:12.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:45:12.747+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:12.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:45:13.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:45:13.204+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:13.203+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:45:13.342+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:13.342+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:45:13.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.624 seconds
[2025-09-30T18:45:43.572+0000] {processor.py:157} INFO - Started process (PID=14380) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:45:43.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:45:43.576+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:43.576+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:45:44.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:45:44.193+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:44.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:45:44.220+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:45:44.220+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:45:44.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.675 seconds
[2025-09-30T18:46:14.369+0000] {processor.py:157} INFO - Started process (PID=14692) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:46:14.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:46:14.371+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:14.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:46:14.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:46:15.369+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:46:46.275+0000] {processor.py:157} INFO - Started process (PID=15004) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:46:46.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:46:46.277+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:46.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:46:46.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:46:46.831+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:46.831+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:46:46.858+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:46:46.858+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:46:46.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.608 seconds
[2025-09-30T18:47:17.751+0000] {processor.py:157} INFO - Started process (PID=15308) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:47:17.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:47:17.753+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:17.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:47:18.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:47:18.565+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:18.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:47:18.610+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:18.610+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:47:18.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.905 seconds
[2025-09-30T18:47:48.795+0000] {processor.py:157} INFO - Started process (PID=15623) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:47:48.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:47:48.797+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:47:48.797+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:47:49.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:47:50.543+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:48:20.747+0000] {processor.py:157} INFO - Started process (PID=15937) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:48:20.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:48:20.749+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:20.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:48:21.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:48:22.065+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:22.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:48:22.096+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:22.095+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:48:22.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.378 seconds
[2025-09-30T18:48:52.484+0000] {processor.py:157} INFO - Started process (PID=16244) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:48:52.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:48:52.486+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:52.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:48:53.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:48:53.356+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:53.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:48:53.384+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:48:53.384+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:48:53.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.925 seconds
[2025-09-30T18:49:24.242+0000] {processor.py:157} INFO - Started process (PID=16561) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:49:24.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:49:24.245+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:24.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:49:24.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:49:24.828+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:24.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:49:24.859+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:24.859+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:49:24.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.642 seconds
[2025-09-30T18:49:55.495+0000] {processor.py:157} INFO - Started process (PID=16868) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:49:55.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:49:55.498+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:49:55.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:49:56.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:49:56.472+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:50:26.694+0000] {processor.py:157} INFO - Started process (PID=17175) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:50:26.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:50:26.697+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:26.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:50:27.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:50:27.274+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:27.273+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:50:27.301+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:27.301+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:50:27.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.632 seconds
[2025-09-30T18:50:57.410+0000] {processor.py:157} INFO - Started process (PID=17482) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:50:57.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:50:57.412+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:57.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:50:57.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:50:57.958+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:57.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:50:57.986+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:50:57.986+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:50:58.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.601 seconds
[2025-09-30T18:51:28.403+0000] {processor.py:157} INFO - Started process (PID=17789) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:51:28.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:51:28.405+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:28.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:51:28.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:51:29.726+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:29.726+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:51:29.753+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:51:29.753+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:51:29.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.376 seconds
[2025-09-30T18:52:00.092+0000] {processor.py:157} INFO - Started process (PID=18114) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:52:00.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:52:00.094+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:00.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:52:00.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:52:00.658+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:00.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:52:00.684+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:00.684+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:52:00.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.616 seconds
[2025-09-30T18:52:31.108+0000] {processor.py:157} INFO - Started process (PID=18423) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:52:31.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:52:31.110+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:31.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:52:31.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:52:32.056+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:32.055+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:52:32.086+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:52:32.086+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:52:32.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.004 seconds
[2025-09-30T18:53:02.221+0000] {processor.py:157} INFO - Started process (PID=18743) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:53:02.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:53:02.222+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:02.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:53:02.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:53:03.177+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:03.176+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:53:03.204+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:03.204+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:53:03.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.007 seconds
[2025-09-30T18:53:33.356+0000] {processor.py:157} INFO - Started process (PID=19060) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:53:33.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:53:33.358+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:33.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:53:33.896+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:53:34.395+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:34.394+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:53:34.441+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:53:34.441+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:53:34.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.123 seconds
[2025-09-30T18:54:05.117+0000] {processor.py:157} INFO - Started process (PID=19364) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:54:05.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:54:05.120+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:05.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:54:05.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:54:06.221+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:06.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:54:06.250+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:06.250+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:54:06.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.160 seconds
[2025-09-30T18:54:36.406+0000] {processor.py:157} INFO - Started process (PID=19681) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:54:36.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:54:36.408+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:36.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:54:36.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:54:38.300+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:38.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:54:38.333+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:54:38.333+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:54:38.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.955 seconds
[2025-09-30T18:55:08.793+0000] {processor.py:157} INFO - Started process (PID=19998) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:55:08.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:55:08.795+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:08.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:55:09.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:55:10.536+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:10.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:55:10.564+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:10.564+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:55:10.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.810 seconds
[2025-09-30T18:55:41.041+0000] {processor.py:157} INFO - Started process (PID=20320) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:55:41.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:55:41.043+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:41.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:55:41.650+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:55:41.674+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:41.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:55:41.700+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:55:41.700+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:55:41.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.684 seconds
[2025-09-30T18:56:11.858+0000] {processor.py:157} INFO - Started process (PID=20630) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:56:11.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:56:11.860+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:11.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:56:12.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:56:12.473+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:12.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:56:12.508+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:12.508+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:56:12.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.675 seconds
[2025-09-30T18:56:43.345+0000] {processor.py:157} INFO - Started process (PID=20941) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:56:43.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:56:43.347+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:56:43.347+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:56:43.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:56:44.936+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T18:57:15.313+0000] {processor.py:157} INFO - Started process (PID=21253) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:57:15.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:57:15.315+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:15.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:57:15.783+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:57:16.801+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:16.800+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:57:16.837+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:16.836+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:57:16.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.550 seconds
[2025-09-30T18:57:47.780+0000] {processor.py:157} INFO - Started process (PID=21565) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:57:47.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:57:47.782+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:47.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:57:48.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:57:48.256+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:48.256+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:57:48.287+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:57:48.287+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:57:48.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.532 seconds
[2025-09-30T18:58:18.474+0000] {processor.py:157} INFO - Started process (PID=21877) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:58:18.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:58:18.476+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:18.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:58:18.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:58:18.957+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:18.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:58:18.987+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:18.987+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:58:19.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.540 seconds
[2025-09-30T18:58:49.251+0000] {processor.py:157} INFO - Started process (PID=22187) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:58:49.252+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:58:49.253+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:49.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:58:49.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:58:49.774+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:49.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:58:49.816+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:58:49.816+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:58:49.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.596 seconds
[2025-09-30T18:59:20.441+0000] {processor.py:157} INFO - Started process (PID=22496) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:59:20.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:59:20.443+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:20.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:59:20.877+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:59:20.902+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:20.902+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:59:20.936+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:20.936+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:59:20.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.521 seconds
[2025-09-30T18:59:51.776+0000] {processor.py:157} INFO - Started process (PID=22803) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:59:51.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T18:59:51.778+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:51.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:59:52.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T18:59:52.287+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:52.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T18:59:52.318+0000] {logging_mixin.py:149} INFO - [2025-09-30T18:59:52.318+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T18:59:52.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.567 seconds
[2025-09-30T19:00:23.010+0000] {processor.py:157} INFO - Started process (PID=23110) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:00:23.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:00:23.012+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:23.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:00:23.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:00:23.492+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:23.491+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:00:23.522+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:23.522+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:00:23.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.537 seconds
[2025-09-30T19:00:53.820+0000] {processor.py:157} INFO - Started process (PID=23417) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:00:53.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:00:53.822+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:53.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:00:54.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:00:54.275+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:54.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:00:54.306+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:00:54.305+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:00:54.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.510 seconds
[2025-09-30T19:01:24.575+0000] {processor.py:157} INFO - Started process (PID=23724) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:01:24.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:01:24.577+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:24.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:01:24.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:01:25.017+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:25.017+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:01:25.051+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:25.051+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:01:25.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.504 seconds
[2025-09-30T19:01:55.247+0000] {processor.py:157} INFO - Started process (PID=24031) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:01:55.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:01:55.249+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:55.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:01:55.720+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:01:57.130+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:57.130+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:01:57.163+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:01:57.163+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:01:57.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.941 seconds
[2025-09-30T19:02:27.265+0000] {processor.py:157} INFO - Started process (PID=24346) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:02:27.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:02:27.269+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:27.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:02:27.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:02:28.836+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:28.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:02:28.873+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:28.873+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:02:29.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.767 seconds
[2025-09-30T19:02:59.081+0000] {processor.py:157} INFO - Started process (PID=24655) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:02:59.082+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:02:59.083+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:59.083+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:02:59.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:02:59.759+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:59.759+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:02:59.789+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:02:59.789+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:02:59.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.735 seconds
[2025-09-30T19:03:30.138+0000] {processor.py:157} INFO - Started process (PID=24962) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:03:30.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:03:30.141+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:30.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:03:30.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:03:31.092+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:31.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:03:31.121+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:03:31.121+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:03:31.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.010 seconds
[2025-09-30T19:04:01.675+0000] {processor.py:157} INFO - Started process (PID=25279) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:04:01.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:04:01.676+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:01.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:04:02.222+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:04:03.097+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:03.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:04:03.123+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:03.123+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:04:03.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.474 seconds
[2025-09-30T19:04:33.503+0000] {processor.py:157} INFO - Started process (PID=25596) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:04:33.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:04:33.505+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:33.504+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:04:34.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:04:34.060+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:34.059+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:04:34.089+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:04:34.089+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:04:34.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.611 seconds
[2025-09-30T19:05:04.183+0000] {processor.py:157} INFO - Started process (PID=25898) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:05:04.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:05:04.186+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:04.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:05:04.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:05:04.771+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:04.771+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:05:04.798+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:04.798+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:05:04.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.639 seconds
[2025-09-30T19:05:35.174+0000] {processor.py:157} INFO - Started process (PID=26205) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:05:35.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:05:35.176+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:05:35.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:05:35.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:05:36.461+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:06:07.341+0000] {processor.py:157} INFO - Started process (PID=26517) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:06:07.342+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:06:07.343+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:07.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:06:07.896+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:06:08.132+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:06:38.699+0000] {processor.py:157} INFO - Started process (PID=26824) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:06:38.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:06:38.701+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:06:38.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:06:39.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:06:40.341+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:07:10.789+0000] {processor.py:157} INFO - Started process (PID=27131) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:07:10.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:07:10.791+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:10.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:07:11.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:07:11.569+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:11.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:07:11.595+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:11.595+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:07:11.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.831 seconds
[2025-09-30T19:07:41.876+0000] {processor.py:157} INFO - Started process (PID=27438) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:07:41.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:07:41.879+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:41.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:07:42.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:07:42.588+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:42.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:07:42.615+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:07:42.614+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:07:42.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.765 seconds
[2025-09-30T19:08:12.836+0000] {processor.py:157} INFO - Started process (PID=27745) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:08:12.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:08:12.838+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:12.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:08:13.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:08:13.385+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:13.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:08:13.413+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:13.412+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:08:13.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.600 seconds
[2025-09-30T19:08:44.365+0000] {processor.py:157} INFO - Started process (PID=28052) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:08:44.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:08:44.367+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:44.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:08:44.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:08:45.588+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:45.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:08:45.614+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:08:45.614+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:08:45.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.272 seconds
[2025-09-30T19:09:15.899+0000] {processor.py:157} INFO - Started process (PID=28366) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:09:15.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:09:15.902+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:15.902+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:09:16.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:09:16.911+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:16.910+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:09:16.941+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:16.941+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:09:16.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.066 seconds
[2025-09-30T19:09:47.048+0000] {processor.py:157} INFO - Started process (PID=28673) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:09:47.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:09:47.050+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:47.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:09:47.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:09:48.682+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:48.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:09:48.709+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:09:48.709+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:09:48.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.685 seconds
[2025-09-30T19:10:19.069+0000] {processor.py:157} INFO - Started process (PID=28980) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:10:19.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:10:19.071+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:19.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:10:19.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:10:19.666+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:19.666+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:10:19.694+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:19.694+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:10:19.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.652 seconds
[2025-09-30T19:10:50.518+0000] {processor.py:157} INFO - Started process (PID=29287) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:10:50.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:10:50.519+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:10:50.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:10:51.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:10:51.540+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:11:22.373+0000] {processor.py:157} INFO - Started process (PID=29599) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:11:22.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:11:22.375+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:22.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:11:22.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:11:22.974+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:22.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:11:23.003+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:23.003+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:11:23.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.655 seconds
[2025-09-30T19:11:53.800+0000] {processor.py:157} INFO - Started process (PID=29911) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:11:53.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:11:53.802+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:53.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:11:54.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:11:54.374+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:54.373+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:11:54.403+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:11:54.402+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:11:54.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.627 seconds
[2025-09-30T19:12:25.199+0000] {processor.py:157} INFO - Started process (PID=30218) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:12:25.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:12:25.202+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:25.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:12:25.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:12:25.778+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:25.777+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:12:25.804+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:25.804+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:12:25.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.628 seconds
[2025-09-30T19:12:56.071+0000] {processor.py:157} INFO - Started process (PID=30525) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:12:56.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:12:56.073+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:12:56.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:12:56.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:12:57.714+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:13:28.188+0000] {processor.py:157} INFO - Started process (PID=30837) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:13:28.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:13:28.190+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:28.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:13:28.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:13:29.109+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:29.108+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:13:29.134+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:29.134+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:13:29.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.968 seconds
[2025-09-30T19:13:59.548+0000] {processor.py:157} INFO - Started process (PID=31144) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:13:59.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:13:59.550+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:13:59.550+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:14:00.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:14:00.124+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:00.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:14:00.156+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:00.156+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:14:00.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.647 seconds
[2025-09-30T19:14:30.923+0000] {processor.py:157} INFO - Started process (PID=31451) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:14:30.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:14:30.925+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:14:30.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:14:31.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:14:32.048+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:15:02.207+0000] {processor.py:157} INFO - Started process (PID=31763) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:15:02.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:15:02.209+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:02.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:15:02.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:15:02.795+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:02.794+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:15:02.822+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:02.822+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:15:02.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.639 seconds
[2025-09-30T19:15:33.253+0000] {processor.py:157} INFO - Started process (PID=32075) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:15:33.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:15:33.255+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:33.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:15:33.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:15:33.906+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:33.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:15:33.936+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:15:33.936+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:15:33.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.708 seconds
[2025-09-30T19:16:04.275+0000] {processor.py:157} INFO - Started process (PID=32382) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:16:04.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:16:04.278+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:04.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:16:04.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:16:05.060+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:05.060+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:16:05.090+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:05.090+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:16:05.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.840 seconds
[2025-09-30T19:16:35.207+0000] {processor.py:157} INFO - Started process (PID=32702) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:16:35.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:16:35.209+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:35.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:16:35.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:16:35.702+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:35.701+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:16:35.739+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:16:35.739+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:16:35.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.555 seconds
[2025-09-30T19:17:06.127+0000] {processor.py:157} INFO - Started process (PID=33009) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:17:06.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:17:06.130+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:06.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:17:06.877+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:17:07.138+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:07.136+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:17:07.263+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:07.263+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:17:07.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.205 seconds
[2025-09-30T19:17:37.479+0000] {processor.py:157} INFO - Started process (PID=33318) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:17:37.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:17:37.481+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:17:37.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:17:37.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:17:38.335+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:18:08.422+0000] {processor.py:157} INFO - Started process (PID=33633) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:18:08.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:18:08.424+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:08.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:18:08.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:18:09.343+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:09.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:18:09.376+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:09.375+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:18:09.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.979 seconds
[2025-09-30T19:18:39.704+0000] {processor.py:157} INFO - Started process (PID=33940) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:18:39.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:18:39.706+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:39.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:18:40.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:18:40.480+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:40.480+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:18:40.511+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:18:40.511+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:18:40.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.835 seconds
[2025-09-30T19:19:11.116+0000] {processor.py:157} INFO - Started process (PID=34247) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:19:11.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:19:11.118+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:11.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:19:11.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:19:11.711+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:11.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:19:11.743+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:11.742+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:19:11.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.652 seconds
[2025-09-30T19:19:41.888+0000] {processor.py:157} INFO - Started process (PID=34551) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:19:41.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:19:41.890+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:41.890+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:19:42.342+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:19:42.704+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:42.703+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:19:42.736+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:19:42.736+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:19:42.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.872 seconds
[2025-09-30T19:20:13.069+0000] {processor.py:157} INFO - Started process (PID=34858) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:20:13.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:20:13.072+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:13.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:20:13.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:20:13.631+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:13.630+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:20:13.658+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:13.658+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:20:13.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.615 seconds
[2025-09-30T19:20:44.115+0000] {processor.py:157} INFO - Started process (PID=35163) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:20:44.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:20:44.117+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:44.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:20:44.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:20:45.131+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:45.130+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:20:45.158+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:20:45.158+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:20:45.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.072 seconds
[2025-09-30T19:21:15.684+0000] {processor.py:157} INFO - Started process (PID=35477) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:21:15.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:21:15.686+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:15.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:21:16.240+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:21:16.265+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:16.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:21:16.293+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:16.293+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:21:16.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.633 seconds
[2025-09-30T19:21:46.768+0000] {processor.py:157} INFO - Started process (PID=35793) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:21:46.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:21:46.770+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:46.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:21:47.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:21:47.313+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:47.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:21:47.339+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:21:47.339+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:21:47.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.594 seconds
[2025-09-30T19:22:17.449+0000] {processor.py:157} INFO - Started process (PID=36098) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:22:17.453+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:22:17.454+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:17.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:22:18.013+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:22:18.140+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:18.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:22:18.167+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:18.167+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:22:18.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.743 seconds
[2025-09-30T19:22:48.390+0000] {processor.py:157} INFO - Started process (PID=36415) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:22:48.394+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:22:48.395+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:48.395+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:22:48.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:22:48.972+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:48.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:22:48.999+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:22:48.998+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:22:49.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.632 seconds
[2025-09-30T19:23:19.124+0000] {processor.py:157} INFO - Started process (PID=36720) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:23:19.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:23:19.126+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:19.125+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:23:19.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:23:19.682+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:19.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:23:19.707+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:19.707+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:23:19.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.608 seconds
[2025-09-30T19:23:49.871+0000] {processor.py:157} INFO - Started process (PID=37024) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:23:49.872+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:23:49.873+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:49.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:23:50.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:23:50.465+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:50.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:23:50.505+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:23:50.505+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:23:50.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.673 seconds
[2025-09-30T19:24:21.176+0000] {processor.py:157} INFO - Started process (PID=37331) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:24:21.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:24:21.179+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:21.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:24:21.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:24:21.763+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:21.762+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:24:21.789+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:21.789+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:24:21.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.639 seconds
[2025-09-30T19:24:51.942+0000] {processor.py:157} INFO - Started process (PID=37643) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:24:51.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:24:51.944+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:51.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:24:52.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:24:52.599+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:52.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:24:52.626+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:24:52.626+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:24:52.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.708 seconds
[2025-09-30T19:25:22.855+0000] {processor.py:157} INFO - Started process (PID=37945) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:25:22.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:25:22.857+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:22.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:25:23.482+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:25:23.903+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:23.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:25:23.932+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:23.932+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:25:23.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.099 seconds
[2025-09-30T19:25:54.298+0000] {processor.py:157} INFO - Started process (PID=38265) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:25:54.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:25:54.299+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:54.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:25:54.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:25:55.853+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:55.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:25:55.883+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:25:55.883+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:25:55.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.607 seconds
[2025-09-30T19:26:26.299+0000] {processor.py:157} INFO - Started process (PID=38579) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:26:26.301+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:26:26.302+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:26.301+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:26:26.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:26:26.910+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:26.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:26:26.942+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:26.942+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:26:26.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.667 seconds
[2025-09-30T19:26:57.041+0000] {processor.py:157} INFO - Started process (PID=38891) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:26:57.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:26:57.045+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:57.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:26:57.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:26:58.568+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:58.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:26:58.603+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:26:58.603+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:26:58.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.597 seconds
[2025-09-30T19:27:29.088+0000] {processor.py:157} INFO - Started process (PID=39198) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:27:29.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:27:29.090+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:29.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:27:29.614+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:27:29.641+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:29.640+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:27:29.669+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:27:29.669+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:27:29.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.606 seconds
[2025-09-30T19:28:00.364+0000] {processor.py:157} INFO - Started process (PID=39505) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:28:00.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:28:00.367+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:00.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:28:00.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:28:00.985+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:00.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:28:01.011+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:01.011+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:28:01.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.672 seconds
[2025-09-30T19:28:31.272+0000] {processor.py:157} INFO - Started process (PID=39812) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:28:31.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:28:31.274+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:31.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:28:31.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:28:32.684+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:32.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:28:32.721+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:28:32.721+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:28:32.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.474 seconds
[2025-09-30T19:29:02.921+0000] {processor.py:157} INFO - Started process (PID=40124) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:29:02.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:29:02.924+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:02.923+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:29:03.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:29:04.468+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:04.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:29:04.496+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:04.495+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:29:04.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.601 seconds
[2025-09-30T19:29:35.284+0000] {processor.py:157} INFO - Started process (PID=40476) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:29:35.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:29:35.285+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:35.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:29:35.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:29:36.414+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:36.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:29:36.443+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:29:36.443+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:29:36.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.188 seconds
[2025-09-30T19:30:06.995+0000] {processor.py:157} INFO - Started process (PID=40791) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:30:06.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:30:06.997+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:06.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:30:07.525+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:30:07.990+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:07.990+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:30:08.017+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:08.017+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:30:08.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.046 seconds
[2025-09-30T19:30:38.189+0000] {processor.py:157} INFO - Started process (PID=41104) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:30:38.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:30:38.191+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:38.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:30:38.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:30:38.939+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:38.938+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:30:38.971+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:30:38.971+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:30:38.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.811 seconds
[2025-09-30T19:31:09.663+0000] {processor.py:157} INFO - Started process (PID=41411) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:31:09.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:31:09.665+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:09.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:31:10.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:31:10.123+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:10.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:31:10.154+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:10.154+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:31:10.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.515 seconds
[2025-09-30T19:31:40.493+0000] {processor.py:157} INFO - Started process (PID=41718) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:31:40.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:31:40.495+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:40.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:31:41.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:31:41.033+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:41.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:31:41.066+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:31:41.066+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:31:41.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.605 seconds
[2025-09-30T19:32:11.165+0000] {processor.py:157} INFO - Started process (PID=42025) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:32:11.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:32:11.167+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:11.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:32:11.700+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:32:11.727+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:11.726+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:32:11.760+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:11.760+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:32:11.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.630 seconds
[2025-09-30T19:32:41.933+0000] {processor.py:157} INFO - Started process (PID=42332) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:32:41.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:32:41.935+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:41.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:32:42.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:32:42.393+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:42.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:32:42.424+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:32:42.424+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:32:42.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.521 seconds
[2025-09-30T19:33:12.623+0000] {processor.py:157} INFO - Started process (PID=42639) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:33:12.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:33:12.626+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:12.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:33:13.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:33:13.077+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:13.077+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:33:13.106+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:13.106+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:33:13.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.507 seconds
[2025-09-30T19:33:43.446+0000] {processor.py:157} INFO - Started process (PID=42941) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:33:43.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:33:43.448+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:43.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:33:43.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:33:44.863+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:44.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:33:44.894+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:33:44.894+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:33:44.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.479 seconds
[2025-09-30T19:34:15.384+0000] {processor.py:157} INFO - Started process (PID=43258) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:34:15.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:34:15.386+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:15.386+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:34:15.807+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:34:15.833+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:15.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:34:15.861+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:15.861+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:34:15.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.501 seconds
[2025-09-30T19:34:46.030+0000] {processor.py:157} INFO - Started process (PID=43560) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:34:46.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:34:46.033+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:46.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:34:46.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:34:46.484+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:46.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:34:46.513+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:34:46.513+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:34:46.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.509 seconds
[2025-09-30T19:35:17.449+0000] {processor.py:157} INFO - Started process (PID=43872) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:35:17.451+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:35:17.452+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:17.452+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:35:17.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:35:17.889+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:17.888+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:35:17.917+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:17.917+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:35:17.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.493 seconds
[2025-09-30T19:35:48.321+0000] {processor.py:157} INFO - Started process (PID=44179) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:35:48.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:35:48.323+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:48.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:35:48.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:35:48.785+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:48.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:35:48.934+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:35:48.934+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:35:48.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.640 seconds
[2025-09-30T19:36:19.337+0000] {processor.py:157} INFO - Started process (PID=44493) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:36:19.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:36:19.339+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:19.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:36:19.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:36:19.902+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:19.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:36:19.928+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:19.928+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:36:19.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.615 seconds
[2025-09-30T19:36:50.075+0000] {processor.py:157} INFO - Started process (PID=44800) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:36:50.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:36:50.077+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:36:50.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:36:50.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:36:51.302+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:37:22.322+0000] {processor.py:157} INFO - Started process (PID=45112) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:37:22.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:37:22.325+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:22.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:37:22.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:37:24.098+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:24.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:37:24.126+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:24.126+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:37:24.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.830 seconds
[2025-09-30T19:37:54.541+0000] {processor.py:157} INFO - Started process (PID=45434) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:37:54.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:37:54.543+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:54.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:37:55.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:37:55.103+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:55.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:37:55.131+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:37:55.131+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:37:55.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.614 seconds
[2025-09-30T19:38:25.447+0000] {processor.py:157} INFO - Started process (PID=45741) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:38:25.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:38:25.449+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:25.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:38:25.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:38:26.311+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-30T19:38:56.389+0000] {processor.py:157} INFO - Started process (PID=46046) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:38:56.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:38:56.391+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:56.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:38:56.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:38:57.311+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:57.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:38:57.337+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:38:57.337+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:38:57.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.973 seconds
[2025-09-30T19:39:27.560+0000] {processor.py:157} INFO - Started process (PID=46355) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:39:27.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:39:27.562+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:27.562+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:39:28.089+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:39:28.112+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:28.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:39:28.143+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:28.143+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:39:28.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.606 seconds
[2025-09-30T19:39:58.729+0000] {processor.py:157} INFO - Started process (PID=46662) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:39:58.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:39:58.731+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:58.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:39:59.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:39:59.581+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:59.580+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:39:59.607+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:39:59.607+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:39:59.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.904 seconds
[2025-09-30T19:40:30.080+0000] {processor.py:157} INFO - Started process (PID=46969) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:40:30.082+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:40:30.082+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:30.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:40:30.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:40:30.978+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:30.977+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:40:31.004+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:40:31.004+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:40:31.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.947 seconds
[2025-09-30T19:41:01.064+0000] {processor.py:157} INFO - Started process (PID=47276) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:41:01.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:41:01.067+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:01.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:41:01.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:41:01.639+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:01.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:41:01.664+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:01.664+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:41:01.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.626 seconds
[2025-09-30T19:41:31.965+0000] {processor.py:157} INFO - Started process (PID=47583) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:41:31.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:41:31.967+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:31.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:41:32.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:41:32.744+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:32.744+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:41:32.770+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:41:32.770+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:41:32.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.830 seconds
[2025-09-30T19:42:03.114+0000] {processor.py:157} INFO - Started process (PID=47890) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:42:03.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-30T19:42:03.116+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:42:03.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:42:03.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-30T19:42:03.705+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:42:03.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-30T19:42:03.731+0000] {logging_mixin.py:149} INFO - [2025-09-30T19:42:03.731+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-30T10:00:00+00:00, run_after=2025-10-01T10:00:00+00:00
[2025-09-30T19:42:03.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.640 seconds
