[2025-10-03T06:22:58.180+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:22:58.183+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:22:58.187+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:22:58.187+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:22:59.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:23:00.124+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:00.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:23:00.197+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:00.196+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:23:00.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.064 seconds
[2025-10-03T06:23:30.575+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:23:30.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:23:30.578+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:30.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:23:31.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:23:31.356+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:31.355+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:23:31.392+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:31.392+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:23:31.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.843 seconds
[2025-10-03T06:24:01.895+0000] {processor.py:157} INFO - Started process (PID=820) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:24:01.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:24:01.899+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:01.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:24:02.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:24:02.380+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:02.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:24:02.409+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:02.409+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:24:02.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.542 seconds
[2025-10-03T06:24:32.535+0000] {processor.py:157} INFO - Started process (PID=1124) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:24:32.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:24:32.537+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:32.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:24:33.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:24:34.194+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:25:04.761+0000] {processor.py:157} INFO - Started process (PID=1442) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:25:04.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:25:04.771+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:04.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:25:05.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:25:05.629+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:05.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:25:05.671+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:05.671+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:25:05.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.961 seconds
[2025-10-03T06:25:36.153+0000] {processor.py:157} INFO - Started process (PID=1742) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:25:36.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:25:36.156+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:36.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:25:36.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:25:36.771+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:36.771+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:25:36.821+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:36.820+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:25:36.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.735 seconds
[2025-10-03T06:26:07.241+0000] {processor.py:157} INFO - Started process (PID=2049) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:26:07.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:26:07.242+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:26:07.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:26:07.837+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:26:07.866+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.866+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:26:07.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.651 seconds
[2025-10-03T06:26:38.383+0000] {processor.py:157} INFO - Started process (PID=2356) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:26:38.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:26:38.386+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:38.386+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:26:38.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:26:39.246+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:39.246+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:26:39.276+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:39.276+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:26:39.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.918 seconds
[2025-10-03T06:27:09.494+0000] {processor.py:157} INFO - Started process (PID=2663) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:27:09.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:27:09.499+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:09.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:27:09.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:27:09.962+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:09.962+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:27:09.990+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:09.990+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:27:10.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.522 seconds
[2025-10-03T06:27:40.418+0000] {processor.py:157} INFO - Started process (PID=2970) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:27:40.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:27:40.421+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:40.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:27:40.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:27:41.138+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:41.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:27:41.171+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:41.171+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:27:41.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.781 seconds
[2025-10-03T06:28:11.982+0000] {processor.py:157} INFO - Started process (PID=3284) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:28:11.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:28:11.985+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:11.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:28:12.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:28:12.462+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:12.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:28:12.492+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:12.492+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:28:12.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.535 seconds
[2025-10-03T06:28:42.662+0000] {processor.py:157} INFO - Started process (PID=3588) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:28:42.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:28:42.664+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:42.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:28:43.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:28:43.111+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.110+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:28:43.141+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.141+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:28:43.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.504 seconds
[2025-10-03T06:29:13.354+0000] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:29:13.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:29:13.355+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:13.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:29:13.794+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:29:15.090+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:15.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:29:15.138+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:15.138+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:29:15.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.952 seconds
[2025-10-03T06:29:45.565+0000] {processor.py:157} INFO - Started process (PID=4205) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:29:45.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:29:45.569+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:45.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:29:46.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:29:46.081+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:46.081+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:29:46.116+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:46.116+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:29:46.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.580 seconds
[2025-10-03T06:30:16.668+0000] {processor.py:157} INFO - Started process (PID=4512) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:30:16.670+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:30:16.671+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:16.671+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:30:17.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:30:17.305+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:17.304+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:30:17.341+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:17.341+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:30:17.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.699 seconds
[2025-10-03T06:30:47.794+0000] {processor.py:157} INFO - Started process (PID=4819) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:30:47.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:30:47.797+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:47.797+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:30:48.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:30:48.542+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:48.542+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:30:48.573+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:48.572+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:30:48.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.803 seconds
[2025-10-03T06:31:18.758+0000] {processor.py:157} INFO - Started process (PID=5123) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:31:18.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:31:18.761+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:18.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:31:19.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:31:20.066+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.065+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:31:20.093+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.093+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:31:20.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.359 seconds
[2025-10-03T06:31:50.340+0000] {processor.py:157} INFO - Started process (PID=5430) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:31:50.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:31:50.342+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:50.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:31:50.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:31:51.317+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:32:21.915+0000] {processor.py:157} INFO - Started process (PID=5747) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:32:21.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:32:21.917+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:21.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:32:22.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:32:22.620+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:22.619+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:32:22.646+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:22.646+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:32:22.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.753 seconds
[2025-10-03T06:32:53.122+0000] {processor.py:157} INFO - Started process (PID=6054) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:32:53.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:32:53.124+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:53.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:32:53.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:32:53.975+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:53.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:32:54.001+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:54.001+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:32:54.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.905 seconds
[2025-10-03T06:33:24.471+0000] {processor.py:157} INFO - Started process (PID=6361) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:33:24.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:33:24.473+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:24.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:33:24.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:33:25.546+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:25.545+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:33:25.620+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:25.619+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:33:25.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.185 seconds
[2025-10-03T06:33:55.770+0000] {processor.py:157} INFO - Started process (PID=6678) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:33:55.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:33:55.771+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:55.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:33:56.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:33:56.733+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:56.732+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:33:56.766+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:56.766+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:33:56.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.020 seconds
[2025-10-03T06:34:27.289+0000] {processor.py:157} INFO - Started process (PID=6985) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:34:27.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:34:27.291+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:27.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:34:27.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:34:27.848+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:27.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:34:27.875+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:27.875+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:34:27.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.610 seconds
[2025-10-03T06:34:58.130+0000] {processor.py:157} INFO - Started process (PID=7292) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:34:58.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:34:58.132+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:58.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:34:58.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:34:59.792+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:35:30.295+0000] {processor.py:157} INFO - Started process (PID=7599) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:35:30.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:35:30.297+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:30.296+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:35:30.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:35:31.922+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:31.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:35:31.948+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:31.948+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:35:31.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.678 seconds
[2025-10-03T06:36:02.691+0000] {processor.py:157} INFO - Started process (PID=7909) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:36:02.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:36:02.694+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:02.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:36:03.510+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:36:03.548+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:03.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:36:03.592+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:03.592+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:36:03.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.940 seconds
[2025-10-03T06:36:34.042+0000] {processor.py:157} INFO - Started process (PID=8216) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:36:34.043+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:36:34.044+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:34.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:36:34.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:36:34.618+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:34.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:36:34.646+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:34.646+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:36:34.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.627 seconds
[2025-10-03T06:37:05.075+0000] {processor.py:157} INFO - Started process (PID=8520) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:37:05.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:37:05.076+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:05.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:37:05.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:37:06.762+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:37:37.068+0000] {processor.py:157} INFO - Started process (PID=8840) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:37:37.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:37:37.070+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:37.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:37:37.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:37:38.443+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:38:08.656+0000] {processor.py:157} INFO - Started process (PID=9145) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:38:08.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:38:08.661+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:08.660+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:38:09.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:38:09.362+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:09.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:38:09.387+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:09.387+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:38:09.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.755 seconds
[2025-10-03T06:38:39.542+0000] {processor.py:157} INFO - Started process (PID=9454) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:38:39.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:38:39.544+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:39.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:38:40.072+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:38:41.449+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:41.449+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:38:41.475+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:41.475+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:38:41.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.957 seconds
[2025-10-03T06:39:11.721+0000] {processor.py:157} INFO - Started process (PID=9766) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:39:11.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:39:11.723+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:11.723+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:39:12.218+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:39:13.154+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:13.153+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:39:13.183+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:13.183+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:39:13.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.492 seconds
[2025-10-03T06:39:43.720+0000] {processor.py:157} INFO - Started process (PID=10101) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:39:43.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:39:43.722+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:43.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:39:44.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:39:44.201+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:44.200+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:39:44.231+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:44.231+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:39:44.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.537 seconds
[2025-10-03T06:40:14.292+0000] {processor.py:157} INFO - Started process (PID=10387) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:40:14.293+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:40:14.294+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:14.293+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:40:14.744+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:40:14.770+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:14.770+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:40:14.800+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:14.800+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:40:14.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.534 seconds
[2025-10-03T06:40:45.242+0000] {processor.py:157} INFO - Started process (PID=10694) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:40:45.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:40:45.246+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:45.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:40:45.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:40:45.762+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:45.762+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:40:45.806+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:45.806+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:40:45.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.595 seconds
[2025-10-03T06:41:16.451+0000] {processor.py:157} INFO - Started process (PID=11001) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:41:16.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:41:16.454+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:16.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:41:16.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:41:17.556+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:41:47.766+0000] {processor.py:157} INFO - Started process (PID=11326) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:41:47.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:41:47.768+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:47.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:41:48.200+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:41:48.225+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:48.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:41:48.264+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:48.264+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:41:48.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.522 seconds
[2025-10-03T06:42:18.806+0000] {processor.py:157} INFO - Started process (PID=11631) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:42:18.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:42:18.808+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:18.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:42:19.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:42:19.531+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:19.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:42:19.562+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:19.561+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:42:19.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.782 seconds
[2025-10-03T06:42:49.714+0000] {processor.py:157} INFO - Started process (PID=11927) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:42:49.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:42:49.716+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:49.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:42:50.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:42:50.209+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:50.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:42:50.239+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:50.238+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:42:50.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.549 seconds
[2025-10-03T06:43:20.420+0000] {processor.py:157} INFO - Started process (PID=12234) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:43:20.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:43:20.422+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:20.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:43:20.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:43:21.309+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:21.308+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:43:21.444+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:21.444+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:43:21.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.054 seconds
[2025-10-03T06:43:51.523+0000] {processor.py:157} INFO - Started process (PID=12540) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:43:51.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:43:51.525+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:51.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:43:51.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:43:52.082+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:52.081+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:43:52.115+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:52.115+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:43:52.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-10-03T06:44:22.631+0000] {processor.py:157} INFO - Started process (PID=12847) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:44:22.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:44:22.634+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:22.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:44:23.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:44:23.920+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:44:54.103+0000] {processor.py:157} INFO - Started process (PID=13154) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:44:54.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:44:54.107+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:54.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:44:54.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:44:56.029+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:45:26.533+0000] {processor.py:157} INFO - Started process (PID=13482) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:45:26.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:45:26.535+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:26.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:45:27.108+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:45:27.478+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:27.477+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:45:27.505+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:27.504+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:45:27.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.998 seconds
[2025-10-03T06:45:58.423+0000] {processor.py:157} INFO - Started process (PID=13791) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:45:58.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:45:58.426+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:58.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:45:59.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:46:00.170+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:00.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:46:00.197+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:00.197+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:46:00.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.797 seconds
[2025-10-03T06:46:30.410+0000] {processor.py:157} INFO - Started process (PID=14111) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:46:30.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:46:30.412+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:30.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:46:30.995+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:46:31.187+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:31.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:46:31.214+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:31.214+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:46:31.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.832 seconds
[2025-10-03T06:47:01.722+0000] {processor.py:157} INFO - Started process (PID=14433) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:47:01.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:47:01.724+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:01.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:47:02.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:47:03.547+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:03.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:47:03.576+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:03.576+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:47:03.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.879 seconds
[2025-10-03T06:47:33.716+0000] {processor.py:157} INFO - Started process (PID=14765) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:47:33.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:47:33.718+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:33.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:47:34.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:47:34.715+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:34.714+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:47:34.746+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:34.745+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:47:34.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.056 seconds
[2025-10-03T06:48:05.225+0000] {processor.py:157} INFO - Started process (PID=15069) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:48:05.227+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:48:05.228+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:05.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:48:05.833+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:48:05.873+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:05.872+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:48:05.915+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:05.914+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:48:05.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.731 seconds
[2025-10-03T06:48:36.595+0000] {processor.py:157} INFO - Started process (PID=15376) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:48:36.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:48:36.597+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:36.597+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:48:37.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:48:37.506+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:37.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:48:37.534+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:37.534+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:48:37.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.964 seconds
[2025-10-03T06:49:08.224+0000] {processor.py:157} INFO - Started process (PID=15688) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:49:08.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:49:08.226+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:08.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:49:08.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:49:08.831+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:08.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:49:08.865+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:08.865+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:49:08.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.672 seconds
[2025-10-03T06:49:39.501+0000] {processor.py:157} INFO - Started process (PID=15995) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:49:39.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:49:39.503+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:39.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:49:40.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:49:40.570+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:40.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:49:40.601+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:40.601+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:49:40.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.131 seconds
[2025-10-03T06:50:10.719+0000] {processor.py:157} INFO - Started process (PID=16325) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:50:10.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:50:10.721+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:10.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:50:11.245+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:50:11.540+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:11.539+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:50:11.571+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:11.571+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:50:11.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.878 seconds
[2025-10-03T06:50:41.948+0000] {processor.py:157} INFO - Started process (PID=16634) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:50:41.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:50:41.950+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:41.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:50:42.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:50:42.531+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:42.531+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:50:42.563+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:42.563+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:50:42.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.646 seconds
[2025-10-03T06:51:13.382+0000] {processor.py:157} INFO - Started process (PID=16946) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:51:13.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:51:13.384+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:13.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:51:13.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:51:14.084+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:14.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:51:14.114+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:14.114+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:51:14.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.756 seconds
[2025-10-03T06:51:44.562+0000] {processor.py:157} INFO - Started process (PID=17253) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:51:44.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:51:44.564+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:44.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:51:45.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:51:45.128+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:45.128+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:51:45.155+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:45.155+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:51:45.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-10-03T06:52:15.438+0000] {processor.py:157} INFO - Started process (PID=17567) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:52:15.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:52:15.440+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:15.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:52:16.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:52:16.051+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:16.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:52:16.083+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:16.083+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:52:16.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.682 seconds
[2025-10-03T06:52:46.508+0000] {processor.py:157} INFO - Started process (PID=17874) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:52:46.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:52:46.510+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:46.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:52:47.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:52:47.747+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:47.746+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:52:47.775+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:47.775+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:52:47.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.290 seconds
[2025-10-03T06:53:17.900+0000] {processor.py:157} INFO - Started process (PID=18186) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:53:17.901+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:53:17.902+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:17.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:53:18.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:53:19.707+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:53:49.855+0000] {processor.py:157} INFO - Started process (PID=18501) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:53:49.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:53:49.857+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:49.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:53:50.399+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:53:50.420+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:50.420+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:53:50.446+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:50.446+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:53:50.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.614 seconds
[2025-10-03T06:54:20.975+0000] {processor.py:157} INFO - Started process (PID=18808) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:54:20.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:54:20.978+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:20.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:54:21.549+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:54:21.574+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:21.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:54:21.605+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:21.605+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:54:21.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.657 seconds
[2025-10-03T06:54:52.546+0000] {processor.py:157} INFO - Started process (PID=19117) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:54:52.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:54:52.548+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:52.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:54:52.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:54:53.022+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:53.021+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:54:53.054+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:53.053+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:54:53.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.534 seconds
[2025-10-03T06:55:23.399+0000] {processor.py:157} INFO - Started process (PID=19424) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:55:23.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:55:23.401+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:23.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:55:23.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:55:23.852+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:23.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:55:23.884+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:23.884+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:55:23.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.513 seconds
[2025-10-03T06:55:54.228+0000] {processor.py:157} INFO - Started process (PID=19729) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:55:54.230+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:55:54.231+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:54.231+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:55:54.670+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:55:55.779+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:55.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:55:55.808+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:55.808+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:55:55.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.605 seconds
[2025-10-03T06:56:26.081+0000] {processor.py:157} INFO - Started process (PID=20048) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:56:26.082+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:56:26.084+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:26.084+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:56:26.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:56:27.702+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:27.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:56:27.740+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:27.740+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:56:27.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.684 seconds
[2025-10-03T06:56:57.881+0000] {processor.py:157} INFO - Started process (PID=20358) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:56:57.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:56:57.883+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:57.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:56:58.321+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:56:59.012+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:59.012+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:56:59.043+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:59.043+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:56:59.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.191 seconds
[2025-10-03T06:57:29.199+0000] {processor.py:157} INFO - Started process (PID=20667) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:57:29.200+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:57:29.200+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:29.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:57:29.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:57:29.637+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:29.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:57:29.668+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:29.668+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:57:29.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.494 seconds
[2025-10-03T06:57:59.994+0000] {processor.py:157} INFO - Started process (PID=20969) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:57:59.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:57:59.997+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:59.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:58:00.432+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:58:00.457+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:00.457+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:58:00.486+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:00.486+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:58:00.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.516 seconds
[2025-10-03T06:58:30.638+0000] {processor.py:157} INFO - Started process (PID=21275) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:58:30.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:58:30.640+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:30.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:58:31.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:58:31.846+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:31.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:58:31.878+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:31.878+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:58:31.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.264 seconds
[2025-10-03T06:59:01.934+0000] {processor.py:157} INFO - Started process (PID=21595) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:59:01.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:59:01.935+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:01.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:59:02.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:59:02.804+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:02.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:59:02.950+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:02.950+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T06:59:02.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.044 seconds
[2025-10-03T06:59:33.617+0000] {processor.py:157} INFO - Started process (PID=21904) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:59:33.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T06:59:33.619+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:33.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:59:34.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T06:59:35.558+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:00:06.169+0000] {processor.py:157} INFO - Started process (PID=22216) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:00:06.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:00:06.172+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:06.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:00:06.745+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:00:06.767+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:06.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:00:06.794+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:06.793+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:00:06.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.649 seconds
[2025-10-03T07:00:37.387+0000] {processor.py:157} INFO - Started process (PID=22521) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:00:37.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:00:37.389+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:37.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:00:37.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:00:37.995+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:37.995+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:00:38.033+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:38.033+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:00:38.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.676 seconds
[2025-10-03T07:01:08.889+0000] {processor.py:157} INFO - Started process (PID=22830) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:01:08.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:01:08.893+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:08.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:01:09.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:01:09.559+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:09.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:01:09.588+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:09.588+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:01:09.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.724 seconds
[2025-10-03T07:01:40.048+0000] {processor.py:157} INFO - Started process (PID=23137) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:01:40.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:01:40.050+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:40.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:01:40.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:01:40.699+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:40.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:01:40.727+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:40.726+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:01:40.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.703 seconds
[2025-10-03T07:02:10.841+0000] {processor.py:157} INFO - Started process (PID=23443) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:02:10.842+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:02:10.843+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:10.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:02:11.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:02:11.407+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:11.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:02:11.434+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:11.434+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:02:11.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-10-03T07:02:41.592+0000] {processor.py:157} INFO - Started process (PID=23753) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:02:41.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:02:41.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:41.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:02:42.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:02:42.145+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:42.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:02:42.172+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:42.172+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:02:42.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.606 seconds
[2025-10-03T07:03:12.470+0000] {processor.py:157} INFO - Started process (PID=24057) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:03:12.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:03:12.472+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:12.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:03:13.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:03:13.178+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:13.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:03:13.209+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:13.209+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:03:13.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.765 seconds
[2025-10-03T07:03:43.560+0000] {processor.py:157} INFO - Started process (PID=24364) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:03:43.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:03:43.562+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:43.562+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:03:44.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:03:44.588+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:44.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:03:44.616+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:44.616+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:03:44.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.080 seconds
[2025-10-03T07:04:15.026+0000] {processor.py:157} INFO - Started process (PID=24676) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:04:15.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:04:15.028+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:15.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:04:15.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:04:15.600+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:15.599+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:04:15.626+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:15.626+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:04:15.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.625 seconds
[2025-10-03T07:04:45.826+0000] {processor.py:157} INFO - Started process (PID=24983) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:04:45.827+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:04:45.828+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:45.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:04:46.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:04:47.830+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:47.829+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:04:47.864+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:47.864+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:04:47.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.073 seconds
[2025-10-03T07:05:18.380+0000] {processor.py:157} INFO - Started process (PID=25307) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:05:18.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:05:18.385+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:18.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:05:18.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:05:19.320+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:19.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:05:19.347+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:19.347+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:05:19.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.993 seconds
[2025-10-03T07:05:49.746+0000] {processor.py:157} INFO - Started process (PID=25629) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:05:49.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:05:49.748+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:49.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:05:50.260+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:05:50.282+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:50.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:05:50.307+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:50.307+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:05:50.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.583 seconds
[2025-10-03T07:06:20.785+0000] {processor.py:157} INFO - Started process (PID=25939) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:06:20.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:06:20.787+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:20.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:06:21.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:06:21.389+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:21.388+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:06:21.415+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:21.415+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:06:21.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.653 seconds
[2025-10-03T07:06:51.671+0000] {processor.py:157} INFO - Started process (PID=26246) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:06:51.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:06:51.672+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:51.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:06:52.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:06:52.457+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:52.457+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:06:52.484+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:52.483+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:06:52.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.836 seconds
[2025-10-03T07:07:22.570+0000] {processor.py:157} INFO - Started process (PID=26548) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:07:22.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:07:22.572+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:22.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:07:23.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:07:23.109+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:23.108+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:07:23.137+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:23.137+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:07:23.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.590 seconds
[2025-10-03T07:07:53.354+0000] {processor.py:157} INFO - Started process (PID=26850) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:07:53.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:07:53.356+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:53.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:07:53.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:07:53.933+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:08:24.194+0000] {processor.py:157} INFO - Started process (PID=27157) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:08:24.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:08:24.196+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:24.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:08:24.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:08:24.773+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:24.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:08:24.802+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:24.802+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:08:24.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.632 seconds
[2025-10-03T07:08:55.574+0000] {processor.py:157} INFO - Started process (PID=27466) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:08:55.575+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:08:55.575+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:55.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:08:55.992+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:08:56.018+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:56.018+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:08:56.048+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:56.048+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:08:56.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.500 seconds
[2025-10-03T07:09:26.144+0000] {processor.py:157} INFO - Started process (PID=27768) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:09:26.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:09:26.146+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:26.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:09:26.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:09:26.973+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:26.972+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:09:27.003+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:27.003+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:09:27.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.885 seconds
[2025-10-03T07:09:57.465+0000] {processor.py:157} INFO - Started process (PID=28075) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:09:57.466+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:09:57.467+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:57.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:09:57.924+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:09:57.950+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:57.950+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:09:58.005+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:58.005+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:09:58.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.582 seconds
[2025-10-03T07:10:28.702+0000] {processor.py:157} INFO - Started process (PID=28382) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:10:28.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:10:28.704+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:28.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:10:29.187+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:10:29.342+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:29.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:10:29.373+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:29.372+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:10:29.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.697 seconds
[2025-10-03T07:10:59.429+0000] {processor.py:157} INFO - Started process (PID=28692) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:10:59.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:10:59.431+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:59.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:10:59.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:10:59.890+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:59.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:10:59.920+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:59.920+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:10:59.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.515 seconds
[2025-10-03T07:11:30.763+0000] {processor.py:157} INFO - Started process (PID=28994) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:11:30.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:11:30.765+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:30.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:11:31.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:11:31.272+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:31.272+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:11:31.307+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:31.307+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:11:31.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.573 seconds
[2025-10-03T07:12:01.847+0000] {processor.py:157} INFO - Started process (PID=29303) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:12:01.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:12:01.848+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:01.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:12:02.294+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:12:02.575+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:02.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:12:02.609+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:02.609+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:12:02.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.793 seconds
[2025-10-03T07:12:33.015+0000] {processor.py:157} INFO - Started process (PID=29613) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:12:33.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:12:33.017+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:33.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:12:33.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:12:33.528+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:33.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:12:33.562+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:33.561+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:12:33.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.577 seconds
[2025-10-03T07:13:03.794+0000] {processor.py:157} INFO - Started process (PID=29917) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:13:03.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:13:03.799+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:03.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:13:04.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:13:04.256+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:04.255+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:13:04.286+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:04.286+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:13:04.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.516 seconds
[2025-10-03T07:13:34.344+0000] {processor.py:157} INFO - Started process (PID=30227) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:13:34.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:13:34.346+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:34.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:13:34.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:13:35.108+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:35.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:13:35.143+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:35.143+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:13:35.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.929 seconds
[2025-10-03T07:14:05.416+0000] {processor.py:157} INFO - Started process (PID=30526) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:14:05.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:14:05.421+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:05.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:14:05.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:14:05.968+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:05.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:14:06.001+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:06.001+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:14:06.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.614 seconds
[2025-10-03T07:14:36.280+0000] {processor.py:157} INFO - Started process (PID=30817) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:14:36.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:14:36.286+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:14:36.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:14:36.775+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:14:36.805+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.805+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:14:36.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.556 seconds
[2025-10-03T07:15:07.512+0000] {processor.py:157} INFO - Started process (PID=31124) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:15:07.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:15:07.514+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:07.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:15:07.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:15:08.004+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:08.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:15:08.145+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:08.145+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:15:08.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.656 seconds
[2025-10-03T07:15:38.570+0000] {processor.py:157} INFO - Started process (PID=31424) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:15:38.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:15:38.574+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:38.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:15:39.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:15:39.806+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:16:10.558+0000] {processor.py:157} INFO - Started process (PID=31749) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:16:10.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:16:10.560+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:10.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:16:11.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:16:11.108+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.108+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:16:11.136+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.136+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:16:11.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.603 seconds
[2025-10-03T07:16:41.454+0000] {processor.py:157} INFO - Started process (PID=32055) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:16:41.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:16:41.457+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:41.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:16:42.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:16:42.057+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.057+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:16:42.085+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.085+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:16:42.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.654 seconds
[2025-10-03T07:17:12.266+0000] {processor.py:157} INFO - Started process (PID=32355) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:17:12.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:17:12.268+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:17:12.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:17:12.848+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:17:12.875+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.875+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:17:12.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.638 seconds
[2025-10-03T07:17:43.130+0000] {processor.py:157} INFO - Started process (PID=32657) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:17:43.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:17:43.136+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:43.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:17:43.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:17:44.590+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:44.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:17:44.621+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:44.620+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:17:44.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.522 seconds
[2025-10-03T07:18:15.254+0000] {processor.py:157} INFO - Started process (PID=32972) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:18:15.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:18:15.256+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:15.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:18:15.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:18:16.225+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:16.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:18:16.254+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:16.254+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:18:16.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.026 seconds
[2025-10-03T07:18:46.431+0000] {processor.py:157} INFO - Started process (PID=33279) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:18:46.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:18:46.434+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:46.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:18:46.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:18:47.003+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:47.002+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:18:47.029+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:47.029+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:18:47.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.624 seconds
[2025-10-03T07:19:17.294+0000] {processor.py:157} INFO - Started process (PID=33578) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:19:17.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:19:17.297+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:17.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:19:17.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:19:18.115+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:18.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:19:18.141+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:18.141+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:19:18.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.873 seconds
[2025-10-03T07:19:48.499+0000] {processor.py:157} INFO - Started process (PID=33882) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:19:48.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:19:48.501+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:48.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:19:49.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:19:50.081+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:20:20.257+0000] {processor.py:157} INFO - Started process (PID=34196) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:20:20.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:20:20.259+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:20.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:20:20.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:20:21.937+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:21.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:20:21.965+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:21.964+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:20:21.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.733 seconds
[2025-10-03T07:20:52.258+0000] {processor.py:157} INFO - Started process (PID=34509) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:20:52.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:20:52.260+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:52.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:20:52.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:20:52.900+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:52.900+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:20:52.935+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:52.935+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:20:52.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.702 seconds
[2025-10-03T07:21:23.003+0000] {processor.py:157} INFO - Started process (PID=34816) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:21:23.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:21:23.005+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:23.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:21:23.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:21:23.616+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:23.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:21:23.646+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:23.646+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:21:23.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.669 seconds
[2025-10-03T07:21:53.883+0000] {processor.py:157} INFO - Started process (PID=35123) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:21:53.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:21:53.886+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:53.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:21:54.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:21:54.669+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:54.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:21:54.709+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:54.709+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:21:54.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.858 seconds
[2025-10-03T07:22:24.941+0000] {processor.py:157} INFO - Started process (PID=35430) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:22:24.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:22:24.943+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:24.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:22:25.469+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:22:25.492+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:25.491+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:22:25.519+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:25.519+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:22:25.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.602 seconds
[2025-10-03T07:22:56.202+0000] {processor.py:157} INFO - Started process (PID=35742) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:22:56.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T07:22:56.204+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:56.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:22:56.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T07:22:56.787+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:56.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:22:56.814+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:56.814+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T07:22:56.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.635 seconds
[2025-10-03T09:12:13.350+0000] {processor.py:157} INFO - Started process (PID=196) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:12:13.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:12:13.376+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:13.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:12:16.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:12:17.740+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T09:12:48.145+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:12:48.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:12:48.151+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:48.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:12:48.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:12:48.855+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:48.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:12:48.886+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:48.885+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:12:48.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.773 seconds
[2025-10-03T09:13:19.328+0000] {processor.py:157} INFO - Started process (PID=827) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:13:19.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:13:19.331+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:19.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:13:19.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:13:20.520+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:20.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:13:20.556+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:20.556+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:13:20.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.253 seconds
[2025-10-03T09:13:50.918+0000] {processor.py:157} INFO - Started process (PID=1145) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:13:50.919+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:13:50.920+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:50.920+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:13:51.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:13:51.529+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:51.529+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:13:51.568+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:51.568+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:13:51.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.695 seconds
[2025-10-03T09:14:22.170+0000] {processor.py:157} INFO - Started process (PID=1452) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:14:22.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:14:22.171+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:22.171+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:14:22.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:14:23.052+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:23.051+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:14:23.099+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:23.098+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:14:23.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.964 seconds
[2025-10-03T09:14:53.395+0000] {processor.py:157} INFO - Started process (PID=1761) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:14:53.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:14:53.397+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:53.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:14:53.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:14:54.072+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:54.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:14:54.102+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:54.102+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:14:54.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.734 seconds
[2025-10-03T09:15:24.881+0000] {processor.py:157} INFO - Started process (PID=2068) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:15:24.883+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:15:24.884+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:24.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:15:25.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:15:25.444+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:25.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:15:25.473+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:25.472+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:15:25.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-10-03T09:15:55.725+0000] {processor.py:157} INFO - Started process (PID=2375) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:15:55.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:15:55.727+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:55.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:15:56.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:15:56.451+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:56.450+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:15:56.496+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:56.496+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:15:56.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.808 seconds
[2025-10-03T09:56:04.417+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:56:04.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:56:04.419+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:04.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:56:06.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:56:06.367+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:06.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:56:06.405+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:06.405+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:56:06.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.021 seconds
[2025-10-03T09:56:37.365+0000] {processor.py:157} INFO - Started process (PID=495) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:56:37.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:56:37.368+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:37.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:56:37.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:56:38.389+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:38.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:56:38.428+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:38.428+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:56:38.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.096 seconds
[2025-10-03T09:57:08.539+0000] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:08.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:57:08.543+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:08.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:08.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:09.400+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:09.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:09.430+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:09.430+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:57:09.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.917 seconds
[2025-10-03T09:57:39.562+0000] {processor.py:157} INFO - Started process (PID=1109) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:39.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:57:39.566+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:39.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:40.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:40.425+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:40.424+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:40.457+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:40.456+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:57:40.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.922 seconds
[2025-10-03T09:57:58.698+0000] {processor.py:157} INFO - Started process (PID=173) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:58.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:57:58.702+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:58.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:59.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:57:59.697+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:59.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:59.746+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:59.746+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:57:59.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.083 seconds
[2025-10-03T09:58:29.925+0000] {processor.py:157} INFO - Started process (PID=481) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:58:29.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:58:29.930+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:29.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:58:30.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:58:30.855+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:30.854+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:58:30.888+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:30.888+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:58:30.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.991 seconds
[2025-10-03T09:59:01.225+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:59:01.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:59:01.233+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:01.232+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:59:01.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:59:01.742+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:01.742+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:59:01.771+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:01.771+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:59:01.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.575 seconds
[2025-10-03T09:59:32.132+0000] {processor.py:157} INFO - Started process (PID=1099) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:59:32.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T09:59:32.135+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:32.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:59:32.623+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T09:59:32.981+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:32.980+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:59:33.015+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:33.014+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T09:59:33.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.919 seconds
[2025-10-03T10:00:04.020+0000] {processor.py:157} INFO - Started process (PID=1409) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:00:04.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:00:04.025+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:04.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:00:04.482+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:00:04.508+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:04.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:00:04.537+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:04.537+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:00:04.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.541 seconds
[2025-10-03T10:00:34.670+0000] {processor.py:157} INFO - Started process (PID=1716) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:00:34.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:00:34.672+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:34.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:00:35.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:00:35.182+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:35.181+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:00:35.210+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:35.210+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:00:35.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.565 seconds
[2025-10-03T10:01:05.604+0000] {processor.py:157} INFO - Started process (PID=2020) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:01:05.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:01:05.606+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:05.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:01:06.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:01:06.032+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:06.031+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:01:06.061+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:06.061+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:01:06.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.484 seconds
[2025-10-03T10:01:36.122+0000] {processor.py:157} INFO - Started process (PID=2327) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:01:36.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:01:36.124+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:36.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:01:36.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:01:37.409+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:02:07.470+0000] {processor.py:157} INFO - Started process (PID=2634) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:02:07.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:02:07.472+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:07.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:02:07.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:02:07.973+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:07.972+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:02:08.003+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:08.003+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:02:08.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.558 seconds
[2025-10-03T10:02:38.113+0000] {processor.py:157} INFO - Started process (PID=2941) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:02:38.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:02:38.116+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:38.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:02:38.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:02:39.544+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:03:09.845+0000] {processor.py:157} INFO - Started process (PID=3253) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:03:09.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:03:09.847+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:09.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:03:10.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:03:11.090+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:03:41.166+0000] {processor.py:157} INFO - Started process (PID=3560) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:03:41.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:03:41.168+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:41.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:03:41.562+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:03:41.589+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:41.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:03:41.748+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:41.748+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:03:41.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-10-03T10:04:12.187+0000] {processor.py:157} INFO - Started process (PID=3867) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:04:12.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:04:12.190+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:12.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:04:12.619+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:04:12.757+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:12.757+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:04:12.787+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:12.786+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:04:12.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.623 seconds
[2025-10-03T10:04:43.200+0000] {processor.py:157} INFO - Started process (PID=4182) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:04:43.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:04:43.202+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:43.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:04:43.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:04:44.884+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:44.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:04:44.916+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:44.916+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:04:44.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.741 seconds
[2025-10-03T10:05:15.056+0000] {processor.py:157} INFO - Started process (PID=4491) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:05:15.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:05:15.058+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:15.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:05:15.580+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:05:15.606+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:15.606+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:05:15.633+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:15.633+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:05:15.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.601 seconds
[2025-10-03T10:05:46.211+0000] {processor.py:157} INFO - Started process (PID=4798) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:05:46.212+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:05:46.213+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:46.213+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:05:46.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:05:47.824+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:47.823+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:05:47.851+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:47.851+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:05:47.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.665 seconds
[2025-10-03T10:06:17.933+0000] {processor.py:157} INFO - Started process (PID=5116) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:06:17.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:06:17.935+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:17.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:06:18.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:06:18.932+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:18.931+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:06:18.959+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:18.959+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:06:18.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.048 seconds
[2025-10-03T10:06:49.163+0000] {processor.py:157} INFO - Started process (PID=5412) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:06:49.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:06:49.166+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:49.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:06:49.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:06:49.813+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:49.812+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:06:49.849+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:49.849+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:06:49.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.711 seconds
[2025-10-03T10:07:20.360+0000] {processor.py:157} INFO - Started process (PID=5719) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:07:20.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:07:20.363+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:20.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:07:20.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:07:21.357+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:21.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:07:21.388+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:21.387+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:07:21.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.053 seconds
[2025-10-03T10:07:52.228+0000] {processor.py:157} INFO - Started process (PID=6044) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:07:52.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:07:52.230+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:52.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:07:52.794+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:07:53.407+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:53.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:07:53.436+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:53.436+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:07:53.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.233 seconds
[2025-10-03T10:08:23.707+0000] {processor.py:157} INFO - Started process (PID=6351) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:08:23.708+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:08:23.709+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:23.709+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:08:24.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:08:24.309+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:24.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:08:24.335+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:24.335+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:08:24.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.652 seconds
[2025-10-03T10:08:55.099+0000] {processor.py:157} INFO - Started process (PID=6655) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:08:55.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:08:55.101+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:55.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:08:55.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:08:55.689+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:55.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:08:55.715+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:55.715+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:08:55.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.640 seconds
[2025-10-03T10:09:25.846+0000] {processor.py:157} INFO - Started process (PID=6962) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:09:25.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:09:25.848+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:25.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:09:26.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:09:26.385+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:26.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:09:26.413+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:26.412+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:09:26.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.591 seconds
[2025-10-03T10:09:57.223+0000] {processor.py:157} INFO - Started process (PID=7269) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:09:57.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:09:57.225+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:57.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:09:57.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:09:57.844+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:57.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:09:57.875+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:57.875+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:09:57.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.677 seconds
[2025-10-03T10:10:28.421+0000] {processor.py:157} INFO - Started process (PID=7576) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:10:28.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:10:28.423+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:28.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:10:28.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:10:29.001+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:29.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:10:29.028+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:29.028+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:10:29.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.630 seconds
[2025-10-03T10:10:59.768+0000] {processor.py:157} INFO - Started process (PID=7883) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:10:59.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:10:59.770+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:59.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:11:00.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:11:00.767+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:00.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:11:00.793+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:00.793+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:11:00.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.049 seconds
[2025-10-03T10:11:31.241+0000] {processor.py:157} INFO - Started process (PID=8206) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:11:31.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:11:31.242+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:31.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:11:31.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:11:31.793+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:31.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:11:31.818+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:31.818+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:11:31.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.599 seconds
[2025-10-03T10:12:02.315+0000] {processor.py:157} INFO - Started process (PID=8521) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:12:02.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:12:02.317+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:02.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:12:02.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:12:03.606+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:12:33.922+0000] {processor.py:157} INFO - Started process (PID=8842) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:12:33.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:12:33.925+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:33.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:12:34.433+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:12:34.455+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:34.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:12:34.481+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:34.481+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:12:34.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.582 seconds
[2025-10-03T10:13:05.642+0000] {processor.py:157} INFO - Started process (PID=9147) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:13:05.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:13:05.644+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:05.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:13:06.159+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:13:06.183+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:06.182+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:13:06.212+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:06.211+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:13:06.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.593 seconds
[2025-10-03T10:13:36.907+0000] {processor.py:157} INFO - Started process (PID=9446) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:13:36.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:13:36.910+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:36.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:13:37.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:13:37.397+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:37.396+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:13:37.425+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:37.425+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:13:37.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.543 seconds
[2025-10-03T10:17:00.815+0000] {processor.py:157} INFO - Started process (PID=9706) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:17:00.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:17:00.825+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:00.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:17:02.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:17:02.753+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:02.752+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:17:02.827+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:02.826+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:17:02.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.075 seconds
[2025-10-03T10:17:33.441+0000] {processor.py:157} INFO - Started process (PID=10016) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:17:33.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:17:33.445+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:33.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:17:33.937+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:17:33.964+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:33.963+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:17:33.997+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:33.997+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:17:34.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.581 seconds
[2025-10-03T10:18:04.422+0000] {processor.py:157} INFO - Started process (PID=10320) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:18:04.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:18:04.424+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:04.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:18:04.819+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:18:04.846+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:04.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:18:04.874+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:04.874+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:18:04.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.479 seconds
[2025-10-03T10:18:34.958+0000] {processor.py:157} INFO - Started process (PID=10627) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:18:34.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:18:34.960+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:34.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:18:35.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:18:35.380+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:35.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:18:35.409+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:35.409+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:18:35.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.478 seconds
[2025-10-03T10:19:05.562+0000] {processor.py:157} INFO - Started process (PID=10934) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:19:05.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:19:05.564+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:05.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:19:05.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:19:05.988+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:05.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:19:06.017+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:06.017+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:19:06.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.483 seconds
[2025-10-03T10:19:36.383+0000] {processor.py:157} INFO - Started process (PID=11241) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:19:36.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:19:36.385+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:36.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:19:36.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:19:36.829+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:36.828+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:19:36.858+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:36.858+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:19:36.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.500 seconds
[2025-10-03T10:20:07.106+0000] {processor.py:157} INFO - Started process (PID=11548) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:20:07.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:20:07.108+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:07.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:20:07.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:20:07.535+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:07.534+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:20:07.568+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:07.568+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:20:07.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.486 seconds
[2025-10-03T10:20:38.087+0000] {processor.py:157} INFO - Started process (PID=11855) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:20:38.088+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:20:38.090+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:38.089+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:20:38.488+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:20:38.514+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:38.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:20:38.543+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:38.543+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:20:38.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.481 seconds
[2025-10-03T10:21:08.732+0000] {processor.py:157} INFO - Started process (PID=12162) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:21:08.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:21:08.734+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:08.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:21:09.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:21:09.156+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:09.155+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:21:09.313+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:09.312+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:21:09.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.612 seconds
[2025-10-03T10:21:39.498+0000] {processor.py:157} INFO - Started process (PID=12469) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:21:39.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:21:39.500+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:39.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:21:39.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:21:39.938+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:39.938+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:21:39.972+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:39.972+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T10:21:39.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.499 seconds
[2025-10-03T10:22:10.233+0000] {processor.py:157} INFO - Started process (PID=12776) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T10:22:10.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T10:22:10.236+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:22:10.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:05:37.530+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:37.528+0000] {timeout.py:68} ERROR - Process timed out, PID: 12776
[2025-10-03T12:05:38.005+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:37.537+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistics_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistics_dag.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py", line 7, in <module>
    from pandas.util.version import Version
  File "<frozen importlib._bootstrap>", line 980, in _find_and_load
  File "<frozen importlib._bootstrap>", line 148, in __enter__
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistics_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 12776
[2025-10-03T12:05:38.035+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:05:38.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 6207.929 seconds
[2025-10-03T12:06:09.304+0000] {processor.py:157} INFO - Started process (PID=13090) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:06:09.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T12:06:09.416+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:06:09.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:22:53.658+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:53.646+0000] {timeout.py:68} ERROR - Process timed out, PID: 13090
[2025-10-03T12:22:53.804+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:53.765+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistics_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistics_dag.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 11, in <module>
    __import__(dependency)
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/__init__.py", line 153, in <module>
    from . import lib
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/lib/__init__.py", line 25, in <module>
    from .index_tricks import *
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/lib/index_tricks.py", line 13, in <module>
    from .function_base import diff
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/lib/function_base.py", line 4383, in <module>
    def delete(arr, obj, axis=None):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistics_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 13090
[2025-10-03T12:22:53.818+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:22:54.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1004.896 seconds
[2025-10-03T12:23:26.013+0000] {processor.py:157} INFO - Started process (PID=13405) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:23:26.063+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T12:23:26.119+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:23:26.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:37:56.165+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:37:56.162+0000] {timeout.py:68} ERROR - Process timed out, PID: 13405
[2025-10-03T12:37:56.560+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:37:56.512+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistics_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistics_dag.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 162, in <module>
    class SeriesGroupBy(GroupBy[Series]):
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 675, in SeriesGroupBy
    @doc(Series.describe)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 391, in decorator
    for component in docstring_components
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 391, in <genexpr>
    for component in docstring_components
  File "/usr/local/lib/python3.7/textwrap.py", line 431, in dedent
    indents = _leading_whitespace_re.findall(text)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistics_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 13405
[2025-10-03T12:37:56.568+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:37:56.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 870.942 seconds
[2025-10-03T12:39:00.149+0000] {processor.py:157} INFO - Started process (PID=13722) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:39:00.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T12:39:00.155+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:00.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:39:01.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:39:01.211+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.211+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:39:01.250+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.250+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T12:39:01.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.143 seconds
[2025-10-03T12:39:33.191+0000] {processor.py:157} INFO - Started process (PID=14030) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:39:33.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T12:39:33.264+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:33.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:39:47.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:39:48.236+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:48.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:39:49.367+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:49.364+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T12:39:50.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 17.111 seconds
[2025-10-03T12:42:31.096+0000] {processor.py:157} INFO - Started process (PID=14342) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:42:31.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T12:42:31.100+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:42:31.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T12:42:31.773+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:42:31.801+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.801+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T12:42:31.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.733 seconds
[2025-10-03T13:22:11.055+0000] {processor.py:157} INFO - Started process (PID=14443) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T13:22:11.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T13:22:11.059+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:11.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T13:22:11.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T13:22:11.789+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:11.788+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T13:22:12.008+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:12.007+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T13:22:12.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.001 seconds
[2025-10-03T18:14:57.266+0000] {processor.py:157} INFO - Started process (PID=14754) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:14:57.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T18:14:57.276+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:57.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:14:59.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:14:59.112+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:59.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:14:59.182+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:59.181+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T18:14:59.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.000 seconds
[2025-10-03T18:15:29.531+0000] {processor.py:157} INFO - Started process (PID=15063) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:15:29.533+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T18:15:29.534+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:29.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:15:30.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:15:30.214+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:30.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:15:30.247+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:30.247+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T18:15:30.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.748 seconds
[2025-10-03T18:16:00.331+0000] {processor.py:157} INFO - Started process (PID=15370) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:16:00.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T18:16:00.333+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:00.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:16:00.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:16:00.952+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:00.951+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:16:00.980+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:00.979+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T18:16:01.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.675 seconds
[2025-10-03T18:16:31.881+0000] {processor.py:157} INFO - Started process (PID=15677) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:16:31.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-03T18:16:31.885+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:31.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:16:32.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-03T18:16:32.646+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:32.646+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:16:32.681+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:32.680+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-03T09:00:00+00:00, run_after=2025-10-04T09:00:00+00:00
[2025-10-03T18:16:32.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.835 seconds
