[2025-10-03T06:22:59.818+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:22:59.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:22:59.821+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:22:59.821+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:23:00.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:23:01.242+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:01.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:23:01.341+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:01.340+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:23:01.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.576 seconds
[2025-10-03T06:23:31.564+0000] {processor.py:157} INFO - Started process (PID=536) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:23:31.565+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:23:31.567+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:31.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:23:32.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:23:32.091+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:32.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:23:32.156+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:32.156+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:23:32.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.658 seconds
[2025-10-03T06:24:02.464+0000] {processor.py:157} INFO - Started process (PID=841) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:24:02.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:24:02.466+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:02.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:24:02.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:24:03.281+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:03.280+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:24:03.313+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:03.312+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:24:03.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.879 seconds
[2025-10-03T06:24:33.721+0000] {processor.py:157} INFO - Started process (PID=1148) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:24:33.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:24:33.723+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:33.723+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:24:34.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:24:35.298+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:35.297+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:24:35.334+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:35.334+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:24:35.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.641 seconds
[2025-10-03T06:25:05.782+0000] {processor.py:157} INFO - Started process (PID=1460) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:25:05.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:25:05.785+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:05.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:25:06.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:25:06.738+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:06.737+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:25:06.783+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:06.783+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:25:06.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.035 seconds
[2025-10-03T06:25:37.138+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:25:37.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:25:37.140+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:37.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:25:37.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:25:37.802+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:37.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:25:37.835+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:37.835+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:25:37.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.722 seconds
[2025-10-03T06:26:07.927+0000] {processor.py:157} INFO - Started process (PID=2080) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:26:07.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:26:07.929+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:26:08.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:26:08.621+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:08.620+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:26:08.666+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:08.666+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:26:08.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.778 seconds
[2025-10-03T06:26:39.095+0000] {processor.py:157} INFO - Started process (PID=2387) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:26:39.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:26:39.097+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:39.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:26:39.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:26:39.602+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:39.602+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:26:39.632+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:39.632+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:26:39.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.566 seconds
[2025-10-03T06:27:10.183+0000] {processor.py:157} INFO - Started process (PID=2694) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:27:10.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:27:10.184+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:10.184+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:27:10.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:27:10.614+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:10.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:27:10.644+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:10.644+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:27:10.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.488 seconds
[2025-10-03T06:27:41.026+0000] {processor.py:157} INFO - Started process (PID=3002) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:27:41.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:27:41.028+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:41.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:27:41.455+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:27:41.479+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:41.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:27:41.507+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:41.507+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:27:41.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.505 seconds
[2025-10-03T06:28:12.544+0000] {processor.py:157} INFO - Started process (PID=3305) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:28:12.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:28:12.546+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:12.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:28:12.964+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:28:12.989+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:12.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:28:13.018+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:13.018+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:28:13.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.497 seconds
[2025-10-03T06:28:43.204+0000] {processor.py:157} INFO - Started process (PID=3604) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:28:43.206+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:28:43.207+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:28:43.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:28:43.692+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:28:43.722+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.722+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:28:43.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.650 seconds
[2025-10-03T06:29:15.336+0000] {processor.py:157} INFO - Started process (PID=3921) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:29:15.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:29:15.338+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:15.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:29:15.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:29:16.116+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:16.115+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:29:16.146+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:16.146+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:29:16.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.839 seconds
[2025-10-03T06:29:46.357+0000] {processor.py:157} INFO - Started process (PID=4236) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:29:46.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:29:46.359+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:46.359+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:29:46.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:29:46.884+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:46.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:29:47.028+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:47.028+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:29:47.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.698 seconds
[2025-10-03T06:30:17.446+0000] {processor.py:157} INFO - Started process (PID=4540) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:30:17.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:30:17.448+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:17.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:30:18.028+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:30:18.049+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:18.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:30:18.075+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:18.075+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:30:18.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.656 seconds
[2025-10-03T06:30:49.264+0000] {processor.py:157} INFO - Started process (PID=4850) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:30:49.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:30:49.267+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:49.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:30:49.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:30:49.870+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:49.869+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:30:49.900+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:49.900+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:30:49.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.661 seconds
[2025-10-03T06:31:20.398+0000] {processor.py:157} INFO - Started process (PID=5156) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:31:20.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:31:20.399+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:31:20.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:31:20.969+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.969+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:31:20.995+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.995+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:31:21.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.620 seconds
[2025-10-03T06:31:51.368+0000] {processor.py:157} INFO - Started process (PID=5456) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:31:51.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:31:51.369+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:51.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:31:51.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:31:52.850+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:52.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:31:52.876+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:52.875+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:31:52.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.529 seconds
[2025-10-03T06:32:24.236+0000] {processor.py:157} INFO - Started process (PID=5781) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:32:24.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:32:24.238+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:24.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:32:24.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:32:24.896+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:24.895+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:32:24.925+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:24.925+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:32:24.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.714 seconds
[2025-10-03T06:32:55.003+0000] {processor.py:157} INFO - Started process (PID=6090) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:32:55.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:32:55.006+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:55.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:32:55.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:32:55.735+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:55.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:32:55.760+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:55.760+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:32:55.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.780 seconds
[2025-10-03T06:33:26.163+0000] {processor.py:157} INFO - Started process (PID=6397) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:33:26.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:33:26.165+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:26.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:33:26.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:33:26.869+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:26.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:33:26.895+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:26.895+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:33:26.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.754 seconds
[2025-10-03T06:33:57.791+0000] {processor.py:157} INFO - Started process (PID=6702) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:33:57.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:33:57.793+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:57.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:33:58.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:33:58.403+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:58.403+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:33:58.429+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:58.429+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:33:58.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.661 seconds
[2025-10-03T06:34:28.710+0000] {processor.py:157} INFO - Started process (PID=7001) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:34:28.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:34:28.712+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:28.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:34:29.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:34:29.293+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:29.292+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:34:29.318+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:29.318+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:34:29.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.632 seconds
[2025-10-03T06:34:59.843+0000] {processor.py:157} INFO - Started process (PID=7308) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:34:59.844+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:34:59.845+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:59.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:35:00.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:35:00.869+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:00.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:35:00.900+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:00.900+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:35:00.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.079 seconds
[2025-10-03T06:35:32.002+0000] {processor.py:157} INFO - Started process (PID=7623) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:35:32.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:35:32.004+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:32.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:35:32.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:35:32.565+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:32.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:35:32.592+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:32.591+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:35:32.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.614 seconds
[2025-10-03T06:36:03.673+0000] {processor.py:157} INFO - Started process (PID=7932) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:36:03.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:36:03.675+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:03.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:36:04.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:36:04.448+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:04.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:36:04.483+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:04.483+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:36:04.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.842 seconds
[2025-10-03T06:36:34.698+0000] {processor.py:157} INFO - Started process (PID=8237) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:36:34.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:36:34.700+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:34.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:36:35.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:36:36.300+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:36.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:36:36.328+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:36.328+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:36:36.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.663 seconds
[2025-10-03T06:37:06.807+0000] {processor.py:157} INFO - Started process (PID=8546) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:37:06.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:37:06.810+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:06.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:37:07.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:37:07.386+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:07.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:37:07.412+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:07.412+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:37:07.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.628 seconds
[2025-10-03T06:37:37.592+0000] {processor.py:157} INFO - Started process (PID=8851) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:37:37.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:37:37.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:37.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:37:38.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:37:38.821+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:38:09.441+0000] {processor.py:157} INFO - Started process (PID=9160) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:38:09.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:38:09.442+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:09.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:38:09.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:38:10.957+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:38:41.049+0000] {processor.py:157} INFO - Started process (PID=9470) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:38:41.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:38:41.051+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:41.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:38:41.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:38:41.586+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:41.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:38:41.616+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:41.615+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:38:41.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.590 seconds
[2025-10-03T06:39:11.901+0000] {processor.py:157} INFO - Started process (PID=9776) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:39:11.902+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:39:11.903+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:11.903+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:39:12.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:39:12.376+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:12.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:39:12.407+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:12.407+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:39:12.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.532 seconds
[2025-10-03T06:39:42.941+0000] {processor.py:157} INFO - Started process (PID=10073) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:39:42.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:39:42.943+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:42.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:39:43.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:39:43.514+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:43.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:39:43.544+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:43.544+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:39:43.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.627 seconds
[2025-10-03T06:40:14.301+0000] {processor.py:157} INFO - Started process (PID=10390) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:40:14.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:40:14.303+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:14.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:40:14.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:40:14.778+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:14.778+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:40:14.808+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:14.808+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:40:14.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.531 seconds
[2025-10-03T06:40:45.257+0000] {processor.py:157} INFO - Started process (PID=10697) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:40:45.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:40:45.259+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:45.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:40:45.739+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:40:46.088+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:46.087+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:40:46.119+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:46.119+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:40:46.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.887 seconds
[2025-10-03T06:41:16.466+0000] {processor.py:157} INFO - Started process (PID=11004) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:41:16.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:41:16.470+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:16.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:41:16.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:41:16.965+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:16.964+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:41:16.994+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:16.994+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:41:17.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.552 seconds
[2025-10-03T06:41:47.222+0000] {processor.py:157} INFO - Started process (PID=11308) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:41:47.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:41:47.227+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:47.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:41:47.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:41:47.683+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:47.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:41:47.714+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:47.714+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:41:47.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.517 seconds
[2025-10-03T06:42:17.786+0000] {processor.py:157} INFO - Started process (PID=11615) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:42:17.787+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:42:17.788+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:17.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:42:18.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:42:19.708+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:42:49.849+0000] {processor.py:157} INFO - Started process (PID=11937) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:42:49.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:42:49.851+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:49.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:42:50.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:42:50.310+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:50.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:42:50.338+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:50.338+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:42:50.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.514 seconds
[2025-10-03T06:43:20.432+0000] {processor.py:157} INFO - Started process (PID=12237) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:43:20.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:43:20.434+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:20.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:43:20.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:43:21.304+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:21.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:43:21.333+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:21.333+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:43:21.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.925 seconds
[2025-10-03T06:43:51.534+0000] {processor.py:157} INFO - Started process (PID=12543) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:43:51.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:43:51.536+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:51.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:43:52.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:43:52.111+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:52.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:43:52.139+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:52.139+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:43:52.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.628 seconds
[2025-10-03T06:44:22.645+0000] {processor.py:157} INFO - Started process (PID=12850) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:44:22.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:44:22.647+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:22.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:44:23.222+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:44:23.244+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:23.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:44:23.271+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:23.271+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:44:23.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.651 seconds
[2025-10-03T06:44:54.120+0000] {processor.py:157} INFO - Started process (PID=13157) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:44:54.122+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:44:54.123+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:54.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:44:54.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:44:54.759+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:54.758+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:44:54.786+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:54.786+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:44:54.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.692 seconds
[2025-10-03T06:45:25.257+0000] {processor.py:157} INFO - Started process (PID=13461) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:45:25.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:45:25.259+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:25.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:45:25.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:45:25.881+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:25.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:45:25.916+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:25.916+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:45:25.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.695 seconds
[2025-10-03T06:45:56.145+0000] {processor.py:157} INFO - Started process (PID=13768) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:45:56.146+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:45:56.147+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:56.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:45:56.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:45:56.783+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:56.783+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:45:56.812+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:56.812+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:45:56.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.695 seconds
[2025-10-03T06:46:27.366+0000] {processor.py:157} INFO - Started process (PID=14075) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:46:27.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:46:27.368+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:27.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:46:27.923+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:46:28.241+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:28.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:46:28.269+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:28.268+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:46:28.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.928 seconds
[2025-10-03T06:46:58.849+0000] {processor.py:157} INFO - Started process (PID=14390) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:46:58.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:46:58.851+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:58.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:46:59.391+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:46:59.739+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:59.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:46:59.768+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:59.768+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:46:59.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.946 seconds
[2025-10-03T06:47:29.913+0000] {processor.py:157} INFO - Started process (PID=14699) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:47:29.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:47:29.915+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:29.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:47:30.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:47:30.462+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:30.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:47:30.489+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:30.489+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:47:30.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.600 seconds
[2025-10-03T06:48:00.598+0000] {processor.py:157} INFO - Started process (PID=15004) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:48:00.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:48:00.600+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:00.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:48:01.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:48:01.165+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:01.164+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:48:01.192+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:01.191+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:48:01.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.615 seconds
[2025-10-03T06:48:31.296+0000] {processor.py:157} INFO - Started process (PID=15306) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:48:31.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:48:31.298+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:31.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:48:31.833+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:48:32.328+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:49:02.598+0000] {processor.py:157} INFO - Started process (PID=15628) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:49:02.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:49:02.600+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:02.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:49:03.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:49:03.715+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:49:33.776+0000] {processor.py:157} INFO - Started process (PID=15930) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:49:33.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:49:33.777+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:33.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:49:34.321+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:49:35.446+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:35.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:49:35.479+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:35.478+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:49:35.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.729 seconds
[2025-10-03T06:50:05.796+0000] {processor.py:157} INFO - Started process (PID=16264) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:50:05.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:50:05.798+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:05.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:50:06.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:50:06.444+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:06.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:50:06.469+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:06.469+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:50:06.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.695 seconds
[2025-10-03T06:50:36.652+0000] {processor.py:157} INFO - Started process (PID=16579) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:50:36.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:50:36.654+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:36.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:50:37.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:50:37.214+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:37.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:50:37.240+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:37.239+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:50:37.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.612 seconds
[2025-10-03T06:51:07.309+0000] {processor.py:157} INFO - Started process (PID=16886) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:51:07.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:51:07.311+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:07.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:51:07.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:51:07.861+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:07.860+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:51:07.887+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:07.886+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:51:07.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.600 seconds
[2025-10-03T06:51:37.953+0000] {processor.py:157} INFO - Started process (PID=17187) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:51:37.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:51:37.955+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:37.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:51:38.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:51:38.810+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:38.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:51:38.839+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:38.839+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:51:38.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.911 seconds
[2025-10-03T06:52:09.043+0000] {processor.py:157} INFO - Started process (PID=17494) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:52:09.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:52:09.050+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:09.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:52:09.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:52:09.628+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:09.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:52:09.659+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:09.659+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:52:09.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.642 seconds
[2025-10-03T06:52:40.107+0000] {processor.py:157} INFO - Started process (PID=17794) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:52:40.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:52:40.109+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:40.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:52:40.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:52:41.568+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:53:11.888+0000] {processor.py:157} INFO - Started process (PID=18116) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:53:11.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:53:11.890+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:11.890+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:53:12.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:53:12.613+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:53:43.275+0000] {processor.py:157} INFO - Started process (PID=18423) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:53:43.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:53:43.277+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:43.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:53:43.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:53:44.958+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:44.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:53:44.995+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:44.995+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:53:45.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.745 seconds
[2025-10-03T06:54:15.189+0000] {processor.py:157} INFO - Started process (PID=18735) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:54:15.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:54:15.191+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:15.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:54:15.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:54:16.072+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:16.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:54:16.111+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:16.111+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:54:16.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.961 seconds
[2025-10-03T06:54:46.263+0000] {processor.py:157} INFO - Started process (PID=19064) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:54:46.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:54:46.265+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:46.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:54:46.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:54:46.739+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:46.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:54:46.769+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:46.769+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:54:46.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.530 seconds
[2025-10-03T06:55:17.654+0000] {processor.py:157} INFO - Started process (PID=19376) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:55:17.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:55:17.655+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:17.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:55:18.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:55:19.633+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:19.632+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:55:19.668+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:19.668+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:55:19.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 2.040 seconds
[2025-10-03T06:55:49.765+0000] {processor.py:157} INFO - Started process (PID=19696) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:55:49.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:55:49.767+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:49.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:55:50.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:55:50.639+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:50.639+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:55:50.676+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:50.676+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:55:50.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.938 seconds
[2025-10-03T06:56:20.981+0000] {processor.py:157} INFO - Started process (PID=20008) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:56:20.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:56:20.983+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:20.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:56:21.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:56:21.435+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:21.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:56:21.464+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:21.464+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:56:21.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.510 seconds
[2025-10-03T06:56:51.974+0000] {processor.py:157} INFO - Started process (PID=20315) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:56:51.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:56:51.976+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:51.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:56:52.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:56:52.633+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:52.632+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:56:52.671+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:52.671+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:56:52.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.726 seconds
[2025-10-03T06:57:23.446+0000] {processor.py:157} INFO - Started process (PID=20624) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:57:23.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:57:23.448+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:23.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:57:23.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:57:24.903+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:57:55.739+0000] {processor.py:157} INFO - Started process (PID=20936) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:57:55.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:57:55.741+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:55.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:57:56.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:57:56.448+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:56.447+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:57:56.484+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:56.484+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:57:56.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.770 seconds
[2025-10-03T06:58:27.278+0000] {processor.py:157} INFO - Started process (PID=21242) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:58:27.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:58:27.280+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:27.280+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:58:27.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:58:28.158+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:28.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:58:28.302+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:28.302+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:58:28.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.046 seconds
[2025-10-03T06:58:58.481+0000] {processor.py:157} INFO - Started process (PID=21557) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:58:58.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:58:58.483+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:58.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:58:58.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:59:00.367+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:59:30.850+0000] {processor.py:157} INFO - Started process (PID=21876) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:59:30.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T06:59:30.852+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:30.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:59:31.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T06:59:31.390+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:31.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:59:31.416+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:31.416+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T06:59:31.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.589 seconds
[2025-10-03T07:00:02.233+0000] {processor.py:157} INFO - Started process (PID=22183) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:00:02.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:00:02.237+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:02.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:00:02.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:00:02.801+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:02.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:00:02.828+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:02.828+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:00:02.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.626 seconds
[2025-10-03T07:00:33.020+0000] {processor.py:157} INFO - Started process (PID=22490) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:00:33.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:00:33.022+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:33.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:00:33.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:00:33.582+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:33.581+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:00:33.607+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:33.607+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:00:33.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.609 seconds
[2025-10-03T07:01:03.913+0000] {processor.py:157} INFO - Started process (PID=22797) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:01:03.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:01:03.915+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:03.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:01:04.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:01:04.758+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:04.758+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:01:04.786+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:04.786+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:01:04.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.898 seconds
[2025-10-03T07:01:35.367+0000] {processor.py:157} INFO - Started process (PID=23114) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:01:35.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:01:35.371+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:35.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:01:35.913+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:01:35.935+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:35.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:01:35.961+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:35.961+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:01:35.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.617 seconds
[2025-10-03T07:02:06.173+0000] {processor.py:157} INFO - Started process (PID=23415) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:02:06.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:02:06.176+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:06.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:02:06.729+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:02:06.751+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:06.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:02:06.777+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:06.777+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:02:06.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.628 seconds
[2025-10-03T07:02:37.559+0000] {processor.py:157} INFO - Started process (PID=23722) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:02:37.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:02:37.561+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:37.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:02:38.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:02:38.137+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:38.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:02:38.163+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:38.163+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:02:38.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.627 seconds
[2025-10-03T07:03:09.074+0000] {processor.py:157} INFO - Started process (PID=24034) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:03:09.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:03:09.076+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:09.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:03:09.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:03:10.351+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:10.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:03:10.378+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:10.378+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:03:10.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.332 seconds
[2025-10-03T07:03:40.510+0000] {processor.py:157} INFO - Started process (PID=24346) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:03:40.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:03:40.512+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:40.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:03:41.044+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:03:41.449+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:41.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:03:41.477+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:41.477+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:03:41.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.994 seconds
[2025-10-03T07:04:12.058+0000] {processor.py:157} INFO - Started process (PID=24653) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:04:12.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:04:12.060+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:12.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:04:12.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:04:12.912+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:12.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:04:12.945+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:12.945+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:04:12.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.915 seconds
[2025-10-03T07:04:43.173+0000] {processor.py:157} INFO - Started process (PID=24965) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:04:43.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:04:43.175+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:43.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:04:43.694+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:04:43.715+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:43.714+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:04:43.742+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:43.742+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:04:43.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.591 seconds
[2025-10-03T07:05:14.336+0000] {processor.py:157} INFO - Started process (PID=25270) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:05:14.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:05:14.338+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:14.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:05:14.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:05:14.867+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:14.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:05:14.895+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:14.895+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:05:14.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.585 seconds
[2025-10-03T07:05:44.977+0000] {processor.py:157} INFO - Started process (PID=25577) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:05:44.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:05:44.980+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:44.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:05:45.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:05:45.542+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:45.541+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:05:45.568+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:45.568+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:05:45.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.616 seconds
[2025-10-03T07:06:15.725+0000] {processor.py:157} INFO - Started process (PID=25886) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:06:15.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:06:15.726+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:15.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:06:16.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:06:16.655+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:16.654+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:06:16.691+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:16.690+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:06:16.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.989 seconds
[2025-10-03T07:06:47.666+0000] {processor.py:157} INFO - Started process (PID=26193) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:06:47.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:06:47.668+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:47.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:06:48.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:06:48.240+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:48.239+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:06:48.272+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:48.272+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:06:48.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.631 seconds
[2025-10-03T07:07:18.790+0000] {processor.py:157} INFO - Started process (PID=26507) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:07:18.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:07:18.792+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:18.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:07:19.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:07:20.062+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:20.062+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:07:20.093+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:20.093+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:07:20.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.327 seconds
[2025-10-03T07:07:50.481+0000] {processor.py:157} INFO - Started process (PID=26819) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:07:50.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:07:50.483+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:50.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:07:51.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:07:51.037+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:51.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:07:51.064+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:51.063+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:07:51.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.607 seconds
[2025-10-03T07:08:21.277+0000] {processor.py:157} INFO - Started process (PID=27131) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:08:21.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:08:21.279+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:21.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:08:21.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:08:21.845+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:21.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:08:21.874+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:21.873+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:08:21.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.621 seconds
[2025-10-03T07:08:52.462+0000] {processor.py:157} INFO - Started process (PID=27438) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:08:52.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:08:52.465+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:52.464+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:08:52.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:08:52.912+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:52.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:08:52.941+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:52.941+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:08:52.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.504 seconds
[2025-10-03T07:09:23.034+0000] {processor.py:157} INFO - Started process (PID=27745) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:09:23.035+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:09:23.036+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:23.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:09:23.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:09:23.918+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:23.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:09:23.949+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:23.949+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:09:23.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.940 seconds
[2025-10-03T07:09:54.395+0000] {processor.py:157} INFO - Started process (PID=28057) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:09:54.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:09:54.396+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:54.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:09:54.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:09:55.847+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:10:26.192+0000] {processor.py:157} INFO - Started process (PID=28364) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:10:26.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:10:26.194+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:26.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:10:26.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:10:26.761+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:26.761+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:10:26.796+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:26.795+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:10:26.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.630 seconds
[2025-10-03T07:10:57.230+0000] {processor.py:157} INFO - Started process (PID=28671) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:10:57.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:10:57.232+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:57.232+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:10:57.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:10:58.329+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:58.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:10:58.363+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:58.363+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:10:58.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.162 seconds
[2025-10-03T07:11:29.209+0000] {processor.py:157} INFO - Started process (PID=28960) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:11:29.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:11:29.212+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:29.212+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:11:29.731+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:11:29.758+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:29.757+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:11:29.788+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:29.788+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:11:29.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.610 seconds
[2025-10-03T07:12:00.349+0000] {processor.py:157} INFO - Started process (PID=29255) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:12:00.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:12:00.352+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:00.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:12:00.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:12:00.856+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:00.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:12:00.894+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:00.894+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:12:00.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.576 seconds
[2025-10-03T07:12:31.336+0000] {processor.py:157} INFO - Started process (PID=29562) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:12:31.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:12:31.338+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:31.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:12:31.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:12:31.910+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:31.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:12:31.940+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:31.940+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:12:31.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.628 seconds
[2025-10-03T07:13:01.994+0000] {processor.py:157} INFO - Started process (PID=29866) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:13:01.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:13:01.996+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:01.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:13:02.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:13:02.569+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:02.568+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:13:02.616+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:02.616+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:13:02.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.657 seconds
[2025-10-03T07:13:33.013+0000] {processor.py:157} INFO - Started process (PID=30183) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:13:33.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:13:33.018+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:33.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:13:33.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:13:34.047+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:14:04.379+0000] {processor.py:157} INFO - Started process (PID=30503) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:14:04.380+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:14:04.381+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:04.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:14:04.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:14:05.180+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:05.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:14:05.337+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:05.337+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:14:05.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.985 seconds
[2025-10-03T07:14:36.807+0000] {processor.py:157} INFO - Started process (PID=30831) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:14:36.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:14:36.809+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:14:37.228+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:14:37.304+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:37.304+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:14:37.435+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:37.434+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:14:37.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.652 seconds
[2025-10-03T07:15:08.433+0000] {processor.py:157} INFO - Started process (PID=31153) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:15:08.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:15:08.435+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:08.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:15:08.994+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:15:09.021+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:09.020+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:15:09.059+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:09.059+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:15:09.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.654 seconds
[2025-10-03T07:15:39.487+0000] {processor.py:157} INFO - Started process (PID=31455) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:15:39.488+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:15:39.489+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:39.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:15:39.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:15:40.021+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:40.020+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:15:40.047+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:40.047+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:15:40.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.583 seconds
[2025-10-03T07:16:11.192+0000] {processor.py:157} INFO - Started process (PID=31762) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:16:11.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:16:11.193+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:16:11.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:16:11.733+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:16:11.760+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.759+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:16:11.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.592 seconds
[2025-10-03T07:16:42.141+0000] {processor.py:157} INFO - Started process (PID=32069) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:16:42.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:16:42.143+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.143+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:16:42.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:16:42.690+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:16:42.716+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.716+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:16:42.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.598 seconds
[2025-10-03T07:17:12.933+0000] {processor.py:157} INFO - Started process (PID=32378) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:17:12.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:17:12.935+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:17:13.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:17:13.501+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:13.501+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:17:13.528+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:13.528+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:17:13.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.621 seconds
[2025-10-03T07:17:44.685+0000] {processor.py:157} INFO - Started process (PID=32683) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:17:44.686+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:17:44.686+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:44.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:17:45.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:17:45.243+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:45.243+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:17:45.271+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:45.271+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:17:45.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.611 seconds
[2025-10-03T07:18:15.982+0000] {processor.py:157} INFO - Started process (PID=32990) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:18:15.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:18:15.984+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:15.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:18:16.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:18:17.598+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:18:48.101+0000] {processor.py:157} INFO - Started process (PID=33304) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:18:48.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:18:48.103+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:48.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:18:48.660+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:18:49.081+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:49.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:18:49.110+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:49.109+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:18:49.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.039 seconds
[2025-10-03T07:19:19.260+0000] {processor.py:157} INFO - Started process (PID=33614) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:19:19.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:19:19.262+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:19.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:19:19.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:19:19.916+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:19.915+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:19:19.948+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:19.948+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:19:19.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.719 seconds
[2025-10-03T07:19:50.627+0000] {processor.py:157} INFO - Started process (PID=33933) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:19:50.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:19:50.630+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:50.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:19:51.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:19:51.876+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:51.876+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:19:51.905+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:51.905+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:19:51.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.305 seconds
[2025-10-03T07:20:22.193+0000] {processor.py:157} INFO - Started process (PID=34240) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:20:22.194+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:20:22.195+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:22.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:20:22.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:20:22.746+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:22.746+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:20:22.772+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:22.772+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:20:22.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.603 seconds
[2025-10-03T07:20:53.731+0000] {processor.py:157} INFO - Started process (PID=34548) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:20:53.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:20:53.734+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:53.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:20:54.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:20:54.310+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:54.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:20:54.336+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:54.335+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:20:54.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.631 seconds
[2025-10-03T07:21:24.798+0000] {processor.py:157} INFO - Started process (PID=34855) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:21:24.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:21:24.800+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:24.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:21:25.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:21:25.649+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:25.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:21:25.679+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:25.678+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:21:25.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.916 seconds
[2025-10-03T07:21:56.136+0000] {processor.py:157} INFO - Started process (PID=35154) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:21:56.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:21:56.139+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:56.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:21:56.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:21:56.800+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:56.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:21:56.825+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:56.825+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:21:56.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.714 seconds
[2025-10-03T07:22:27.216+0000] {processor.py:157} INFO - Started process (PID=35461) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:22:27.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:22:27.219+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:27.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:22:27.805+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:22:27.826+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:27.826+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:22:27.853+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:27.852+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:22:27.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.662 seconds
[2025-10-03T07:22:58.003+0000] {processor.py:157} INFO - Started process (PID=35768) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:22:58.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T07:22:58.005+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:58.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:22:58.556+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T07:22:58.578+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:58.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:22:58.608+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:58.608+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T07:22:58.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.632 seconds
[2025-10-03T09:12:16.786+0000] {processor.py:157} INFO - Started process (PID=217) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:12:16.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:12:16.790+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:16.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:12:17.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:12:17.864+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:17.863+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:12:18.008+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:18.007+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:12:18.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.264 seconds
[2025-10-03T09:12:48.389+0000] {processor.py:157} INFO - Started process (PID=530) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:12:48.391+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:12:48.393+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:48.393+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:12:48.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:12:48.974+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:48.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:12:49.010+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:49.010+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:12:49.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.648 seconds
[2025-10-03T09:13:19.339+0000] {processor.py:157} INFO - Started process (PID=830) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:13:19.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:13:19.343+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:19.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:13:19.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:13:19.893+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:19.893+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:13:19.926+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:19.926+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:13:19.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.617 seconds
[2025-10-03T09:13:50.208+0000] {processor.py:157} INFO - Started process (PID=1134) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:13:50.210+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:13:50.211+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:50.211+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:13:50.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:13:51.068+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:51.068+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:13:51.100+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:51.100+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:13:51.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.919 seconds
[2025-10-03T09:14:21.176+0000] {processor.py:157} INFO - Started process (PID=1441) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:14:21.177+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:14:21.178+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:21.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:14:21.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:14:22.427+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:22.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:14:22.482+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:22.482+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:14:22.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.339 seconds
[2025-10-03T09:14:52.717+0000] {processor.py:157} INFO - Started process (PID=1748) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:14:52.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:14:52.719+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:52.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:14:53.276+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:14:53.305+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:53.305+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:14:53.334+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:53.333+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:14:53.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.642 seconds
[2025-10-03T09:15:23.545+0000] {processor.py:157} INFO - Started process (PID=2055) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:15:23.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:15:23.547+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:23.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:15:24.015+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:15:24.041+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:24.040+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:15:24.069+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:24.069+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:15:24.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.550 seconds
[2025-10-03T09:15:54.812+0000] {processor.py:157} INFO - Started process (PID=2362) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:15:54.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:15:54.814+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:54.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:15:55.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:15:55.635+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:55.635+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:15:55.671+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:55.671+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:15:55.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.884 seconds
[2025-10-03T09:56:06.477+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:56:06.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:56:06.482+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:06.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:56:07.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:56:07.727+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T09:56:38.038+0000] {processor.py:157} INFO - Started process (PID=516) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:56:38.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:56:38.040+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:38.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:56:38.524+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:56:39.000+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:38.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:56:39.030+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:39.029+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:56:39.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.022 seconds
[2025-10-03T09:57:09.485+0000] {processor.py:157} INFO - Started process (PID=825) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:09.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:57:09.487+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:09.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:09.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:09.934+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:09.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:09.965+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:09.965+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:57:09.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.507 seconds
[2025-10-03T09:57:40.148+0000] {processor.py:157} INFO - Started process (PID=1130) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:40.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:57:40.150+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:40.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:40.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:41.013+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:41.012+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:41.045+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:41.045+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:57:41.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.048 seconds
[2025-10-03T09:57:59.788+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:57:59.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:57:59.795+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:59.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:58:00.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:58:00.929+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:00.928+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:58:00.977+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:00.976+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:58:01.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.236 seconds
[2025-10-03T09:58:32.064+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:58:32.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:58:32.066+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:32.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:58:32.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:58:33.194+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:33.193+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:58:33.222+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:33.222+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:58:33.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.192 seconds
[2025-10-03T09:59:03.847+0000] {processor.py:157} INFO - Started process (PID=818) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:59:03.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:59:03.850+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:03.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:59:04.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:59:04.433+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:04.432+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:59:04.466+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:04.466+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:59:04.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.644 seconds
[2025-10-03T09:59:34.598+0000] {processor.py:157} INFO - Started process (PID=1125) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:59:34.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T09:59:34.600+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:34.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:59:35.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T09:59:35.170+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:35.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:59:35.213+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:35.213+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T09:59:35.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.650 seconds
[2025-10-03T10:00:05.608+0000] {processor.py:157} INFO - Started process (PID=1432) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:00:05.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:00:05.609+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:05.609+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:00:06.100+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:00:06.127+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:06.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:00:06.159+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:06.158+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:00:06.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.578 seconds
[2025-10-03T10:00:36.751+0000] {processor.py:157} INFO - Started process (PID=1739) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:00:36.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:00:36.753+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:36.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:00:37.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:00:38.531+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:38.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:00:38.565+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:38.565+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:00:38.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.848 seconds
[2025-10-03T10:01:09.138+0000] {processor.py:157} INFO - Started process (PID=2082) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:01:09.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:01:09.140+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:09.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:01:09.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:01:09.843+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:09.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:01:09.873+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:09.873+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:01:09.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.761 seconds
[2025-10-03T10:01:40.728+0000] {processor.py:157} INFO - Started process (PID=2394) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:01:40.729+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:01:40.730+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:40.730+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:01:41.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:01:41.188+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:41.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:01:41.220+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:41.220+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:01:41.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.516 seconds
[2025-10-03T10:02:11.917+0000] {processor.py:157} INFO - Started process (PID=2701) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:02:11.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:02:11.919+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:11.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:02:12.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:02:12.821+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:12.820+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:02:12.849+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:12.849+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:02:12.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.959 seconds
[2025-10-03T10:02:42.977+0000] {processor.py:157} INFO - Started process (PID=3003) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:02:42.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:02:42.979+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:42.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:02:43.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:02:43.432+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:43.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:02:43.468+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:43.467+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:02:43.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.516 seconds
[2025-10-03T10:03:13.616+0000] {processor.py:157} INFO - Started process (PID=3310) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:03:13.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:03:13.618+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:13.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:03:14.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:03:14.465+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:14.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:03:14.619+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:14.618+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:03:14.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.032 seconds
[2025-10-03T10:03:44.788+0000] {processor.py:157} INFO - Started process (PID=3616) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:03:44.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:03:44.791+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:44.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:03:45.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:03:45.505+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:45.505+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:03:45.536+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:45.535+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:03:45.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.774 seconds
[2025-10-03T10:04:16.178+0000] {processor.py:157} INFO - Started process (PID=3913) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:04:16.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:04:16.181+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:16.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:04:16.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:04:17.291+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:17.291+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:04:17.319+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:17.319+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:04:17.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.163 seconds
[2025-10-03T10:04:47.654+0000] {processor.py:157} INFO - Started process (PID=4238) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:04:47.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:04:47.656+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:47.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:04:48.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:04:48.300+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:48.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:04:48.326+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:48.326+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:04:48.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.696 seconds
[2025-10-03T10:05:18.412+0000] {processor.py:157} INFO - Started process (PID=4532) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:05:18.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:05:18.414+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:18.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:05:18.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:05:19.908+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:19.906+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:05:19.935+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:19.935+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:05:19.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.545 seconds
[2025-10-03T10:05:50.742+0000] {processor.py:157} INFO - Started process (PID=4862) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:05:50.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:05:50.744+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:50.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:05:51.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:05:51.302+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:51.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:05:51.333+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:51.332+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:05:51.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.614 seconds
[2025-10-03T10:06:22.106+0000] {processor.py:157} INFO - Started process (PID=5174) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:06:22.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:06:22.112+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:22.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:06:22.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:06:22.687+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:22.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:06:22.713+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:22.713+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:06:22.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.634 seconds
[2025-10-03T10:06:53.151+0000] {processor.py:157} INFO - Started process (PID=5481) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:06:53.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:06:53.153+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:53.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:06:53.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:06:54.850+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:54.849+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:06:54.881+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:54.881+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:06:54.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.753 seconds
[2025-10-03T10:07:25.362+0000] {processor.py:157} INFO - Started process (PID=5806) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:07:25.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:07:25.364+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:25.364+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:07:25.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:07:25.994+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:25.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:07:26.025+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:26.025+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:07:26.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.689 seconds
[2025-10-03T10:07:56.118+0000] {processor.py:157} INFO - Started process (PID=6105) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:07:56.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:07:56.121+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:56.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:07:56.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:07:56.885+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:56.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:07:56.912+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:56.912+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:07:56.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.817 seconds
[2025-10-03T10:08:27.104+0000] {processor.py:157} INFO - Started process (PID=6412) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:08:27.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:08:27.106+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:27.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:08:27.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:08:27.644+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:27.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:08:27.677+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:27.677+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:08:27.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.600 seconds
[2025-10-03T10:08:58.346+0000] {processor.py:157} INFO - Started process (PID=6717) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:08:58.347+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:08:58.349+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:58.349+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:08:58.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:08:58.973+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:58.972+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:08:59.000+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:59.000+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:08:59.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.677 seconds
[2025-10-03T10:09:29.551+0000] {processor.py:157} INFO - Started process (PID=7021) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:09:29.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:09:29.553+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:29.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:09:30.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:09:30.715+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:10:00.819+0000] {processor.py:157} INFO - Started process (PID=7333) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:10:00.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:10:00.822+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:00.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:10:01.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:10:01.444+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:01.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:10:01.473+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:01.473+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:10:01.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.681 seconds
[2025-10-03T10:10:31.592+0000] {processor.py:157} INFO - Started process (PID=7640) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:10:31.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:10:31.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:31.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:10:32.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:10:32.453+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:32.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:10:32.479+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:32.479+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:10:32.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.910 seconds
[2025-10-03T10:11:03.288+0000] {processor.py:157} INFO - Started process (PID=7954) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:11:03.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:11:03.290+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:03.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:11:03.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:11:03.835+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:03.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:11:03.863+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:03.863+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:11:03.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.600 seconds
[2025-10-03T10:11:34.295+0000] {processor.py:157} INFO - Started process (PID=8259) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:11:34.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:11:34.297+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:34.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:11:34.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:11:34.848+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:34.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:11:34.876+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:34.876+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:11:34.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.603 seconds
[2025-10-03T10:12:05.134+0000] {processor.py:157} INFO - Started process (PID=8573) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:12:05.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:12:05.136+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:05.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:12:05.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:12:05.769+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:12:35.902+0000] {processor.py:157} INFO - Started process (PID=8875) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:12:35.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:12:35.904+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:35.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:12:36.442+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:12:36.463+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:36.463+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:12:36.489+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:36.489+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:12:36.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.610 seconds
[2025-10-03T10:13:06.565+0000] {processor.py:157} INFO - Started process (PID=9180) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:13:06.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:13:06.567+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:06.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:13:07.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:13:08.357+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:08.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:13:08.388+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:08.387+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:13:08.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.849 seconds
[2025-10-03T10:13:39.486+0000] {processor.py:157} INFO - Started process (PID=9502) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:13:39.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:13:39.488+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:39.488+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:13:39.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:13:39.937+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:39.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:13:39.972+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:39.971+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:13:39.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.511 seconds
[2025-10-03T10:17:02.940+0000] {processor.py:157} INFO - Started process (PID=9730) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:17:02.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:17:02.943+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:02.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:17:03.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:17:03.946+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:03.945+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:17:04.087+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:04.087+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:17:04.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.240 seconds
[2025-10-03T10:17:34.910+0000] {processor.py:157} INFO - Started process (PID=10037) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:17:34.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:17:34.912+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:34.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:17:35.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:17:36.061+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:36.060+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:17:36.092+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:36.091+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:17:36.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.209 seconds
[2025-10-03T10:18:06.480+0000] {processor.py:157} INFO - Started process (PID=10346) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:18:06.481+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:18:06.482+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:06.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:18:06.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:18:06.987+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:06.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:18:07.016+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:07.016+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:18:07.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.559 seconds
[2025-10-03T10:18:37.358+0000] {processor.py:157} INFO - Started process (PID=10643) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:18:37.359+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:18:37.360+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:37.360+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:18:37.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:18:37.829+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:37.828+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:18:37.861+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:37.861+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:18:37.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.534 seconds
[2025-10-03T10:19:08.112+0000] {processor.py:157} INFO - Started process (PID=10950) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:19:08.113+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:19:08.114+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:08.114+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:19:08.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:19:08.577+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:08.576+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:19:08.606+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:08.606+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:19:08.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.521 seconds
[2025-10-03T10:19:38.836+0000] {processor.py:157} INFO - Started process (PID=11257) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:19:38.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:19:38.839+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:38.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:19:39.258+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:19:39.285+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:39.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:19:39.317+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:39.317+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:19:39.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.510 seconds
[2025-10-03T10:20:09.592+0000] {processor.py:157} INFO - Started process (PID=11564) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:20:09.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:20:09.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:09.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:20:10.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:20:10.059+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:10.059+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:20:10.104+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:10.103+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:20:10.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.545 seconds
[2025-10-03T10:20:40.508+0000] {processor.py:157} INFO - Started process (PID=11871) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:20:40.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:20:40.510+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:40.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:20:40.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:20:40.965+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:40.964+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:20:40.996+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:40.996+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:20:41.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.515 seconds
[2025-10-03T10:21:11.143+0000] {processor.py:157} INFO - Started process (PID=12178) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:21:11.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:21:11.145+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:11.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:21:11.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:21:11.698+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:11.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:21:11.727+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:11.726+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:21:11.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.610 seconds
[2025-10-03T10:21:41.919+0000] {processor.py:157} INFO - Started process (PID=12485) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:21:41.920+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T10:21:41.921+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:41.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:21:42.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T10:21:42.391+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:42.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:21:42.551+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:42.551+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T10:21:42.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.661 seconds
[2025-10-03T12:05:38.535+0000] {processor.py:157} INFO - Started process (PID=12800) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:05:38.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T12:05:38.539+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:38.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:05:39.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:05:39.761+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:39.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:05:39.814+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:39.814+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T12:05:39.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.336 seconds
[2025-10-03T12:22:54.415+0000] {processor.py:157} INFO - Started process (PID=13122) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:22:54.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T12:22:54.421+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:54.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:22:55.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:22:55.473+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:55.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:22:55.522+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:55.522+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T12:22:55.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.144 seconds
[2025-10-03T12:37:57.621+0000] {processor.py:157} INFO - Started process (PID=13452) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:37:57.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T12:37:57.626+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:37:57.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:37:58.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:37:58.625+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:37:58.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:37:58.719+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:37:58.719+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T12:37:58.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.142 seconds
[2025-10-03T12:39:01.325+0000] {processor.py:157} INFO - Started process (PID=13746) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:39:01.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T12:39:01.327+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:39:01.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:39:01.928+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.927+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:39:01.956+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.956+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T12:39:01.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.656 seconds
[2025-10-03T12:39:49.960+0000] {processor.py:157} INFO - Started process (PID=14051) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:39:49.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T12:39:49.998+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:49.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:40:03.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:40:03.295+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:40:03.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:40:03.555+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:40:03.554+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T12:40:03.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 13.873 seconds
[2025-10-03T12:42:31.851+0000] {processor.py:157} INFO - Started process (PID=14365) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:42:31.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T12:42:31.853+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:42:32.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T12:42:32.391+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:32.391+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:42:32.419+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:32.418+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T12:42:32.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.593 seconds
[2025-10-03T13:22:12.102+0000] {processor.py:157} INFO - Started process (PID=14466) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T13:22:12.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T13:22:12.105+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:12.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T13:22:12.785+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T13:22:12.834+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:12.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T13:22:12.866+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:12.866+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T13:22:12.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.797 seconds
[2025-10-03T18:14:57.545+0000] {processor.py:157} INFO - Started process (PID=14766) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:14:57.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T18:14:57.550+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:57.550+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:14:59.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:14:59.161+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:59.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:14:59.227+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:59.227+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T18:14:59.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.745 seconds
[2025-10-03T18:15:29.543+0000] {processor.py:157} INFO - Started process (PID=15066) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:15:29.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T18:15:29.547+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:29.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:15:30.211+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:15:30.241+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:30.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:15:30.272+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:30.271+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T18:15:30.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.757 seconds
[2025-10-03T18:16:00.427+0000] {processor.py:157} INFO - Started process (PID=15380) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:16:00.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T18:16:00.434+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:00.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:16:00.993+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:16:01.017+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:01.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:16:01.045+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:01.045+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T18:16:01.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.657 seconds
[2025-10-03T18:16:31.895+0000] {processor.py:157} INFO - Started process (PID=15680) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:16:31.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-03T18:16:31.901+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:31.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:16:32.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-03T18:16:32.642+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:32.641+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:16:32.677+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:32.676+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-03T00:00:00+00:00, run_after=2025-10-04T00:00:00+00:00
[2025-10-03T18:16:32.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.816 seconds
