[2025-10-03T06:22:58.168+0000] {processor.py:157} INFO - Started process (PID=189) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:22:58.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:22:58.175+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:22:58.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:22:59.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:22:59.698+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:22:59.698+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:22:59.740+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:22:59.740+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:22:59.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.611 seconds
[2025-10-03T06:23:30.208+0000] {processor.py:157} INFO - Started process (PID=510) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:23:30.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:23:30.210+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:30.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:23:30.955+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:23:30.986+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:30.985+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:23:31.016+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:23:31.016+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:23:31.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.839 seconds
[2025-10-03T06:24:01.885+0000] {processor.py:157} INFO - Started process (PID=817) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:24:01.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:24:01.888+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:01.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:24:02.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:24:02.911+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:24:33.104+0000] {processor.py:157} INFO - Started process (PID=1135) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:24:33.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:24:33.106+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:33.105+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:24:33.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:24:33.615+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:33.615+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:24:33.660+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:24:33.660+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:24:33.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.589 seconds
[2025-10-03T06:25:04.184+0000] {processor.py:157} INFO - Started process (PID=1431) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:25:04.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:25:04.188+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:04.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:25:05.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:25:05.715+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:05.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:25:05.755+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:05.754+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:25:05.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.621 seconds
[2025-10-03T06:25:36.143+0000] {processor.py:157} INFO - Started process (PID=1739) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:25:36.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:25:36.145+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:36.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:25:36.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:25:36.642+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:36.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:25:36.674+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:25:36.674+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:25:36.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.556 seconds
[2025-10-03T06:26:07.231+0000] {processor.py:157} INFO - Started process (PID=2046) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:26:07.233+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:26:07.234+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.233+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:26:07.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:26:07.708+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.708+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:26:07.737+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:07.737+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:26:07.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.530 seconds
[2025-10-03T06:26:38.371+0000] {processor.py:157} INFO - Started process (PID=2353) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:26:38.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:26:38.376+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:38.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:26:38.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:26:38.859+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:38.859+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:26:38.889+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:26:38.888+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:26:38.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.544 seconds
[2025-10-03T06:27:09.484+0000] {processor.py:157} INFO - Started process (PID=2660) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:27:09.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:27:09.486+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:09.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:27:09.913+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:27:10.101+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:27:40.407+0000] {processor.py:157} INFO - Started process (PID=2967) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:27:40.408+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:27:40.410+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:40.409+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:27:40.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:27:40.896+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:40.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:27:40.925+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:27:40.925+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:27:40.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.544 seconds
[2025-10-03T06:28:11.974+0000] {processor.py:157} INFO - Started process (PID=3281) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:28:11.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:28:11.976+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:11.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:28:12.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:28:12.789+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:12.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:28:12.822+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:12.822+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:28:12.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.874 seconds
[2025-10-03T06:28:43.195+0000] {processor.py:157} INFO - Started process (PID=3601) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:28:43.196+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:28:43.197+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.197+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:28:43.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:28:43.657+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:28:43.685+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:28:43.685+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:28:43.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.514 seconds
[2025-10-03T06:29:14.367+0000] {processor.py:157} INFO - Started process (PID=3906) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:29:14.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:29:14.369+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:14.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:29:14.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:29:15.090+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:15.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:29:15.264+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:15.263+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:29:15.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.929 seconds
[2025-10-03T06:29:45.553+0000] {processor.py:157} INFO - Started process (PID=4202) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:29:45.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:29:45.556+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:45.556+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:29:46.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:29:46.196+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:46.195+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:29:46.231+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:29:46.231+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:29:46.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.715 seconds
[2025-10-03T06:30:16.656+0000] {processor.py:157} INFO - Started process (PID=4509) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:30:16.657+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:30:16.658+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:16.658+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:30:17.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:30:17.131+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:17.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:30:17.341+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:17.341+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:30:17.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.709 seconds
[2025-10-03T06:30:47.785+0000] {processor.py:157} INFO - Started process (PID=4816) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:30:47.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:30:47.787+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:47.787+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:30:48.245+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:30:49.811+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:49.811+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:30:49.838+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:30:49.837+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:30:49.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.076 seconds
[2025-10-03T06:31:20.195+0000] {processor.py:157} INFO - Started process (PID=5144) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:31:20.196+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:31:20.196+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:31:20.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:31:20.771+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:31:20.796+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:20.796+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:31:20.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.624 seconds
[2025-10-03T06:31:51.357+0000] {processor.py:157} INFO - Started process (PID=5453) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:31:51.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:31:51.359+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:51.359+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:31:51.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:31:51.925+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:51.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:31:51.952+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:31:51.952+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:31:51.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.616 seconds
[2025-10-03T06:32:22.698+0000] {processor.py:157} INFO - Started process (PID=5760) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:32:22.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:32:22.700+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:22.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:32:23.220+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:32:24.195+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:32:54.329+0000] {processor.py:157} INFO - Started process (PID=6072) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:32:54.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:32:54.331+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:54.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:32:54.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:32:54.917+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:54.916+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:32:54.946+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:32:54.945+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:32:54.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.642 seconds
[2025-10-03T06:33:25.463+0000] {processor.py:157} INFO - Started process (PID=6382) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:33:25.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:33:25.465+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:25.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:33:26.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:33:26.084+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:26.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:33:26.110+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:26.109+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:33:26.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.670 seconds
[2025-10-03T06:33:56.624+0000] {processor.py:157} INFO - Started process (PID=6689) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:33:56.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:33:56.626+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:56.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:33:57.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:33:58.220+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:58.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:33:58.245+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:33:58.245+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:33:58.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.644 seconds
[2025-10-03T06:34:28.699+0000] {processor.py:157} INFO - Started process (PID=6998) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:34:28.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:34:28.701+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:28.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:34:29.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:34:29.587+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:29.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:34:29.616+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:29.616+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:34:29.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.944 seconds
[2025-10-03T06:34:59.833+0000] {processor.py:157} INFO - Started process (PID=7305) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:34:59.834+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:34:59.835+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:34:59.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:35:00.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:35:00.415+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:00.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:35:00.442+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:00.442+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:35:00.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.633 seconds
[2025-10-03T06:35:31.310+0000] {processor.py:157} INFO - Started process (PID=7610) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:35:31.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:35:31.312+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:31.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:35:31.826+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:35:32.192+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:32.191+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:35:32.219+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:35:32.219+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:35:32.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.933 seconds
[2025-10-03T06:36:02.676+0000] {processor.py:157} INFO - Started process (PID=7906) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:36:02.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:36:02.679+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:02.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:36:03.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:36:03.550+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:03.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:36:03.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:03.593+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:36:03.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.952 seconds
[2025-10-03T06:36:34.032+0000] {processor.py:157} INFO - Started process (PID=8213) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:36:34.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:36:34.034+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:34.034+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:36:34.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:36:35.157+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:35.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:36:35.184+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:36:35.184+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:36:35.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.175 seconds
[2025-10-03T06:37:05.261+0000] {processor.py:157} INFO - Started process (PID=8530) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:37:05.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:37:05.262+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:05.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:37:05.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:37:05.850+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:05.850+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:37:05.875+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:05.875+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:37:05.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.638 seconds
[2025-10-03T06:37:36.448+0000] {processor.py:157} INFO - Started process (PID=8827) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:37:36.449+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:37:36.450+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:36.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:37:36.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:37:36.991+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:36.990+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:37:37.016+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:37:37.016+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:37:37.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.592 seconds
[2025-10-03T06:38:07.640+0000] {processor.py:157} INFO - Started process (PID=9134) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:38:07.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:38:07.642+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:07.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:38:08.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:38:08.744+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:38:38.903+0000] {processor.py:157} INFO - Started process (PID=9441) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:38:38.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:38:38.904+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:38.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:38:39.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:38:39.461+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:39.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:38:39.487+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:38:39.487+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:38:39.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.608 seconds
[2025-10-03T06:39:09.622+0000] {processor.py:157} INFO - Started process (PID=9748) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:39:09.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:39:09.624+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:09.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:39:10.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:39:10.179+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:10.179+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:39:10.207+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:10.206+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:39:10.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.607 seconds
[2025-10-03T06:39:40.866+0000] {processor.py:157} INFO - Started process (PID=10055) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:39:40.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:39:40.868+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:40.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:39:41.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:39:41.880+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:41.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:39:41.909+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:39:41.909+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:39:41.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.070 seconds
[2025-10-03T06:40:12.004+0000] {processor.py:157} INFO - Started process (PID=10367) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:40:12.005+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:40:12.006+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:12.006+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:40:12.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:40:12.465+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:12.465+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:40:12.494+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:12.494+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:40:12.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.513 seconds
[2025-10-03T06:40:43.015+0000] {processor.py:157} INFO - Started process (PID=10672) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:40:43.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:40:43.017+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:43.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:40:43.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:40:44.599+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:44.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:40:44.629+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:40:44.629+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:40:44.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.640 seconds
[2025-10-03T06:41:14.901+0000] {processor.py:157} INFO - Started process (PID=10988) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:41:14.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:41:14.904+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:14.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:41:15.342+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:41:15.370+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:15.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:41:15.399+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:15.399+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:41:15.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.524 seconds
[2025-10-03T06:41:45.601+0000] {processor.py:157} INFO - Started process (PID=11295) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:41:45.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:41:45.603+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:45.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:41:46.100+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:41:46.126+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:46.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:41:46.157+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:41:46.156+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:41:46.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.580 seconds
[2025-10-03T06:42:16.243+0000] {processor.py:157} INFO - Started process (PID=11602) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:42:16.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:42:16.245+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:16.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:42:16.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:42:16.690+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:16.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:42:16.719+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:16.719+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:42:16.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.501 seconds
[2025-10-03T06:42:47.150+0000] {processor.py:157} INFO - Started process (PID=11909) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:42:47.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:42:47.152+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:47.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:42:47.581+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:42:47.607+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:47.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:42:47.637+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:42:47.637+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:42:47.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.512 seconds
[2025-10-03T06:43:17.841+0000] {processor.py:157} INFO - Started process (PID=12216) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:43:17.842+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:43:17.843+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:17.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:43:18.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:43:18.313+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:18.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:43:18.342+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:18.342+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:43:18.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.526 seconds
[2025-10-03T06:43:48.492+0000] {processor.py:157} INFO - Started process (PID=12522) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:43:48.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:43:48.494+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:48.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:43:48.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:43:49.165+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:49.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:43:49.201+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:43:49.200+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:43:49.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.738 seconds
[2025-10-03T06:44:19.977+0000] {processor.py:157} INFO - Started process (PID=12829) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:44:19.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:44:19.979+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:19.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:44:20.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:44:20.522+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:20.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:44:20.549+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:20.549+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:44:20.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.595 seconds
[2025-10-03T06:44:51.439+0000] {processor.py:157} INFO - Started process (PID=13136) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:44:51.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:44:51.441+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:51.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:44:51.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:44:52.005+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:52.005+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:44:52.030+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:44:52.030+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:44:52.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.614 seconds
[2025-10-03T06:45:22.782+0000] {processor.py:157} INFO - Started process (PID=13443) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:45:22.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:45:22.785+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:22.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:45:23.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:45:23.367+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:45:53.933+0000] {processor.py:157} INFO - Started process (PID=13750) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:45:53.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:45:53.937+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:53.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:45:54.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:45:54.680+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:54.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:45:54.708+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:45:54.708+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:45:54.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.804 seconds
[2025-10-03T06:46:24.776+0000] {processor.py:157} INFO - Started process (PID=14057) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:46:24.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:46:24.778+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:24.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:46:25.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:46:25.398+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:25.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:46:25.432+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:25.431+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:46:25.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.679 seconds
[2025-10-03T06:46:56.048+0000] {processor.py:157} INFO - Started process (PID=14364) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:46:56.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:46:56.051+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:56.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:46:56.626+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:46:56.648+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:56.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:46:56.677+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:46:56.677+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:46:56.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.651 seconds
[2025-10-03T06:47:26.893+0000] {processor.py:157} INFO - Started process (PID=14671) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:47:26.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:47:26.895+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:26.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:47:27.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:47:28.285+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T06:47:59.186+0000] {processor.py:157} INFO - Started process (PID=14978) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:47:59.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:47:59.188+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:47:59.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:47:59.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:48:00.047+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:00.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:48:00.075+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:00.074+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:48:00.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.916 seconds
[2025-10-03T06:48:30.782+0000] {processor.py:157} INFO - Started process (PID=15285) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:48:30.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:48:30.784+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:30.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:48:31.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:48:31.412+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:31.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:48:31.440+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:48:31.440+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:48:31.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.682 seconds
[2025-10-03T06:49:01.763+0000] {processor.py:157} INFO - Started process (PID=15602) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:49:01.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:49:01.765+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:01.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:49:02.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:49:02.302+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:02.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:49:02.328+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:02.328+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:49:02.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.589 seconds
[2025-10-03T06:49:32.840+0000] {processor.py:157} INFO - Started process (PID=15909) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:49:32.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:49:32.844+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:32.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:49:33.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:49:33.912+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:33.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:49:33.939+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:49:33.939+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:49:33.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.124 seconds
[2025-10-03T06:50:03.996+0000] {processor.py:157} INFO - Started process (PID=16221) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:50:03.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:50:03.997+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:03.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:50:04.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:50:04.766+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:04.766+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:50:04.795+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:04.795+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:50:04.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.824 seconds
[2025-10-03T06:50:35.230+0000] {processor.py:157} INFO - Started process (PID=16528) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:50:35.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:50:35.232+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:35.231+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:50:35.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:50:35.800+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:35.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:50:35.831+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:50:35.831+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:50:35.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.625 seconds
[2025-10-03T06:51:06.076+0000] {processor.py:157} INFO - Started process (PID=16853) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:51:06.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:51:06.079+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:06.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:51:06.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:51:07.226+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:07.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:51:07.252+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:07.252+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:51:07.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.204 seconds
[2025-10-03T06:51:37.668+0000] {processor.py:157} INFO - Started process (PID=17165) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:51:37.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:51:37.671+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:37.670+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:51:38.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:51:38.513+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:38.513+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:51:38.552+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:51:38.551+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:51:38.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.912 seconds
[2025-10-03T06:52:08.936+0000] {processor.py:157} INFO - Started process (PID=17482) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:52:08.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:52:08.939+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:08.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:52:09.530+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:52:09.553+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:09.553+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:52:09.583+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:09.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:52:09.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.679 seconds
[2025-10-03T06:52:40.096+0000] {processor.py:157} INFO - Started process (PID=17791) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:52:40.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:52:40.098+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:40.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:52:40.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:52:40.689+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:40.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:52:40.715+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:52:40.715+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:52:40.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.643 seconds
[2025-10-03T06:53:11.227+0000] {processor.py:157} INFO - Started process (PID=18098) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:53:11.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:53:11.230+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:11.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:53:11.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:53:11.802+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:11.802+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:53:11.830+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:11.830+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:53:11.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.630 seconds
[2025-10-03T06:53:41.948+0000] {processor.py:157} INFO - Started process (PID=18405) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:53:41.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:53:41.951+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:41.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:53:42.474+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:53:42.496+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:42.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:53:42.522+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:53:42.522+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:53:42.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.596 seconds
[2025-10-03T06:54:12.803+0000] {processor.py:157} INFO - Started process (PID=18712) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:54:12.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:54:12.805+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:12.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:54:13.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:54:13.381+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:13.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:54:13.408+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:13.408+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:54:13.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.629 seconds
[2025-10-03T06:54:43.965+0000] {processor.py:157} INFO - Started process (PID=19019) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:54:43.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:54:43.967+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:43.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:54:44.393+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:54:44.418+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:44.418+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:54:44.450+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:54:44.450+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:54:44.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.509 seconds
[2025-10-03T06:55:14.666+0000] {processor.py:157} INFO - Started process (PID=19326) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:55:14.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:55:14.668+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:14.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:55:15.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:55:15.118+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:15.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:55:15.148+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:15.148+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:55:15.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.509 seconds
[2025-10-03T06:55:45.233+0000] {processor.py:157} INFO - Started process (PID=19638) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:55:45.234+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:55:45.235+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:45.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:55:45.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:55:45.677+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:45.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:55:45.708+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:55:45.708+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:55:45.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.501 seconds
[2025-10-03T06:56:15.770+0000] {processor.py:157} INFO - Started process (PID=19943) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:56:15.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:56:15.771+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:15.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:56:16.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:56:16.604+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:16.604+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:56:16.634+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:16.634+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:56:16.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.894 seconds
[2025-10-03T06:56:47.123+0000] {processor.py:157} INFO - Started process (PID=20254) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:56:47.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:56:47.125+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:47.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:56:47.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:56:47.612+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:47.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:56:47.644+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:56:47.644+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:56:47.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.546 seconds
[2025-10-03T06:57:18.076+0000] {processor.py:157} INFO - Started process (PID=20561) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:57:18.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:57:18.080+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:18.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:57:18.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:57:18.535+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:18.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:57:18.565+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:18.565+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:57:18.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.519 seconds
[2025-10-03T06:57:49.156+0000] {processor.py:157} INFO - Started process (PID=20868) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:57:49.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:57:49.158+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:49.158+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:57:49.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:57:49.614+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:49.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:57:49.753+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:57:49.753+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:57:49.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.628 seconds
[2025-10-03T06:58:20.543+0000] {processor.py:157} INFO - Started process (PID=21179) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:58:20.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:58:20.545+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:20.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:58:20.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:58:20.983+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:20.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:58:21.012+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:21.012+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:58:21.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.494 seconds
[2025-10-03T06:58:51.768+0000] {processor.py:157} INFO - Started process (PID=21486) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:58:51.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:58:51.770+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:51.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:58:52.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:58:53.301+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:53.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:58:53.450+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:58:53.450+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:58:53.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.713 seconds
[2025-10-03T06:59:24.451+0000] {processor.py:157} INFO - Started process (PID=21798) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:59:24.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:59:24.453+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:24.453+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:59:24.882+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:59:25.694+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:25.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:59:25.727+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:25.726+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:59:25.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.416 seconds
[2025-10-03T06:59:55.906+0000] {processor.py:157} INFO - Started process (PID=22123) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:59:55.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T06:59:55.908+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:55.908+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:59:56.536+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T06:59:56.560+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:56.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T06:59:56.586+0000] {logging_mixin.py:149} INFO - [2025-10-03T06:59:56.585+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T06:59:56.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.701 seconds
[2025-10-03T07:00:27.581+0000] {processor.py:157} INFO - Started process (PID=22430) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:00:27.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:00:27.583+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:27.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:00:28.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:00:28.152+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:28.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:00:28.179+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:28.179+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:00:28.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.622 seconds
[2025-10-03T07:00:58.276+0000] {processor.py:157} INFO - Started process (PID=22747) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:00:58.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:00:58.278+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:58.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:00:58.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:00:58.860+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:58.860+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:00:58.895+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:00:58.895+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:00:58.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.648 seconds
[2025-10-03T07:01:29.274+0000] {processor.py:157} INFO - Started process (PID=23054) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:01:29.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:01:29.276+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:29.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:01:29.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:01:29.905+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:29.904+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:01:29.933+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:01:29.932+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:01:29.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.685 seconds
[2025-10-03T07:02:00.099+0000] {processor.py:157} INFO - Started process (PID=23362) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:02:00.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:02:00.102+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:00.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:02:00.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:02:00.679+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:00.678+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:02:00.705+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:00.704+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:02:00.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.628 seconds
[2025-10-03T07:02:31.228+0000] {processor.py:157} INFO - Started process (PID=23674) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:02:31.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:02:31.230+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:31.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:02:31.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:02:32.289+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:32.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:02:32.317+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:02:32.317+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:02:32.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.113 seconds
[2025-10-03T07:03:02.438+0000] {processor.py:157} INFO - Started process (PID=23986) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:03:02.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:03:02.440+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:02.439+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:03:03.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:03:03.411+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:03.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:03:03.439+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:03.439+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:03:03.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.025 seconds
[2025-10-03T07:03:34.094+0000] {processor.py:157} INFO - Started process (PID=24291) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:03:34.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:03:34.097+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:34.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:03:34.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:03:34.959+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:34.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:03:34.985+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:03:34.984+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:03:35.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.914 seconds
[2025-10-03T07:04:05.482+0000] {processor.py:157} INFO - Started process (PID=24613) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:04:05.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:04:05.484+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:05.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:04:06.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:04:07.210+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:07.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:04:07.237+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:07.237+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:04:07.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.778 seconds
[2025-10-03T07:04:37.543+0000] {processor.py:157} INFO - Started process (PID=24922) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:04:37.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:04:37.545+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:37.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:04:38.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:04:39.336+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:39.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:04:39.375+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:04:39.375+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:04:39.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.861 seconds
[2025-10-03T07:05:09.458+0000] {processor.py:157} INFO - Started process (PID=25234) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:05:09.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:05:09.460+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:09.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:05:09.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:05:10.020+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:10.019+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:05:10.048+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:10.048+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:05:10.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.617 seconds
[2025-10-03T07:05:40.352+0000] {processor.py:157} INFO - Started process (PID=25541) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:05:40.353+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:05:40.354+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:40.354+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:05:40.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:05:41.324+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:41.324+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:05:41.351+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:05:41.351+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:05:41.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.022 seconds
[2025-10-03T07:06:11.485+0000] {processor.py:157} INFO - Started process (PID=25848) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:06:11.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:06:11.487+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:11.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:06:12.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:06:12.058+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:12.057+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:06:12.086+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:12.085+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:06:12.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.626 seconds
[2025-10-03T07:06:42.354+0000] {processor.py:157} INFO - Started process (PID=26155) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:06:42.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:06:42.357+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:42.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:06:42.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:06:43.205+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:43.205+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:06:43.232+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:06:43.232+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:06:43.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.902 seconds
[2025-10-03T07:07:13.742+0000] {processor.py:157} INFO - Started process (PID=26467) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:07:13.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:07:13.744+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:13.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:07:14.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:07:14.299+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:14.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:07:14.326+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:14.326+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:07:14.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.608 seconds
[2025-10-03T07:07:44.972+0000] {processor.py:157} INFO - Started process (PID=26774) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:07:44.973+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:07:44.974+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:44.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:07:45.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:07:46.682+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:46.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:07:46.710+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:07:46.710+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:07:46.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.761 seconds
[2025-10-03T07:08:16.788+0000] {processor.py:157} INFO - Started process (PID=27081) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:08:16.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:08:16.791+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:16.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:08:17.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:08:17.684+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:17.684+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:08:17.714+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:17.714+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:08:17.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.950 seconds
[2025-10-03T07:08:47.977+0000] {processor.py:157} INFO - Started process (PID=27388) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:08:47.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:08:47.980+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:08:47.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:08:48.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:08:49.038+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:09:19.451+0000] {processor.py:157} INFO - Started process (PID=27707) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:09:19.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:09:19.454+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:19.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:09:19.946+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:09:20.161+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:20.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:09:20.190+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:20.190+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:09:20.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.765 seconds
[2025-10-03T07:09:50.866+0000] {processor.py:157} INFO - Started process (PID=28019) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:09:50.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:09:50.869+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:50.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:09:51.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:09:51.357+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:51.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:09:51.389+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:09:51.389+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:09:51.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.549 seconds
[2025-10-03T07:10:21.686+0000] {processor.py:157} INFO - Started process (PID=28326) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:10:21.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:10:21.689+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:21.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:10:22.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:10:22.287+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:22.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:10:22.318+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:22.318+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:10:22.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.665 seconds
[2025-10-03T07:10:52.593+0000] {processor.py:157} INFO - Started process (PID=28636) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:10:52.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:10:52.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:52.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:10:53.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:10:54.111+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:54.110+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:10:54.146+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:10:54.146+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:10:54.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.586 seconds
[2025-10-03T07:11:29.003+0000] {processor.py:157} INFO - Started process (PID=28948) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:11:29.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:11:29.023+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:29.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:11:29.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:11:30.676+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:30.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:11:30.707+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:11:30.706+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:11:30.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.733 seconds
[2025-10-03T07:12:00.935+0000] {processor.py:157} INFO - Started process (PID=29278) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:12:00.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:12:00.938+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:00.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:12:01.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:12:01.752+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:01.751+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:12:01.784+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:01.784+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:12:01.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.879 seconds
[2025-10-03T07:12:32.152+0000] {processor.py:157} INFO - Started process (PID=29595) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:12:32.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:12:32.155+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:12:32.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:12:32.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:12:32.973+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:13:03.008+0000] {processor.py:157} INFO - Started process (PID=29904) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:13:03.009+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:13:03.010+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:03.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:13:03.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:13:03.706+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:03.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:13:03.737+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:03.737+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:13:03.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.755 seconds
[2025-10-03T07:13:34.084+0000] {processor.py:157} INFO - Started process (PID=30211) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:13:34.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:13:34.086+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:34.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:13:34.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:13:35.135+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:35.135+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:13:35.164+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:13:35.164+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:13:35.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.108 seconds
[2025-10-03T07:14:05.401+0000] {processor.py:157} INFO - Started process (PID=30523) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:14:05.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:14:05.408+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:05.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:14:05.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:14:05.962+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:05.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:14:06.113+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:06.113+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:14:06.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.740 seconds
[2025-10-03T07:14:36.172+0000] {processor.py:157} INFO - Started process (PID=30805) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:14:36.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:14:36.174+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:14:36.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:14:36.717+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:14:36.746+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:14:36.746+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:14:36.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.598 seconds
[2025-10-03T07:15:07.289+0000] {processor.py:157} INFO - Started process (PID=31112) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:15:07.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:15:07.291+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:07.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:15:07.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:15:07.809+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:07.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:15:07.965+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:07.964+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:15:07.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.700 seconds
[2025-10-03T07:15:38.561+0000] {processor.py:157} INFO - Started process (PID=31421) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:15:38.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:15:38.563+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:38.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:15:39.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:15:39.174+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:39.173+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:15:39.201+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:15:39.201+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:15:39.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.662 seconds
[2025-10-03T07:16:09.590+0000] {processor.py:157} INFO - Started process (PID=31728) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:16:09.591+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:16:09.593+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:09.592+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:16:10.148+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:16:11.129+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.128+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:16:11.157+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:11.157+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:16:11.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.593 seconds
[2025-10-03T07:16:41.290+0000] {processor.py:157} INFO - Started process (PID=32043) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:16:41.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:16:41.292+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:41.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:16:41.932+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:16:42.080+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:16:42.107+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:16:42.107+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:16:42.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.843 seconds
[2025-10-03T07:17:12.258+0000] {processor.py:157} INFO - Started process (PID=32352) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:17:12.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:17:12.260+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:17:12.820+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:17:12.844+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.842+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:17:12.871+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:12.871+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:17:12.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.642 seconds
[2025-10-03T07:17:43.121+0000] {processor.py:157} INFO - Started process (PID=32654) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:17:43.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:17:43.123+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:43.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:17:43.707+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:17:43.731+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:43.730+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:17:43.758+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:17:43.758+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:17:43.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.661 seconds
[2025-10-03T07:18:14.227+0000] {processor.py:157} INFO - Started process (PID=32961) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:18:14.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:18:14.229+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:14.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:18:14.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:18:15.375+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:18:45.849+0000] {processor.py:157} INFO - Started process (PID=33268) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:18:45.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:18:45.851+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:45.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:18:46.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:18:46.420+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:46.419+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:18:46.462+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:18:46.461+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:18:46.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.712 seconds
[2025-10-03T07:19:17.284+0000] {processor.py:157} INFO - Started process (PID=33575) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:19:17.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:19:17.287+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:17.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:19:17.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:19:18.575+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:18.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:19:18.601+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:18.600+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:19:18.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.341 seconds
[2025-10-03T07:19:49.511+0000] {processor.py:157} INFO - Started process (PID=33893) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:19:49.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:19:49.513+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:49.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:19:50.071+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:19:50.456+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:50.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:19:50.514+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:19:50.513+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:19:50.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.059 seconds
[2025-10-03T07:20:21.811+0000] {processor.py:157} INFO - Started process (PID=34217) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:20:21.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:20:21.813+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:21.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:20:22.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:20:22.811+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:22.811+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:20:22.840+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:22.840+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:20:22.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.052 seconds
[2025-10-03T07:20:52.997+0000] {processor.py:157} INFO - Started process (PID=34535) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:20:52.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:20:52.999+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:52.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:20:53.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:20:53.673+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:53.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:20:53.706+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:20:53.706+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:20:53.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.738 seconds
[2025-10-03T07:21:24.262+0000] {processor.py:157} INFO - Started process (PID=34839) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:21:24.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:21:24.264+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:24.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:21:24.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:21:26.023+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.8), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T07:21:56.125+0000] {processor.py:157} INFO - Started process (PID=35151) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:21:56.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:21:56.127+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:56.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:21:56.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:21:56.800+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:56.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:21:56.825+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:21:56.825+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:21:56.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.723 seconds
[2025-10-03T07:22:27.204+0000] {processor.py:157} INFO - Started process (PID=35458) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:22:27.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:22:27.206+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:27.206+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:22:27.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:22:27.820+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:27.819+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:22:27.850+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:27.850+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:22:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.673 seconds
[2025-10-03T07:22:57.992+0000] {processor.py:157} INFO - Started process (PID=35765) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:22:57.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T07:22:57.994+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:57.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:22:58.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T07:22:58.544+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:58.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T07:22:58.571+0000] {logging_mixin.py:149} INFO - [2025-10-03T07:22:58.571+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T07:22:58.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.607 seconds
[2025-10-03T09:12:13.374+0000] {processor.py:157} INFO - Started process (PID=193) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:12:13.377+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:12:13.398+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:13.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:12:16.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:12:16.629+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:16.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:12:16.683+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:16.683+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:12:16.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 3.440 seconds
[2025-10-03T09:12:46.793+0000] {processor.py:157} INFO - Started process (PID=500) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:12:46.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:12:46.796+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:46.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:12:47.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:12:47.452+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:47.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:12:47.482+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:12:47.482+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:12:47.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.720 seconds
[2025-10-03T09:13:17.715+0000] {processor.py:157} INFO - Started process (PID=807) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:13:17.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:13:17.717+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:17.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:13:18.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:13:18.220+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:18.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:13:18.257+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:18.256+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:13:18.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.569 seconds
[2025-10-03T09:13:48.611+0000] {processor.py:157} INFO - Started process (PID=1121) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:13:48.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:13:48.613+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:48.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:13:49.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:13:49.112+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:49.112+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:13:49.142+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:13:49.141+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:13:49.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.556 seconds
[2025-10-03T09:14:19.576+0000] {processor.py:157} INFO - Started process (PID=1428) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:14:19.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:14:19.577+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:19.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:14:20.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:14:20.079+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:20.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:14:20.115+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:20.115+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:14:20.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.563 seconds
[2025-10-03T09:14:50.915+0000] {processor.py:157} INFO - Started process (PID=1735) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:14:50.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:14:50.917+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:50.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:14:51.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:14:51.622+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:51.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:14:51.656+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:14:51.656+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:14:51.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.765 seconds
[2025-10-03T09:15:22.300+0000] {processor.py:157} INFO - Started process (PID=2042) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:15:22.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:15:22.303+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:22.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:15:22.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:15:22.776+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:22.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:15:22.809+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:22.809+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:15:22.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.536 seconds
[2025-10-03T09:15:53.447+0000] {processor.py:157} INFO - Started process (PID=2349) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:15:53.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:15:53.448+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:53.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:15:53.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:15:53.960+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:53.959+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:15:53.991+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:15:53.990+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:15:54.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.568 seconds
[2025-10-03T09:56:04.409+0000] {processor.py:157} INFO - Started process (PID=177) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:56:04.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:56:04.412+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:04.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:56:06.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:56:06.372+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:06.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:56:06.409+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:06.409+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:56:06.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.032 seconds
[2025-10-03T09:56:37.356+0000] {processor.py:157} INFO - Started process (PID=492) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:56:37.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:56:37.359+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:37.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:56:37.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:56:37.957+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:37.957+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:56:37.988+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:56:37.988+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:56:38.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.657 seconds
[2025-10-03T09:57:08.530+0000] {processor.py:157} INFO - Started process (PID=799) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:08.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:57:08.532+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:08.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:08.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:08.995+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:08.994+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:09.023+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:09.023+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:57:09.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.517 seconds
[2025-10-03T09:57:39.554+0000] {processor.py:157} INFO - Started process (PID=1106) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:39.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:57:39.556+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:39.556+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:40.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:40.063+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:40.062+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:40.094+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:40.094+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:57:40.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.566 seconds
[2025-10-03T09:57:58.689+0000] {processor.py:157} INFO - Started process (PID=170) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:58.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:57:58.695+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:58.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:59.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:57:59.644+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:59.644+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:57:59.688+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:57:59.688+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:57:59.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.047 seconds
[2025-10-03T09:58:29.917+0000] {processor.py:157} INFO - Started process (PID=478) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:58:29.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:58:29.919+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:29.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:58:30.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:58:30.845+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:30.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:58:30.873+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:58:30.873+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:58:30.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.988 seconds
[2025-10-03T09:59:01.214+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:59:01.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:59:01.217+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:01.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:59:01.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:59:02.869+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:02.869+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:59:02.900+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:02.900+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:59:02.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.711 seconds
[2025-10-03T09:59:33.082+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:59:33.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T09:59:33.086+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:33.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:59:33.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T09:59:33.624+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:33.623+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T09:59:33.660+0000] {logging_mixin.py:149} INFO - [2025-10-03T09:59:33.660+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T09:59:33.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.614 seconds
[2025-10-03T10:00:04.012+0000] {processor.py:157} INFO - Started process (PID=1406) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:00:04.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:00:04.014+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:04.014+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:00:04.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:00:04.511+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:04.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:00:04.541+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:04.540+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:00:04.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.554 seconds
[2025-10-03T10:00:34.660+0000] {processor.py:157} INFO - Started process (PID=1713) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:00:34.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:00:34.662+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:34.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:00:35.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:00:36.026+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:36.025+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:00:36.055+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:00:36.055+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:00:36.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.420 seconds
[2025-10-03T10:01:06.115+0000] {processor.py:157} INFO - Started process (PID=2033) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:01:06.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:01:06.116+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:06.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:01:06.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:01:06.723+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:06.722+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:01:06.753+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:06.753+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:01:06.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.663 seconds
[2025-10-03T10:01:36.885+0000] {processor.py:157} INFO - Started process (PID=2338) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:01:36.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:01:36.887+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:36.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:01:37.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:01:38.452+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:38.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:01:38.482+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:01:38.482+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:01:38.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.623 seconds
[2025-10-03T10:02:08.547+0000] {processor.py:157} INFO - Started process (PID=2655) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:02:08.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:02:08.548+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:08.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:02:08.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:02:08.994+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:08.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:02:09.023+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:09.023+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:02:09.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.500 seconds
[2025-10-03T10:02:39.588+0000] {processor.py:157} INFO - Started process (PID=2959) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:02:39.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:02:39.590+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:39.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:02:40.033+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:02:40.059+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:40.058+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:02:40.091+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:02:40.091+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:02:40.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.530 seconds
[2025-10-03T10:03:10.864+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:03:10.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:03:10.866+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:10.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:03:11.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:03:12.316+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:03:42.966+0000] {processor.py:157} INFO - Started process (PID=3583) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:03:42.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:03:42.969+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:42.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:03:43.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:03:43.431+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:43.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:03:43.580+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:03:43.580+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:03:43.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.643 seconds
[2025-10-03T10:04:13.847+0000] {processor.py:157} INFO - Started process (PID=3890) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:04:13.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:04:13.849+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:13.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:04:14.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:04:14.290+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:14.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:04:14.319+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:14.319+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:04:14.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.603 seconds
[2025-10-03T10:04:44.730+0000] {processor.py:157} INFO - Started process (PID=4195) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:04:44.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:04:44.732+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:44.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:04:45.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:04:45.288+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:45.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:04:45.313+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:04:45.313+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:04:45.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.607 seconds
[2025-10-03T10:05:15.689+0000] {processor.py:157} INFO - Started process (PID=4504) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:05:15.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:05:15.694+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:15.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:05:16.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:05:16.266+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:16.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:05:16.293+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:16.293+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:05:16.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.628 seconds
[2025-10-03T10:05:46.686+0000] {processor.py:157} INFO - Started process (PID=4809) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:05:46.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:05:46.689+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:46.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:05:47.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:05:47.326+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:47.326+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:05:47.357+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:05:47.356+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:05:47.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.696 seconds
[2025-10-03T10:06:17.510+0000] {processor.py:157} INFO - Started process (PID=5105) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:06:17.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:06:17.512+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:17.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:06:18.173+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:06:19.208+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:06:49.615+0000] {processor.py:157} INFO - Started process (PID=5428) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:06:49.616+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:06:49.617+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:49.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:06:50.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:06:50.692+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:50.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:06:50.719+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:06:50.719+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:06:50.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.128 seconds
[2025-10-03T10:07:20.940+0000] {processor.py:157} INFO - Started process (PID=5745) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:07:20.941+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:07:20.942+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:20.942+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:07:21.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:07:21.471+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:21.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:07:21.505+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:21.505+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:07:21.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.594 seconds
[2025-10-03T10:07:52.220+0000] {processor.py:157} INFO - Started process (PID=6041) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:07:52.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:07:52.222+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:52.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:07:52.788+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:07:52.811+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:52.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:07:52.837+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:07:52.836+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:07:52.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.639 seconds
[2025-10-03T10:08:23.696+0000] {processor.py:157} INFO - Started process (PID=6348) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:08:23.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:08:23.698+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:23.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:08:24.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:08:25.066+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:08:55.236+0000] {processor.py:157} INFO - Started process (PID=6665) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:08:55.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:08:55.238+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:55.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:08:55.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:08:55.788+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:55.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:08:55.813+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:08:55.813+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:08:55.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.599 seconds
[2025-10-03T10:09:26.467+0000] {processor.py:157} INFO - Started process (PID=6975) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:09:26.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:09:26.468+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:26.468+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:09:27.031+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:09:27.479+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:27.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:09:27.509+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:27.509+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:09:27.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.068 seconds
[2025-10-03T10:09:57.928+0000] {processor.py:157} INFO - Started process (PID=7282) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:09:57.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:09:57.930+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:57.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:09:58.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:09:58.574+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:58.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:09:58.604+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:09:58.603+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:09:58.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.699 seconds
[2025-10-03T10:10:29.079+0000] {processor.py:157} INFO - Started process (PID=7589) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:10:29.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:10:29.081+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:29.081+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:10:29.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:10:30.044+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:30.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:10:30.071+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:10:30.071+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:10:30.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.014 seconds
[2025-10-03T10:11:00.571+0000] {processor.py:157} INFO - Started process (PID=7907) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:11:00.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:11:00.573+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:00.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:11:01.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:11:01.096+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:01.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:11:01.130+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:01.129+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:11:01.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.593 seconds
[2025-10-03T10:11:31.233+0000] {processor.py:157} INFO - Started process (PID=8203) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:11:31.234+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:11:31.235+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:31.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:11:31.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:11:31.780+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:31.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:11:31.806+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:11:31.806+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:11:31.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.595 seconds
[2025-10-03T10:12:01.860+0000] {processor.py:157} INFO - Started process (PID=8507) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:12:01.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:12:01.862+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:01.862+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:12:02.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:12:02.483+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:02.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:12:02.512+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:02.511+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:12:02.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.675 seconds
[2025-10-03T10:12:32.929+0000] {processor.py:157} INFO - Started process (PID=8811) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:12:32.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:12:32.931+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:32.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:12:33.472+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:12:33.494+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:33.494+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:12:33.520+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:12:33.520+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:12:33.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.615 seconds
[2025-10-03T10:13:04.095+0000] {processor.py:157} INFO - Started process (PID=9118) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:13:04.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:13:04.097+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:04.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:13:04.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:13:05.990+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:13:36.894+0000] {processor.py:157} INFO - Started process (PID=9443) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:13:36.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:13:36.897+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:13:36.897+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:13:37.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:13:38.151+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:17:00.815+0000] {processor.py:157} INFO - Started process (PID=9705) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:17:00.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:17:00.828+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:00.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:17:02.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:17:02.982+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:17:33.430+0000] {processor.py:157} INFO - Started process (PID=10013) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:17:33.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:17:33.433+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:17:33.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:17:33.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:17:35.003+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-03T10:18:05.862+0000] {processor.py:157} INFO - Started process (PID=10333) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:18:05.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:18:05.864+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:05.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:18:06.268+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:18:06.391+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:06.390+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:18:06.421+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:06.420+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:18:06.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.588 seconds
[2025-10-03T10:18:37.348+0000] {processor.py:157} INFO - Started process (PID=10640) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:18:37.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:18:37.350+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:37.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:18:37.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:18:37.827+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:37.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:18:37.857+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:18:37.857+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:18:37.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.537 seconds
[2025-10-03T10:19:08.100+0000] {processor.py:157} INFO - Started process (PID=10947) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:19:08.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:19:08.102+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:08.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:19:08.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:19:08.564+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:08.564+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:19:08.594+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:08.593+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:19:08.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.519 seconds
[2025-10-03T10:19:38.822+0000] {processor.py:157} INFO - Started process (PID=11254) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:19:38.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:19:38.825+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:38.824+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:19:39.258+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:19:39.290+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:39.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:19:39.322+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:19:39.322+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:19:39.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.528 seconds
[2025-10-03T10:20:09.580+0000] {processor.py:157} INFO - Started process (PID=11561) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:20:09.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:20:09.583+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:09.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:20:09.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:20:10.036+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:10.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:20:10.080+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:10.080+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:20:10.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.533 seconds
[2025-10-03T10:20:40.496+0000] {processor.py:157} INFO - Started process (PID=11868) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:20:40.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:20:40.498+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:40.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:20:40.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:20:40.946+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:40.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:20:40.977+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:20:40.977+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:20:40.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.507 seconds
[2025-10-03T10:21:11.132+0000] {processor.py:157} INFO - Started process (PID=12175) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:21:11.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:21:11.134+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:11.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:21:11.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:21:11.692+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:11.690+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:21:11.722+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:11.721+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:21:11.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.614 seconds
[2025-10-03T10:21:41.907+0000] {processor.py:157} INFO - Started process (PID=12482) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:21:41.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T10:21:41.910+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:41.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:21:42.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T10:21:42.372+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:42.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T10:21:42.404+0000] {logging_mixin.py:149} INFO - [2025-10-03T10:21:42.404+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T10:21:42.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.644 seconds
[2025-10-03T12:05:38.511+0000] {processor.py:157} INFO - Started process (PID=12797) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:05:38.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T12:05:38.518+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:38.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:05:39.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:05:39.674+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:39.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:05:39.732+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:05:39.732+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T12:05:39.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.263 seconds
[2025-10-03T12:06:10.270+0000] {processor.py:157} INFO - Started process (PID=13101) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:06:10.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T12:06:10.303+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:06:10.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:22:53.679+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:53.676+0000] {timeout.py:68} ERROR - Process timed out, PID: 13101
[2025-10-03T12:22:53.791+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:22:53.766+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistic_dag2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistic_dag2.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 11, in <module>
    __import__(dependency)
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/__init__.py", line 150, in <module>
    from . import core
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/__init__.py", line 72, in <module>
    from . import numeric
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/numeric.py", line 2526, in <module>
    from . import arrayprint
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/arrayprint.py", line 1479, in <module>
    def array_repr(arr, max_line_width=None, precision=None, suppress_small=None):
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/overrides.py", line 198, in decorator
    source, filename='<__array_function__ internals>', mode='exec')
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistic_dag2.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 13101
[2025-10-03T12:22:53.807+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:22:54.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1003.894 seconds
[2025-10-03T12:23:25.761+0000] {processor.py:157} INFO - Started process (PID=13402) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:23:25.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T12:23:25.794+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:23:25.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:37:56.584+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:37:56.582+0000] {timeout.py:68} ERROR - Process timed out, PID: 13402
[2025-10-03T12:37:56.594+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function _collection_gced at 0x7f3cfcccf320>
[2025-10-03T12:37:56.604+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2025-10-03T12:37:56.606+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/event/registry.py", line 53, in _collection_gced
[2025-10-03T12:37:56.607+0000] {logging_mixin.py:149} WARNING -     def _collection_gced(ref):
[2025-10-03T12:37:56.609+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2025-10-03T12:37:56.610+0000] {logging_mixin.py:149} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2025-10-03T12:37:56.611+0000] {logging_mixin.py:149} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistic_dag2.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 13402
[2025-10-03T12:37:56.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:38:59.952+0000] {processor.py:157} INFO - Started process (PID=13713) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:39:00.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T12:39:00.147+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:00.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:39:01.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:39:01.219+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:39:01.250+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:01.250+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T12:39:01.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.361 seconds
[2025-10-03T12:39:32.883+0000] {processor.py:157} INFO - Started process (PID=14027) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:39:32.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T12:39:32.952+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:32.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:39:47.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:39:47.560+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:47.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:39:48.324+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:39:48.321+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T12:39:48.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 16.159 seconds
[2025-10-03T12:42:31.085+0000] {processor.py:157} INFO - Started process (PID=14339) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:42:31.086+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T12:42:31.088+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.087+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:42:31.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T12:42:31.752+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.751+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T12:42:31.785+0000] {logging_mixin.py:149} INFO - [2025-10-03T12:42:31.785+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T12:42:31.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.734 seconds
[2025-10-03T13:22:11.038+0000] {processor.py:157} INFO - Started process (PID=14440) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T13:22:11.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T13:22:11.043+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:11.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T13:22:11.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T13:22:11.789+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:11.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T13:22:11.839+0000] {logging_mixin.py:149} INFO - [2025-10-03T13:22:11.839+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T13:22:12.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.012 seconds
[2025-10-03T18:14:54.850+0000] {processor.py:157} INFO - Started process (PID=14733) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:14:54.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T18:14:54.873+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:54.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:14:57.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:14:57.227+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:57.225+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:14:57.320+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:14:57.320+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T18:14:57.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.530 seconds
[2025-10-03T18:15:27.747+0000] {processor.py:157} INFO - Started process (PID=15037) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:15:27.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T18:15:27.753+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:27.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:15:28.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:15:28.498+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:28.497+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:15:28.525+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:28.525+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T18:15:28.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.803 seconds
[2025-10-03T18:15:58.689+0000] {processor.py:157} INFO - Started process (PID=15344) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:15:58.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T18:15:58.692+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:58.691+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:15:59.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:15:59.289+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:59.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:15:59.313+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:15:59.313+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T18:15:59.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.646 seconds
[2025-10-03T18:16:30.184+0000] {processor.py:157} INFO - Started process (PID=15651) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:16:30.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-03T18:16:30.186+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:30.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:16:30.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-03T18:16:30.856+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:30.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-03T18:16:30.885+0000] {logging_mixin.py:149} INFO - [2025-10-03T18:16:30.885+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-03T10:00:00+00:00, run_after=2025-10-04T10:00:00+00:00
[2025-10-03T18:16:30.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.727 seconds
