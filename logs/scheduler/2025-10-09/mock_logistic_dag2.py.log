[2025-10-09T08:00:06.017+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:00:06.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:00:06.022+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:00:06.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:00:07.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:00:07.913+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:00:07.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:00:07.972+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:00:07.972+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:00:08.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.006 seconds
[2025-10-09T08:00:38.156+0000] {processor.py:157} INFO - Started process (PID=488) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:00:38.158+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:00:38.160+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:00:38.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:00:38.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:00:38.891+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:00:38.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:00:38.918+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:00:38.918+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:00:38.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.783 seconds
[2025-10-09T08:01:09.453+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:01:09.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:01:09.456+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:01:09.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:01:09.905+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:01:09.934+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:01:09.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:01:09.968+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:01:09.968+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:01:09.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.548 seconds
[2025-10-09T08:01:40.388+0000] {processor.py:157} INFO - Started process (PID=1108) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:01:40.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:01:40.391+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:01:40.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:01:40.877+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:01:40.922+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:01:40.921+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:01:40.963+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:01:40.962+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:01:40.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.607 seconds
[2025-10-09T08:02:11.349+0000] {processor.py:157} INFO - Started process (PID=1415) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:02:11.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:02:11.352+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:02:11.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:02:11.789+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:02:11.822+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:02:11.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:02:11.863+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:02:11.863+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:02:11.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.543 seconds
[2025-10-09T08:02:42.314+0000] {processor.py:157} INFO - Started process (PID=1730) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:02:42.315+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:02:42.316+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:02:42.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:02:42.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:02:42.772+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:02:42.771+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:02:42.856+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:02:42.856+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:02:42.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.583 seconds
[2025-10-09T08:03:13.040+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:03:13.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:03:13.043+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:03:13.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:03:13.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:03:13.567+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:03:13.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:03:13.596+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:03:13.595+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:03:13.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.620 seconds
[2025-10-09T08:03:43.772+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:03:43.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:03:43.774+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:03:43.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:03:44.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:03:44.249+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:03:44.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:03:44.335+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:03:44.335+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:03:44.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.590 seconds
[2025-10-09T08:04:14.594+0000] {processor.py:157} INFO - Started process (PID=2666) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:04:14.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:04:14.596+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:04:14.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:04:15.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:04:15.119+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:04:15.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:04:15.148+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:04:15.148+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:04:15.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.578 seconds
[2025-10-09T08:04:45.701+0000] {processor.py:157} INFO - Started process (PID=2965) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:04:45.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:04:45.705+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:04:45.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:04:46.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:04:46.182+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:04:46.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:04:46.211+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:04:46.211+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:04:46.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.534 seconds
[2025-10-09T08:05:17.088+0000] {processor.py:157} INFO - Started process (PID=3272) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:05:17.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:05:17.090+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:05:17.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:05:17.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:05:17.571+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:05:17.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:05:17.749+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:05:17.749+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:05:17.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.706 seconds
[2025-10-09T08:05:48.494+0000] {processor.py:157} INFO - Started process (PID=3579) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:05:48.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:05:48.498+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:05:48.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:05:48.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:05:48.969+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:05:48.968+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:05:48.998+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:05:48.998+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:05:49.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.529 seconds
[2025-10-09T08:06:19.146+0000] {processor.py:157} INFO - Started process (PID=3883) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:06:19.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:06:19.148+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:06:19.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:06:19.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:06:19.613+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:06:19.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:06:19.745+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:06:19.745+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:06:19.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.627 seconds
[2025-10-09T08:06:50.310+0000] {processor.py:157} INFO - Started process (PID=4200) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:06:50.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:06:50.313+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:06:50.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:06:50.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:06:50.878+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:06:50.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:06:50.904+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:06:50.904+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:06:50.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.619 seconds
[2025-10-09T08:07:21.761+0000] {processor.py:157} INFO - Started process (PID=4510) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:07:21.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:07:21.764+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:07:21.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:07:22.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:07:22.363+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:07:22.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:07:22.388+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:07:22.388+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:07:22.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.653 seconds
[2025-10-09T08:07:53.108+0000] {processor.py:157} INFO - Started process (PID=4817) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:07:53.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:07:53.110+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:07:53.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:07:53.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:07:53.710+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:07:53.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:07:53.736+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:07:53.736+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:07:53.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.651 seconds
[2025-10-09T08:08:24.498+0000] {processor.py:157} INFO - Started process (PID=5124) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:08:24.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:08:24.501+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:08:24.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:08:25.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:08:25.082+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:08:25.082+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:08:25.117+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:08:25.117+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:08:25.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.646 seconds
[2025-10-09T08:08:55.201+0000] {processor.py:157} INFO - Started process (PID=5431) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:08:55.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:08:55.203+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:08:55.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:08:55.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:08:55.860+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:08:55.859+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:08:55.893+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:08:55.892+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:08:55.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.725 seconds
[2025-10-09T08:09:26.759+0000] {processor.py:157} INFO - Started process (PID=5738) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:09:26.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:09:26.762+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:09:26.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:09:27.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:09:27.407+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:09:27.406+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:09:27.436+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:09:27.436+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:09:27.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.703 seconds
[2025-10-09T08:09:58.338+0000] {processor.py:157} INFO - Started process (PID=6045) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:09:58.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:09:58.340+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:09:58.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:09:58.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:09:58.917+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:09:58.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:09:58.945+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:09:58.945+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:09:58.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.629 seconds
[2025-10-09T08:10:29.767+0000] {processor.py:157} INFO - Started process (PID=6352) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:10:29.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:10:29.769+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:10:29.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:10:30.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:10:30.335+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:10:30.334+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:10:30.364+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:10:30.364+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:10:30.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.623 seconds
[2025-10-09T08:11:01.052+0000] {processor.py:157} INFO - Started process (PID=6659) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:11:01.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:11:01.054+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:11:01.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:11:01.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:11:01.655+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:11:01.655+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:11:01.682+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:11:01.682+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:11:01.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.653 seconds
[2025-10-09T08:11:32.532+0000] {processor.py:157} INFO - Started process (PID=6966) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:11:32.533+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:11:32.533+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:11:32.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:11:33.069+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:11:33.089+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:11:33.088+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:11:33.116+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:11:33.116+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:11:33.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.608 seconds
[2025-10-09T08:12:03.877+0000] {processor.py:157} INFO - Started process (PID=7283) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:12:03.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:12:03.879+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:12:03.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:12:04.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:12:04.428+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:12:04.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:12:04.456+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:12:04.456+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:12:04.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.605 seconds
[2025-10-09T08:12:35.415+0000] {processor.py:157} INFO - Started process (PID=7590) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:12:35.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:12:35.419+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:12:35.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:12:35.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:12:35.997+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:12:35.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:12:36.026+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:12:36.026+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:12:36.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.634 seconds
[2025-10-09T08:13:06.846+0000] {processor.py:157} INFO - Started process (PID=7897) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:13:06.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:13:06.848+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:13:06.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:13:07.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:13:07.459+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:13:07.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:13:07.487+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:13:07.487+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:13:07.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.665 seconds
[2025-10-09T08:13:38.258+0000] {processor.py:157} INFO - Started process (PID=8204) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:13:38.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:13:38.262+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:13:38.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:13:38.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:13:38.830+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:13:38.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:13:38.855+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:13:38.855+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:13:38.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.622 seconds
[2025-10-09T08:14:09.431+0000] {processor.py:157} INFO - Started process (PID=8511) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:14:09.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:14:09.433+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:14:09.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:14:10.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:14:10.045+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:14:10.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:14:10.072+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:14:10.072+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:14:10.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.666 seconds
[2025-10-09T08:14:40.965+0000] {processor.py:157} INFO - Started process (PID=8818) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:14:40.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:14:40.968+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:14:40.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:14:41.513+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:14:41.536+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:14:41.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:14:41.563+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:14:41.563+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:14:41.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.625 seconds
[2025-10-09T08:15:11.822+0000] {processor.py:157} INFO - Started process (PID=9132) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:15:11.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:15:11.825+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:15:11.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:15:12.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:15:12.322+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:15:12.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:15:12.355+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:15:12.355+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:15:12.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.559 seconds
[2025-10-09T08:15:43.247+0000] {processor.py:157} INFO - Started process (PID=9447) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:15:43.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:15:43.249+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:15:43.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:15:43.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:15:43.762+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:15:43.761+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:15:43.798+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:15:43.798+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:15:43.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.582 seconds
[2025-10-09T08:16:14.249+0000] {processor.py:157} INFO - Started process (PID=9746) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:16:14.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:16:14.250+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:16:14.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:16:14.685+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:16:14.877+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:16:14.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:16:14.906+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:16:14.906+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:16:14.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.682 seconds
[2025-10-09T08:16:45.296+0000] {processor.py:157} INFO - Started process (PID=10062) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:16:45.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:16:45.298+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:16:45.298+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:16:45.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:16:45.782+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:16:45.782+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:16:45.811+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:16:45.811+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:16:45.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.542 seconds
[2025-10-09T08:17:16.093+0000] {processor.py:157} INFO - Started process (PID=10378) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:17:16.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:17:16.095+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:17:16.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:17:16.545+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:17:16.576+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:17:16.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:17:16.608+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:17:16.608+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:17:16.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.544 seconds
[2025-10-09T08:17:46.957+0000] {processor.py:157} INFO - Started process (PID=10685) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:17:46.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:17:46.960+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:17:46.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:17:47.450+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:17:47.475+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:17:47.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:17:47.504+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:17:47.504+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:17:47.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.572 seconds
[2025-10-09T08:18:17.852+0000] {processor.py:157} INFO - Started process (PID=10992) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:18:17.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:18:17.854+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:18:17.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:18:18.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:18:19.389+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-09T08:18:49.609+0000] {processor.py:157} INFO - Started process (PID=11317) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:18:49.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:18:49.610+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:18:49.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:18:50.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:18:50.080+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:18:50.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:18:50.113+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:18:50.113+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:18:50.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.530 seconds
[2025-10-09T08:19:20.400+0000] {processor.py:157} INFO - Started process (PID=11611) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:19:20.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:19:20.402+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:19:20.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:19:20.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:19:21.250+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:19:21.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:19:21.377+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:19:21.377+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:19:21.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.000 seconds
[2025-10-09T08:19:51.564+0000] {processor.py:157} INFO - Started process (PID=11918) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:19:51.565+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:19:51.567+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:19:51.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:19:51.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:19:52.340+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:19:52.340+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:19:52.372+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:19:52.372+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:19:52.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.832 seconds
[2025-10-09T08:20:23.180+0000] {processor.py:157} INFO - Started process (PID=12225) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:20:23.181+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:20:23.182+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:20:23.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:20:23.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:20:23.798+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:20:23.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:20:23.827+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:20:23.827+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:20:23.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.676 seconds
[2025-10-09T08:20:54.300+0000] {processor.py:157} INFO - Started process (PID=12532) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:20:54.301+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:20:54.302+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:20:54.302+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:20:54.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:20:55.099+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:20:55.099+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:20:55.127+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:20:55.127+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:20:55.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.852 seconds
[2025-10-09T08:21:25.308+0000] {processor.py:157} INFO - Started process (PID=12836) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:21:25.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:21:25.312+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:21:25.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:21:25.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:21:25.887+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:21:25.886+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:21:25.913+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:21:25.913+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:21:25.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.629 seconds
[2025-10-09T08:21:56.495+0000] {processor.py:157} INFO - Started process (PID=13143) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:21:56.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:21:56.497+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:21:56.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:21:57.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:21:57.746+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:21:57.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:21:57.777+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:21:57.777+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:21:57.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.311 seconds
[2025-10-09T08:22:27.862+0000] {processor.py:157} INFO - Started process (PID=13467) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:22:27.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:22:27.864+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:22:27.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:22:28.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:22:28.431+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:22:28.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:22:28.461+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:22:28.461+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:22:28.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.623 seconds
[2025-10-09T08:22:58.638+0000] {processor.py:157} INFO - Started process (PID=13771) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:22:58.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:22:58.640+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:22:58.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:22:59.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:22:59.980+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:22:59.979+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:23:00.008+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:23:00.007+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:23:00.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.396 seconds
[2025-10-09T08:23:30.196+0000] {processor.py:157} INFO - Started process (PID=14083) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:23:30.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:23:30.198+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:23:30.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:23:30.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:23:30.744+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:23:30.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:23:30.770+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:23:30.770+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:23:30.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.598 seconds
[2025-10-09T08:24:01.453+0000] {processor.py:157} INFO - Started process (PID=14390) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:24:01.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:24:01.455+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:24:01.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:24:01.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:24:03.002+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-09T08:24:33.965+0000] {processor.py:157} INFO - Started process (PID=14700) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:24:33.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:24:33.966+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:24:33.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:24:34.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:24:35.030+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:24:35.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:24:35.058+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:24:35.057+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:24:35.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.116 seconds
[2025-10-09T08:25:05.206+0000] {processor.py:157} INFO - Started process (PID=15007) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:25:05.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:25:05.208+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:25:05.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:25:05.817+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:25:06.357+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-09T08:25:36.929+0000] {processor.py:157} INFO - Started process (PID=15322) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:25:36.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:25:36.931+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:25:36.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:25:37.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:25:39.033+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:25:39.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:25:39.061+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:25:39.061+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:25:39.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.158 seconds
[2025-10-09T08:26:09.238+0000] {processor.py:157} INFO - Started process (PID=15641) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:26:09.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:26:09.240+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:26:09.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:26:09.883+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:26:10.410+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:26:10.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:26:10.446+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:26:10.446+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:26:10.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.241 seconds
[2025-10-09T08:26:41.208+0000] {processor.py:157} INFO - Started process (PID=15964) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:26:41.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:26:41.210+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:26:41.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:26:41.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:26:41.879+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:26:41.879+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:26:41.906+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:26:41.906+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:26:41.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.724 seconds
[2025-10-09T08:27:12.393+0000] {processor.py:157} INFO - Started process (PID=16269) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:27:12.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:27:12.396+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:27:12.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:27:12.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:27:12.994+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:27:12.993+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:27:13.020+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:27:13.020+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:27:13.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.651 seconds
[2025-10-09T08:27:43.331+0000] {processor.py:157} INFO - Started process (PID=16576) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:27:43.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:27:43.334+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:27:43.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:27:43.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:27:43.911+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:27:43.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:27:43.941+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:27:43.941+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:27:43.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.634 seconds
[2025-10-09T08:28:14.221+0000] {processor.py:157} INFO - Started process (PID=16890) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:28:14.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:28:14.224+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:28:14.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:28:14.769+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:28:15.313+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:28:15.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:28:15.397+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:28:15.397+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:28:15.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.202 seconds
[2025-10-09T08:28:45.719+0000] {processor.py:157} INFO - Started process (PID=17197) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:28:45.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:28:45.722+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:28:45.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:28:46.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:28:46.382+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:28:46.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:28:46.408+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:28:46.407+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:28:46.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.711 seconds
[2025-10-09T08:29:16.700+0000] {processor.py:157} INFO - Started process (PID=17504) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:29:16.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:29:16.704+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:29:16.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:29:17.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:29:17.444+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:29:17.444+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:29:17.474+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:29:17.474+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:29:17.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.801 seconds
[2025-10-09T08:29:47.939+0000] {processor.py:157} INFO - Started process (PID=17811) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:29:47.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-09T08:29:47.944+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:29:47.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:29:48.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-09T08:29:48.527+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:29:48.526+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-09T08:29:48.552+0000] {logging_mixin.py:149} INFO - [2025-10-09T08:29:48.552+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-09T10:00:00+00:00, run_after=2025-10-10T10:00:00+00:00
[2025-10-09T08:29:48.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.639 seconds
