[2025-09-26T08:24:44.315+0000] {processor.py:157} INFO - Started process (PID=21535) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:24:44.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:24:44.318+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:24:44.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:24:44.877+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.877+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:logistics_data_etl_pipeline
[2025-09-26T08:24:44.889+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.889+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:logistics_data_etl_pipeline
[2025-09-26T08:24:44.896+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.896+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:logistics_data_etl_pipeline
[2025-09-26T08:24:44.914+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:24:44.929+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.928+0000] {dag.py:2747} INFO - Creating ORM DAG for logistics_data_etl_pipeline
[2025-09-26T08:24:44.944+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:24:44.944+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:24:44.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.660 seconds
[2025-09-26T08:25:15.435+0000] {processor.py:157} INFO - Started process (PID=21829) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:25:15.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:25:15.437+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:25:15.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:25:15.896+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:25:15.921+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:25:15.921+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:25:15.950+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:25:15.950+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:25:15.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.542 seconds
[2025-09-26T08:25:46.402+0000] {processor.py:157} INFO - Started process (PID=22121) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:25:46.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:25:46.404+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:25:46.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:25:46.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:25:46.872+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:25:46.872+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:25:46.903+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:25:46.903+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:25:46.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.527 seconds
[2025-09-26T08:26:17.484+0000] {processor.py:157} INFO - Started process (PID=22412) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:26:17.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:26:17.486+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:26:17.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:26:17.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:26:17.971+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:26:17.970+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:26:18.001+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:26:18.001+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:26:18.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.546 seconds
[2025-09-26T08:26:48.509+0000] {processor.py:157} INFO - Started process (PID=22706) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:26:48.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:26:48.513+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:26:48.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:26:48.951+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:26:48.977+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:26:48.977+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:26:49.008+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:26:49.008+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:26:49.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.525 seconds
[2025-09-26T08:27:19.533+0000] {processor.py:157} INFO - Started process (PID=23000) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:27:19.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:27:19.535+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:27:19.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:27:19.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:27:20.687+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:27:20.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:27:20.722+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:27:20.722+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:27:20.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.214 seconds
[2025-09-26T08:27:51.071+0000] {processor.py:157} INFO - Started process (PID=23304) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:27:51.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:27:51.073+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:27:51.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:27:51.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:27:51.835+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:27:51.834+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:27:51.868+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:27:51.867+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:27:51.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.822 seconds
[2025-09-26T08:28:22.463+0000] {processor.py:157} INFO - Started process (PID=23605) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:28:22.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:28:22.466+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:28:22.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:28:22.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:28:22.988+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:28:22.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:28:23.042+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:28:23.042+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:28:23.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.606 seconds
[2025-09-26T08:28:53.609+0000] {processor.py:157} INFO - Started process (PID=23899) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:28:53.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:28:53.611+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:28:53.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:28:54.176+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:28:54.311+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:28:54.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:28:54.543+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:28:54.543+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:28:54.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.968 seconds
[2025-09-26T08:29:24.872+0000] {processor.py:157} INFO - Started process (PID=24196) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:29:24.873+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:29:24.874+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:29:24.874+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:29:25.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:29:25.737+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:29:25.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:29:25.766+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:29:25.766+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:29:25.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.920 seconds
[2025-09-26T08:29:55.861+0000] {processor.py:157} INFO - Started process (PID=24490) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:29:55.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:29:55.863+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:29:55.863+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:29:56.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:29:56.424+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:29:56.424+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:29:56.450+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:29:56.450+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:29:56.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.612 seconds
[2025-09-26T08:30:27.284+0000] {processor.py:157} INFO - Started process (PID=24791) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:30:27.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:30:27.286+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:30:27.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:30:27.818+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:30:27.841+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:30:27.841+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:30:27.868+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:30:27.868+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:30:27.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.606 seconds
[2025-09-26T08:30:58.387+0000] {processor.py:157} INFO - Started process (PID=25085) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:30:58.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:30:58.388+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:30:58.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:30:58.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:30:59.953+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:30:59.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:30:59.980+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:30:59.980+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:31:00.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.617 seconds
[2025-09-26T08:31:30.126+0000] {processor.py:157} INFO - Started process (PID=25379) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:31:30.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:31:30.129+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:31:30.128+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:31:30.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:31:30.686+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:31:30.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:31:30.712+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:31:30.712+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:31:30.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.609 seconds
[2025-09-26T08:32:00.932+0000] {processor.py:157} INFO - Started process (PID=25673) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:32:00.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:32:00.935+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:32:00.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:32:01.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:32:02.026+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:32:02.025+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:32:02.053+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:32:02.053+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:32:02.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.147 seconds
[2025-09-26T08:32:32.400+0000] {processor.py:157} INFO - Started process (PID=25987) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:32:32.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:32:32.404+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:32:32.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:32:32.946+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:32:32.968+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:32:32.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:32:32.995+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:32:32.995+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:32:33.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.619 seconds
[2025-09-26T08:33:03.289+0000] {processor.py:157} INFO - Started process (PID=26282) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:33:03.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:33:03.292+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:33:03.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:33:03.817+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:33:03.844+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:33:03.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:33:03.876+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:33:03.876+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:33:03.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.619 seconds
[2025-09-26T08:33:34.618+0000] {processor.py:157} INFO - Started process (PID=26576) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:33:34.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:33:34.621+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:33:34.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:33:35.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:33:35.340+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:34:06.269+0000] {processor.py:157} INFO - Started process (PID=26870) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:34:06.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:34:06.271+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:34:06.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:34:06.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:34:07.801+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:34:38.406+0000] {processor.py:157} INFO - Started process (PID=27187) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:34:38.408+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:34:38.408+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:34:38.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:34:39.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:34:39.442+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:34:39.441+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:34:39.469+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:34:39.469+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:34:39.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.090 seconds
[2025-09-26T08:35:09.847+0000] {processor.py:157} INFO - Started process (PID=27496) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:35:09.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:35:09.848+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:35:09.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:35:10.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:35:10.753+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:35:41.329+0000] {processor.py:157} INFO - Started process (PID=27797) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:35:41.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:35:41.331+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:35:41.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:35:41.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:35:42.731+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:35:42.730+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:35:42.760+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:35:42.760+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:35:42.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.456 seconds
[2025-09-26T08:36:13.276+0000] {processor.py:157} INFO - Started process (PID=28096) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:36:13.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:36:13.278+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:36:13.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:36:13.829+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:36:13.850+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:36:13.850+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:36:13.876+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:36:13.876+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:36:13.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.627 seconds
[2025-09-26T08:36:44.031+0000] {processor.py:157} INFO - Started process (PID=28390) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:36:44.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:36:44.033+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:36:44.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:36:44.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:36:44.585+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:36:44.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:36:44.611+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:36:44.611+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:36:44.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.604 seconds
[2025-09-26T08:37:15.057+0000] {processor.py:157} INFO - Started process (PID=28684) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:37:15.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:37:15.059+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:37:15.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:37:15.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:37:16.910+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:37:47.511+0000] {processor.py:157} INFO - Started process (PID=28988) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:37:47.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:37:47.513+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:37:47.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:37:48.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:37:49.346+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:37:49.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:37:49.374+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:37:49.374+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:37:49.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.888 seconds
[2025-09-26T08:38:19.659+0000] {processor.py:157} INFO - Started process (PID=29297) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:38:19.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:38:19.661+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:38:19.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:38:20.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:38:20.535+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:38:20.534+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:38:20.565+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:38:20.565+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:38:20.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.932 seconds
[2025-09-26T08:38:51.078+0000] {processor.py:157} INFO - Started process (PID=29591) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:38:51.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:38:51.080+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:38:51.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:38:51.630+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:38:52.171+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:38:52.171+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:38:52.201+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:38:52.200+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:38:52.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.148 seconds
[2025-09-26T08:39:22.330+0000] {processor.py:157} INFO - Started process (PID=29890) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:39:22.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:39:22.332+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:39:22.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:39:22.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:39:22.884+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:39:22.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:39:22.910+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:39:22.910+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:39:22.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.603 seconds
[2025-09-26T08:39:53.792+0000] {processor.py:157} INFO - Started process (PID=30184) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:39:53.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:39:53.795+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:39:53.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:39:54.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:39:54.371+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:39:54.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:39:54.398+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:39:54.398+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:39:54.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.629 seconds
[2025-09-26T08:40:24.759+0000] {processor.py:157} INFO - Started process (PID=30485) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:40:24.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:40:24.760+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:40:24.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:40:25.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:40:25.345+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:40:25.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:40:25.372+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:40:25.371+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:40:25.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.637 seconds
[2025-09-26T08:40:55.713+0000] {processor.py:157} INFO - Started process (PID=30779) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:40:55.714+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:40:55.715+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:40:55.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:40:56.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:40:57.477+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:41:27.691+0000] {processor.py:157} INFO - Started process (PID=31078) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:41:27.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:41:27.693+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:41:27.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:41:28.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:41:28.260+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:41:28.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:41:28.286+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:41:28.286+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:41:28.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.619 seconds
[2025-09-26T08:41:58.739+0000] {processor.py:157} INFO - Started process (PID=31372) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:41:58.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:41:58.741+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:41:58.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:41:59.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:41:59.309+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:41:59.308+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:41:59.336+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:41:59.336+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:41:59.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.623 seconds
[2025-09-26T08:42:29.857+0000] {processor.py:157} INFO - Started process (PID=31666) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:42:29.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:42:29.859+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:42:29.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:42:30.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:42:30.598+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:42:30.592+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:42:30.711+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:42:30.711+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:42:30.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.896 seconds
[2025-09-26T08:43:00.887+0000] {processor.py:157} INFO - Started process (PID=31969) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:43:00.890+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:43:00.891+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:43:00.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:43:01.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:43:01.718+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:43:01.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:43:01.750+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:43:01.750+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:43:01.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.890 seconds
[2025-09-26T08:43:32.456+0000] {processor.py:157} INFO - Started process (PID=32268) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:43:32.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:43:32.460+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:43:32.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:43:32.902+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:43:32.926+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:43:32.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:43:32.955+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:43:32.955+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:43:32.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.525 seconds
[2025-09-26T08:44:03.753+0000] {processor.py:157} INFO - Started process (PID=32567) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:44:03.754+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:44:03.756+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:44:03.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:44:04.188+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:44:04.214+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:44:04.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:44:04.245+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:44:04.245+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:44:04.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.517 seconds
[2025-09-26T08:44:34.674+0000] {processor.py:157} INFO - Started process (PID=32859) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:44:34.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:44:34.677+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:44:34.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:44:35.094+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:44:35.741+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:45:06.551+0000] {processor.py:157} INFO - Started process (PID=33160) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:45:06.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:45:06.553+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:45:06.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:45:06.979+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:45:07.274+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:45:07.274+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:45:07.305+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:45:07.305+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:45:07.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.786 seconds
[2025-09-26T08:45:38.176+0000] {processor.py:157} INFO - Started process (PID=33454) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:45:38.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:45:38.179+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:45:38.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:45:38.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:45:38.865+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:45:38.865+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:45:38.901+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:45:38.901+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:45:38.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.755 seconds
[2025-09-26T08:46:09.064+0000] {processor.py:157} INFO - Started process (PID=33748) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:46:09.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:46:09.066+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:46:09.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:46:09.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:46:09.552+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:46:09.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:46:09.583+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:46:09.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:46:09.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.546 seconds
[2025-09-26T08:46:40.594+0000] {processor.py:157} INFO - Started process (PID=34047) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:46:40.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:46:40.597+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:46:40.597+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:46:41.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:46:41.574+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:46:41.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:46:41.605+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:46:41.605+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:46:41.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.036 seconds
[2025-09-26T08:47:12.223+0000] {processor.py:157} INFO - Started process (PID=34346) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:47:12.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:47:12.226+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:47:12.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:47:12.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:47:13.580+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:47:13.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:47:13.612+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:47:13.611+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:47:13.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.521 seconds
[2025-09-26T08:47:44.605+0000] {processor.py:157} INFO - Started process (PID=34648) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:47:44.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:47:44.608+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:47:44.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:47:45.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:47:45.090+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:47:45.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:47:45.256+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:47:45.256+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:47:45.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.729 seconds
[2025-09-26T08:48:15.642+0000] {processor.py:157} INFO - Started process (PID=34953) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:48:15.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:48:15.647+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:48:15.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:48:16.069+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:48:16.102+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:48:16.101+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:48:16.139+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:48:16.139+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:48:16.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.529 seconds
[2025-09-26T08:48:46.222+0000] {processor.py:157} INFO - Started process (PID=35242) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:48:46.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:48:46.224+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:48:46.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:48:46.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:48:47.094+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:48:47.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:48:47.135+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:48:47.135+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:48:47.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.945 seconds
[2025-09-26T08:49:17.406+0000] {processor.py:157} INFO - Started process (PID=35551) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:49:17.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:49:17.408+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:49:17.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:49:17.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:49:18.079+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:49:18.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:49:18.112+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:49:18.112+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:49:18.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.738 seconds
[2025-09-26T08:49:48.769+0000] {processor.py:157} INFO - Started process (PID=35848) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:49:48.770+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:49:48.771+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:49:48.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:49:49.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:49:49.368+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:49:49.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:49:49.398+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:49:49.398+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:49:49.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.653 seconds
[2025-09-26T08:50:19.459+0000] {processor.py:157} INFO - Started process (PID=36144) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:50:19.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:50:19.461+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:50:19.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:50:19.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:50:20.258+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:50:20.258+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:50:20.285+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:50:20.284+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:50:20.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.850 seconds
[2025-09-26T08:50:50.419+0000] {processor.py:157} INFO - Started process (PID=36435) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:50:50.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:50:50.422+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:50:50.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:50:50.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:50:51.435+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:50:51.434+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:50:51.536+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:50:51.535+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:50:51.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.150 seconds
[2025-09-26T08:51:21.957+0000] {processor.py:157} INFO - Started process (PID=36731) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:51:21.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:51:21.960+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:51:21.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:51:22.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:51:23.873+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:51:23.873+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:51:23.903+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:51:23.902+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:51:23.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.972 seconds
[2025-09-26T08:51:54.041+0000] {processor.py:157} INFO - Started process (PID=37030) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:51:54.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:51:54.043+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:51:54.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:51:54.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:51:54.617+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:51:54.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:51:54.647+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:51:54.647+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:51:54.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.631 seconds
[2025-09-26T08:52:25.255+0000] {processor.py:157} INFO - Started process (PID=37329) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:52:25.257+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:52:25.258+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:52:25.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:52:25.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:52:25.894+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:52:25.893+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:52:25.928+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:52:25.928+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:52:25.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.701 seconds
[2025-09-26T08:52:56.316+0000] {processor.py:157} INFO - Started process (PID=37623) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:52:56.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:52:56.319+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:52:56.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:52:56.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:52:57.338+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:52:57.338+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:52:57.371+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:52:57.370+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:52:57.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.080 seconds
[2025-09-26T08:53:27.965+0000] {processor.py:157} INFO - Started process (PID=37933) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:53:27.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:53:27.967+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:53:27.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:53:28.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:53:28.529+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:53:28.528+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:53:28.557+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:53:28.557+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:53:28.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-09-26T08:53:59.461+0000] {processor.py:157} INFO - Started process (PID=38227) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:53:59.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:53:59.463+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:53:59.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:54:00.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:54:00.027+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:54:00.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:54:00.054+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:54:00.054+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:54:00.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.619 seconds
[2025-09-26T08:54:30.923+0000] {processor.py:157} INFO - Started process (PID=38521) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:54:30.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:54:30.925+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:54:30.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:54:31.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:54:31.518+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:54:31.517+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:54:31.549+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:54:31.549+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:54:31.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.653 seconds
[2025-09-26T08:55:02.099+0000] {processor.py:157} INFO - Started process (PID=38815) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:55:02.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:55:02.102+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:55:02.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:55:02.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:55:03.418+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:55:03.418+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:55:03.445+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:55:03.445+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:55:03.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.371 seconds
[2025-09-26T08:55:33.739+0000] {processor.py:157} INFO - Started process (PID=39120) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:55:33.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:55:33.741+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:55:33.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:55:34.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:55:35.288+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:56:05.747+0000] {processor.py:157} INFO - Started process (PID=39416) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:56:05.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:56:05.748+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:56:05.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:56:06.306+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:56:07.262+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:56:37.420+0000] {processor.py:157} INFO - Started process (PID=39743) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:56:37.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:56:37.422+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:56:37.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:56:37.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:56:38.080+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:56:38.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:56:38.116+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:56:38.116+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:56:38.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.720 seconds
[2025-09-26T08:57:08.695+0000] {processor.py:157} INFO - Started process (PID=40037) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:57:08.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:57:08.697+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:57:08.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:57:09.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:57:09.829+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:57:39.892+0000] {processor.py:157} INFO - Started process (PID=40346) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:57:39.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:57:39.894+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:57:39.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:57:40.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:57:41.136+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T08:58:12.190+0000] {processor.py:157} INFO - Started process (PID=40662) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:58:12.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:58:12.194+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:58:12.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:58:12.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:58:12.890+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:58:12.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:58:12.914+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:58:12.914+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:58:12.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.752 seconds
[2025-09-26T08:58:43.443+0000] {processor.py:157} INFO - Started process (PID=40956) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:58:43.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:58:43.445+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:58:43.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:58:44.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:58:44.331+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:58:44.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:58:44.359+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:58:44.359+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:58:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.942 seconds
[2025-09-26T08:59:15.282+0000] {processor.py:157} INFO - Started process (PID=41259) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:59:15.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:59:15.285+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:59:15.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:59:15.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:59:16.142+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:59:16.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T08:59:16.174+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:59:16.174+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T08:59:16.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.916 seconds
[2025-09-26T08:59:46.876+0000] {processor.py:157} INFO - Started process (PID=41554) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:59:46.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T08:59:46.879+0000] {logging_mixin.py:149} INFO - [2025-09-26T08:59:46.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:59:47.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T08:59:48.440+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T09:00:18.508+0000] {processor.py:157} INFO - Started process (PID=41858) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:00:18.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:00:18.511+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:00:18.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:00:19.033+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:00:19.784+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T09:00:49.897+0000] {processor.py:157} INFO - Started process (PID=42152) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:00:49.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:00:49.899+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:00:49.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:00:50.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:00:50.439+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:00:50.439+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:00:50.466+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:00:50.466+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:00:50.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.594 seconds
[2025-09-26T09:01:20.754+0000] {processor.py:157} INFO - Started process (PID=42446) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:01:20.756+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:01:20.757+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:01:20.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:01:21.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:01:21.498+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:01:21.497+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:01:21.529+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:01:21.529+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:01:21.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.803 seconds
[2025-09-26T09:01:52.452+0000] {processor.py:157} INFO - Started process (PID=42740) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:01:52.453+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:01:52.455+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:01:52.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:01:52.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:01:52.936+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:01:52.936+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:01:52.966+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:01:52.965+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:01:52.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.539 seconds
[2025-09-26T09:02:23.604+0000] {processor.py:157} INFO - Started process (PID=43035) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:02:23.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:02:23.607+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:02:23.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:02:24.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:02:24.166+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:02:24.166+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:02:24.197+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:02:24.197+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:02:24.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.621 seconds
[2025-09-26T09:02:54.899+0000] {processor.py:157} INFO - Started process (PID=43334) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:02:54.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:02:54.901+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:02:54.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:02:55.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:02:55.363+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:02:55.363+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:02:55.393+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:02:55.392+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:02:55.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.520 seconds
[2025-09-26T09:03:25.827+0000] {processor.py:157} INFO - Started process (PID=43628) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:03:25.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:03:25.829+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:03:25.829+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:03:26.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:03:26.399+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:03:26.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:03:26.434+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:03:26.434+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:03:26.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.639 seconds
[2025-09-26T09:03:56.883+0000] {processor.py:157} INFO - Started process (PID=43922) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:03:56.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:03:56.884+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:03:56.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:03:57.321+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:03:58.055+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:03:58.055+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:03:58.087+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:03:58.087+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:03:58.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.229 seconds
[2025-09-26T09:04:28.873+0000] {processor.py:157} INFO - Started process (PID=44221) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:04:28.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:04:28.876+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:04:28.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:04:29.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:04:29.358+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:04:29.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:04:29.390+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:04:29.390+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:04:29.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.543 seconds
[2025-09-26T09:05:00.170+0000] {processor.py:157} INFO - Started process (PID=44521) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:05:00.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:05:00.173+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:05:00.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:05:00.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:05:01.094+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:05:01.094+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:05:01.126+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:05:01.126+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:05:01.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.982 seconds
[2025-09-26T09:05:31.446+0000] {processor.py:157} INFO - Started process (PID=44815) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:05:31.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:05:31.448+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:05:31.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:05:31.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:05:31.906+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:05:31.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:05:31.936+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:05:31.936+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:05:31.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.516 seconds
[2025-09-26T09:06:02.710+0000] {processor.py:157} INFO - Started process (PID=45112) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:06:02.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:06:02.714+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:06:02.713+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:06:03.149+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:06:03.175+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:06:03.174+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:06:03.207+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:06:03.207+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:06:03.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.537 seconds
[2025-09-26T09:06:33.809+0000] {processor.py:157} INFO - Started process (PID=45416) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:06:33.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:06:33.813+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:06:33.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:06:34.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:06:34.291+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:06:34.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:06:34.322+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:06:34.321+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:06:34.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.541 seconds
[2025-09-26T09:07:04.393+0000] {processor.py:157} INFO - Started process (PID=45710) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:07:04.394+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:07:04.395+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:07:04.395+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:07:04.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:07:04.851+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:07:04.850+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:07:04.882+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:07:04.882+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:07:04.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.517 seconds
[2025-09-26T09:07:35.112+0000] {processor.py:157} INFO - Started process (PID=46001) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:07:35.113+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:07:35.114+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:07:35.113+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:07:35.538+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:07:35.801+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:07:35.800+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:07:35.831+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:07:35.831+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:07:35.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.744 seconds
[2025-09-26T09:08:05.928+0000] {processor.py:157} INFO - Started process (PID=46298) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:08:05.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:08:05.931+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:08:05.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:08:06.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:08:06.827+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:08:06.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:08:06.857+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:08:06.857+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:08:06.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.958 seconds
[2025-09-26T09:08:37.607+0000] {processor.py:157} INFO - Started process (PID=46599) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:08:37.608+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:08:37.609+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:08:37.609+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:08:38.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:08:38.077+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:08:38.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:08:38.108+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:08:38.107+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:08:38.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.637 seconds
[2025-09-26T09:09:08.958+0000] {processor.py:157} INFO - Started process (PID=46898) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:09:08.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:09:08.960+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:09:08.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:09:09.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:09:09.447+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:09:09.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:09:09.578+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:09:09.577+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:09:09.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.644 seconds
[2025-09-26T09:09:39.849+0000] {processor.py:157} INFO - Started process (PID=47192) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:09:39.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:09:39.852+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:09:39.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:09:40.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:09:40.469+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:09:40.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:09:40.497+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:09:40.497+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:09:40.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.676 seconds
[2025-09-26T09:10:10.908+0000] {processor.py:157} INFO - Started process (PID=47489) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:10:10.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:10:10.910+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:10:10.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:10:11.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:10:11.462+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:10:11.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:10:11.489+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:10:11.489+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:10:11.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.603 seconds
[2025-09-26T09:10:41.750+0000] {processor.py:157} INFO - Started process (PID=47783) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:10:41.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:10:41.752+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:10:41.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:10:42.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:10:42.342+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:10:42.341+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:10:42.374+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:10:42.374+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:10:42.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.651 seconds
[2025-09-26T09:11:12.851+0000] {processor.py:157} INFO - Started process (PID=48079) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:11:12.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:11:12.853+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:11:12.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:11:13.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:11:13.399+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:11:13.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:11:13.425+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:11:13.425+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:11:13.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.597 seconds
[2025-09-26T09:11:43.665+0000] {processor.py:157} INFO - Started process (PID=48371) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:11:43.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:11:43.667+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:11:43.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:11:44.242+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:11:44.641+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:11:44.640+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:11:44.673+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:11:44.673+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:11:44.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.033 seconds
[2025-09-26T09:12:15.160+0000] {processor.py:157} INFO - Started process (PID=48667) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:12:15.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:12:15.162+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:12:15.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:12:15.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:12:16.094+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:12:16.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:12:16.131+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:12:16.131+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:12:16.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.996 seconds
[2025-09-26T09:12:46.406+0000] {processor.py:157} INFO - Started process (PID=48971) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:12:46.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:12:46.408+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:12:46.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:12:46.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:12:47.788+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T09:13:17.845+0000] {processor.py:157} INFO - Started process (PID=49283) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:13:17.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:13:17.847+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:13:17.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:13:18.388+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:13:18.409+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:13:18.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:13:18.437+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:13:18.437+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:13:18.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.615 seconds
[2025-09-26T09:13:48.896+0000] {processor.py:157} INFO - Started process (PID=49574) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:13:48.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:13:48.898+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:13:48.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:13:49.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:13:50.330+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:13:50.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:13:50.359+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:13:50.359+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:13:50.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.491 seconds
[2025-09-26T09:14:20.649+0000] {processor.py:157} INFO - Started process (PID=49876) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:14:20.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:14:20.651+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:14:20.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:14:21.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:14:21.633+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:14:21.633+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:14:21.662+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:14:21.661+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:14:21.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.041 seconds
[2025-09-26T09:14:52.525+0000] {processor.py:157} INFO - Started process (PID=50187) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:14:52.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:14:52.527+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:14:52.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:14:53.059+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:14:53.080+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:14:53.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:14:53.107+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:14:53.107+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:14:53.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.610 seconds
[2025-09-26T09:15:23.425+0000] {processor.py:157} INFO - Started process (PID=50479) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:15:23.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:15:23.428+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:15:23.428+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:15:24.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:15:24.795+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T09:15:55.446+0000] {processor.py:157} INFO - Started process (PID=50785) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:15:55.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:15:55.449+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:15:55.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:15:56.021+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:15:56.047+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:15:56.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:15:56.075+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:15:56.075+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:15:56.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.655 seconds
[2025-09-26T09:16:26.731+0000] {processor.py:157} INFO - Started process (PID=51079) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:16:26.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:16:26.736+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:16:26.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:16:27.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:16:27.821+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:16:27.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:16:27.848+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:16:27.848+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:16:27.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.141 seconds
[2025-09-26T09:16:57.915+0000] {processor.py:157} INFO - Started process (PID=51393) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:16:57.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:16:57.917+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:16:57.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:16:58.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:16:58.689+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:16:58.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:16:58.717+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:16:58.717+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:16:58.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.827 seconds
[2025-09-26T09:17:29.198+0000] {processor.py:157} INFO - Started process (PID=51687) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:17:29.199+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:17:29.199+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:17:29.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:17:29.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:17:30.891+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:17:30.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:17:30.922+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:17:30.922+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:17:30.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.752 seconds
[2025-09-26T09:18:01.451+0000] {processor.py:157} INFO - Started process (PID=51998) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:18:01.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:18:01.453+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:18:01.453+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:18:01.984+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:18:02.112+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:18:02.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:18:02.138+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:18:02.138+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:18:02.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.710 seconds
[2025-09-26T09:18:32.678+0000] {processor.py:157} INFO - Started process (PID=52292) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:18:32.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T09:18:32.681+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:18:32.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:18:33.201+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T09:18:33.222+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:18:33.222+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T09:18:33.249+0000] {logging_mixin.py:149} INFO - [2025-09-26T09:18:33.249+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T09:18:33.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.595 seconds
[2025-09-26T13:48:06.412+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:48:06.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:48:06.416+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:48:06.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:48:07.660+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:48:07.730+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:48:07.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:48:07.766+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:48:07.766+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:48:07.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.390 seconds
[2025-09-26T13:48:38.253+0000] {processor.py:157} INFO - Started process (PID=465) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:48:38.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:48:38.255+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:48:38.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:48:38.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:48:39.277+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:48:39.277+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:48:39.310+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:48:39.309+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:48:39.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.089 seconds
[2025-09-26T13:49:09.766+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:49:09.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:49:09.769+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:49:09.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:49:10.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:49:10.287+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:49:10.287+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:49:10.318+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:49:10.318+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:49:10.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.581 seconds
[2025-09-26T13:49:41.034+0000] {processor.py:157} INFO - Started process (PID=1071) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:49:41.035+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:49:41.036+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:49:41.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:49:41.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:49:41.491+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:49:41.490+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:49:41.521+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:49:41.521+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:49:41.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.511 seconds
[2025-09-26T13:50:11.818+0000] {processor.py:157} INFO - Started process (PID=1367) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:50:11.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:50:11.820+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:50:11.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:50:12.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:50:12.570+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:50:12.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:50:12.604+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:50:12.603+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:50:12.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.809 seconds
[2025-09-26T13:50:42.850+0000] {processor.py:157} INFO - Started process (PID=1674) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:50:42.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:50:42.856+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:50:42.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:50:43.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:50:43.315+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:50:43.314+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:50:43.347+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:50:43.347+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:50:43.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.522 seconds
[2025-09-26T13:51:13.687+0000] {processor.py:157} INFO - Started process (PID=1955) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:51:13.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:51:13.689+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:51:13.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:51:14.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:51:14.484+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:51:14.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:51:14.513+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:51:14.512+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:51:14.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.850 seconds
[2025-09-26T13:51:44.847+0000] {processor.py:157} INFO - Started process (PID=2246) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:51:44.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:51:44.849+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:51:44.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:51:45.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:51:46.440+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T13:52:16.479+0000] {processor.py:157} INFO - Started process (PID=2550) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:52:16.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:52:16.481+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:52:16.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:52:16.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:52:16.911+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:52:16.910+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:52:16.940+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:52:16.940+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:52:16.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.486 seconds
[2025-09-26T13:52:47.605+0000] {processor.py:157} INFO - Started process (PID=2844) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:52:47.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:52:47.607+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:52:47.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:52:48.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:52:48.371+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:52:48.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:52:48.403+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:52:48.403+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:52:48.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.822 seconds
[2025-09-26T13:53:18.496+0000] {processor.py:157} INFO - Started process (PID=3136) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:53:18.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:53:18.498+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:53:18.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:53:18.991+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:53:19.183+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:53:19.183+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:53:19.221+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:53:19.221+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:53:19.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.756 seconds
[2025-09-26T13:53:49.468+0000] {processor.py:157} INFO - Started process (PID=3425) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:53:49.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:53:49.470+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:53:49.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:53:49.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:53:50.700+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:53:50.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:53:50.731+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:53:50.731+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:53:50.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.292 seconds
[2025-09-26T13:54:21.197+0000] {processor.py:157} INFO - Started process (PID=3740) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:54:21.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:54:21.199+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:54:21.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:54:21.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:54:21.796+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:54:21.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:54:21.941+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:54:21.940+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:54:21.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.773 seconds
[2025-09-26T13:54:52.328+0000] {processor.py:157} INFO - Started process (PID=4034) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:54:52.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:54:52.330+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:54:52.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:54:52.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:54:52.919+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:54:52.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:54:53.148+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:54:53.147+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:54:53.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.850 seconds
[2025-09-26T13:55:01.824+0000] {processor.py:157} INFO - Started process (PID=4221) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:55:01.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:55:01.826+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:55:01.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:55:02.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:55:02.281+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:55:02.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:55:02.440+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:55:02.440+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:55:02.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.649 seconds
[2025-09-26T13:55:32.961+0000] {processor.py:157} INFO - Started process (PID=4519) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:55:32.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:55:32.963+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:55:32.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:55:33.450+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:55:34.702+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T13:56:05.100+0000] {processor.py:157} INFO - Started process (PID=4833) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:56:05.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:56:05.101+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:56:05.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:56:05.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:56:05.725+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:56:05.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:56:05.758+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:56:05.757+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:56:05.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.685 seconds
[2025-09-26T13:56:37.080+0000] {processor.py:157} INFO - Started process (PID=5132) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:56:37.083+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:56:37.084+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:56:37.084+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:56:37.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:56:37.638+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:56:37.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:56:37.665+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:56:37.664+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:56:37.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.609 seconds
[2025-09-26T13:57:08.815+0000] {processor.py:157} INFO - Started process (PID=5431) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:57:08.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:57:08.817+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:57:08.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:57:09.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:57:09.525+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:57:09.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:57:09.552+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:57:09.552+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:57:09.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.762 seconds
[2025-09-26T13:57:40.656+0000] {processor.py:157} INFO - Started process (PID=5749) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:57:40.657+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:57:40.658+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:57:40.658+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:57:41.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:57:41.755+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:57:41.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:57:41.783+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:57:41.783+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:57:41.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.151 seconds
[2025-09-26T13:58:12.736+0000] {processor.py:157} INFO - Started process (PID=6061) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:58:12.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:58:12.738+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:58:12.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:58:13.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:58:14.184+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:58:14.184+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:58:14.213+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:58:14.213+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:58:14.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.500 seconds
[2025-09-26T13:58:44.374+0000] {processor.py:157} INFO - Started process (PID=6368) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:58:44.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:58:44.377+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:58:44.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:58:44.905+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:58:45.051+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:58:45.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:58:45.078+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:58:45.078+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:58:45.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.727 seconds
[2025-09-26T13:59:15.687+0000] {processor.py:157} INFO - Started process (PID=6671) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:59:15.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:59:15.690+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:59:15.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:59:16.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:59:17.247+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T13:59:47.740+0000] {processor.py:157} INFO - Started process (PID=6967) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:59:47.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T13:59:47.742+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:59:47.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:59:48.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T13:59:48.278+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:59:48.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T13:59:48.304+0000] {logging_mixin.py:149} INFO - [2025-09-26T13:59:48.304+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T13:59:48.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.586 seconds
[2025-09-26T14:00:18.789+0000] {processor.py:157} INFO - Started process (PID=7266) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:00:18.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:00:18.791+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:00:18.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:00:19.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:00:19.490+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:00:19.489+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:00:19.517+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:00:19.516+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:00:19.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.753 seconds
[2025-09-26T14:00:49.800+0000] {processor.py:157} INFO - Started process (PID=7579) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:00:49.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:00:49.803+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:00:49.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:00:50.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:00:50.368+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:00:50.368+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:00:50.397+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:00:50.397+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:00:50.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.623 seconds
[2025-09-26T14:01:20.948+0000] {processor.py:157} INFO - Started process (PID=7873) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:01:20.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:01:20.950+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:01:20.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:01:21.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:01:21.992+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:01:21.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:01:22.019+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:01:22.018+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:01:22.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.095 seconds
[2025-09-26T14:01:52.328+0000] {processor.py:157} INFO - Started process (PID=8167) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:01:52.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:01:52.330+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:01:52.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:01:52.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:01:53.232+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:01:53.232+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:01:53.259+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:01:53.259+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:01:53.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.955 seconds
[2025-09-26T14:02:23.628+0000] {processor.py:157} INFO - Started process (PID=8461) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:02:23.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:02:23.630+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:02:23.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:02:24.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:02:24.160+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:02:24.159+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:02:24.186+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:02:24.186+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:02:24.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.580 seconds
[2025-09-26T14:02:54.718+0000] {processor.py:157} INFO - Started process (PID=8740) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:02:54.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:02:54.720+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:02:54.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:02:55.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:02:56.570+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T14:03:27.355+0000] {processor.py:157} INFO - Started process (PID=9049) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:03:27.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:03:27.357+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:03:27.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:03:27.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:03:27.893+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:03:27.892+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:03:27.918+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:03:27.918+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:03:27.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.588 seconds
[2025-09-26T14:03:58.268+0000] {processor.py:157} INFO - Started process (PID=9343) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:03:58.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:03:58.270+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:03:58.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:03:58.785+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:03:59.153+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:03:59.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:03:59.188+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:03:59.188+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:03:59.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.947 seconds
[2025-09-26T14:04:30.128+0000] {processor.py:157} INFO - Started process (PID=9646) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:04:30.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:04:30.131+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:04:30.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:04:30.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:04:30.675+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:04:30.675+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:04:30.702+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:04:30.702+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:04:30.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.598 seconds
[2025-09-26T14:05:00.887+0000] {processor.py:157} INFO - Started process (PID=9943) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:05:00.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:05:00.889+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:05:00.889+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:05:01.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:05:02.821+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:05:02.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:05:02.849+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:05:02.849+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:05:02.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.986 seconds
[2025-09-26T14:05:32.954+0000] {processor.py:157} INFO - Started process (PID=10257) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:05:32.955+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:05:32.956+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:05:32.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:05:33.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:05:34.681+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.6), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-26T14:06:05.158+0000] {processor.py:157} INFO - Started process (PID=10559) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:06:05.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:06:05.161+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:06:05.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:06:05.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:06:05.703+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:06:05.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:06:05.730+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:06:05.730+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:06:05.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.596 seconds
[2025-09-26T14:06:35.874+0000] {processor.py:157} INFO - Started process (PID=10855) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:06:35.875+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:06:35.876+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:06:35.876+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:06:36.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:06:36.401+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:06:36.401+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:06:36.427+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:06:36.427+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:06:36.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.577 seconds
[2025-09-26T14:07:06.729+0000] {processor.py:157} INFO - Started process (PID=11147) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:07:06.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:07:06.731+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:07:06.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:07:07.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:07:07.285+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:07:07.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:07:07.311+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:07:07.310+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:07:07.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.605 seconds
[2025-09-26T14:07:37.383+0000] {processor.py:157} INFO - Started process (PID=11441) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:07:37.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:07:37.385+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:07:37.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:07:37.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:07:37.838+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:07:37.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:07:37.868+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:07:37.868+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:07:37.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.509 seconds
[2025-09-26T14:08:08.752+0000] {processor.py:157} INFO - Started process (PID=11737) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:08:08.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:08:08.754+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:08:08.754+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:08:09.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:08:09.588+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:08:09.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:08:09.619+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:08:09.619+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:08:09.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.893 seconds
[2025-09-26T14:08:39.904+0000] {processor.py:157} INFO - Started process (PID=12031) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:08:39.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-26T14:08:39.907+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:08:39.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:08:40.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-26T14:08:40.469+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:08:40.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-26T14:08:40.507+0000] {logging_mixin.py:149} INFO - [2025-09-26T14:08:40.506+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-26T09:00:00+00:00, run_after=2025-09-27T09:00:00+00:00
[2025-09-26T14:08:40.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.632 seconds
