[2025-09-29T00:13:45.332+0000] {processor.py:157} INFO - Started process (PID=45928) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:13:45.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:13:45.335+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:13:45.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:13:46.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:13:46.212+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:13:46.212+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:13:46.240+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:13:46.240+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:13:46.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.940 seconds
[2025-09-29T00:14:17.108+0000] {processor.py:157} INFO - Started process (PID=46236) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:14:17.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:14:17.110+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:14:17.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:14:19.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:14:19.644+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:14:19.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:14:19.806+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:14:19.804+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:14:19.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.875 seconds
[2025-09-29T00:16:58.052+0000] {processor.py:157} INFO - Started process (PID=46338) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:16:58.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:16:58.085+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:16:58.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:17:00.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:17:00.377+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:00.375+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:17:00.506+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:00.494+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:17:00.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.777 seconds
[2025-09-29T00:17:31.413+0000] {processor.py:157} INFO - Started process (PID=46645) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:17:31.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:17:31.416+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:31.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:17:32.025+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:17:32.049+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:32.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:17:32.077+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:32.077+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:17:34.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.861 seconds
[2025-09-29T00:18:04.780+0000] {processor.py:157} INFO - Started process (PID=46952) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:18:04.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:18:04.782+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:04.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:18:05.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:18:05.362+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:05.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:18:05.386+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:05.386+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:18:05.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.633 seconds
[2025-09-29T00:18:35.783+0000] {processor.py:157} INFO - Started process (PID=47259) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:18:35.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:18:35.785+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:35.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:18:36.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:18:36.409+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:36.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:18:36.434+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:36.434+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:18:36.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.683 seconds
[2025-09-29T00:19:06.937+0000] {processor.py:157} INFO - Started process (PID=47566) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:19:06.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:19:06.939+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:06.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:19:07.402+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:19:07.429+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:07.429+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:19:07.455+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:07.455+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:19:07.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.547 seconds
[2025-09-29T00:19:37.650+0000] {processor.py:157} INFO - Started process (PID=47873) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:19:37.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:19:37.653+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:37.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:19:38.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:19:38.124+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:38.124+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:19:38.152+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:38.152+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:19:38.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.532 seconds
[2025-09-29T00:20:08.225+0000] {processor.py:157} INFO - Started process (PID=48180) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:20:08.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:20:08.227+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:08.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:20:08.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:20:08.737+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:08.737+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:20:08.766+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:08.766+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:20:08.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.569 seconds
[2025-09-29T00:20:39.050+0000] {processor.py:157} INFO - Started process (PID=48487) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:20:39.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:20:39.052+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:39.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:20:39.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:20:39.505+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:39.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:20:39.558+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:39.558+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:20:39.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.547 seconds
[2025-09-29T00:21:09.925+0000] {processor.py:157} INFO - Started process (PID=48794) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:21:09.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:21:09.927+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:09.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:21:10.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:21:10.407+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:10.406+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:21:10.439+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:10.439+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:21:10.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.545 seconds
[2025-09-29T00:21:40.836+0000] {processor.py:157} INFO - Started process (PID=49101) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:21:40.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:21:40.839+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:40.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:21:41.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:21:41.305+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:41.305+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:21:41.331+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:41.331+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:21:41.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.525 seconds
[2025-09-29T00:22:11.711+0000] {processor.py:157} INFO - Started process (PID=49408) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:22:11.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:22:11.713+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:11.713+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:22:12.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:22:12.171+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:12.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:22:12.198+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:12.198+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:22:12.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.511 seconds
[2025-09-29T00:22:42.579+0000] {processor.py:157} INFO - Started process (PID=49715) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:22:42.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:22:42.581+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:42.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:22:43.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:22:43.042+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:43.042+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:22:43.069+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:43.069+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:22:43.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.514 seconds
[2025-09-29T00:23:13.297+0000] {processor.py:157} INFO - Started process (PID=50022) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:23:13.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:23:13.299+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:13.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:23:13.739+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:23:13.765+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:13.765+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:23:13.792+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:13.792+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:23:13.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.522 seconds
[2025-09-29T00:23:43.900+0000] {processor.py:157} INFO - Started process (PID=50329) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:23:43.901+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:23:43.902+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:43.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:23:44.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:23:44.356+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:44.355+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:23:44.519+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:44.519+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:23:44.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.645 seconds
[2025-09-29T00:24:14.954+0000] {processor.py:157} INFO - Started process (PID=50647) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:24:14.955+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:24:14.957+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:14.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:24:15.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:24:15.482+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:15.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:24:15.639+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:15.639+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:24:15.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.709 seconds
[2025-09-29T00:24:46.137+0000] {processor.py:157} INFO - Started process (PID=50961) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:24:46.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:24:46.139+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:46.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:24:46.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:24:46.693+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:46.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:24:46.726+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:46.725+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:24:46.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.615 seconds
[2025-09-29T00:25:16.981+0000] {processor.py:157} INFO - Started process (PID=51255) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:25:16.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:25:16.984+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:16.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:25:17.600+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:25:17.629+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:17.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:25:17.658+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:17.658+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:25:17.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.707 seconds
[2025-09-29T00:25:48.593+0000] {processor.py:157} INFO - Started process (PID=51562) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:25:48.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:25:48.595+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:48.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:25:49.171+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:25:49.198+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:49.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:25:49.226+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:49.226+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:25:49.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.660 seconds
[2025-09-29T00:26:19.986+0000] {processor.py:157} INFO - Started process (PID=51869) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:26:19.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:26:19.988+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:19.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:26:20.562+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:26:20.586+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:20.586+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:26:20.609+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:20.609+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:26:20.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.649 seconds
[2025-09-29T00:26:51.528+0000] {processor.py:157} INFO - Started process (PID=52176) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:26:51.529+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:26:51.530+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:51.530+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:26:52.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:26:52.154+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:52.153+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:26:52.180+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:52.180+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:26:52.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.677 seconds
[2025-09-29T00:27:22.825+0000] {processor.py:157} INFO - Started process (PID=52483) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:27:22.827+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:27:22.828+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:27:22.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:27:23.372+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:27:23.412+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:27:23.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:27:23.441+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:27:23.441+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:27:23.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.645 seconds
[2025-09-29T00:42:32.868+0000] {processor.py:157} INFO - Started process (PID=52765) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:42:32.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:42:32.890+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:42:32.889+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:42:34.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:42:34.123+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:42:34.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:42:34.175+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:42:34.174+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:42:34.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.343 seconds
[2025-09-29T00:43:04.500+0000] {processor.py:157} INFO - Started process (PID=53078) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:43:04.501+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:43:04.502+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:43:04.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:43:05.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:43:05.089+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:43:05.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:43:05.116+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:43:05.116+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:43:05.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.645 seconds
[2025-09-29T00:58:18.907+0000] {processor.py:157} INFO - Started process (PID=53379) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:58:18.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:58:18.915+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:18.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:58:19.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:58:19.988+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:19.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:58:20.026+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:20.026+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:58:20.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.157 seconds
[2025-09-29T00:58:50.632+0000] {processor.py:157} INFO - Started process (PID=53692) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:58:50.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:58:50.763+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:50.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:59:03.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:59:04.244+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:04.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:59:05.536+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:05.521+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:59:06.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 15.692 seconds
[2025-09-29T00:59:36.403+0000] {processor.py:157} INFO - Started process (PID=54000) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:59:36.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T00:59:36.406+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:36.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:59:37.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T00:59:37.109+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:37.108+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:59:37.140+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:37.140+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T00:59:37.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.770 seconds
[2025-09-29T01:00:07.218+0000] {processor.py:157} INFO - Started process (PID=54307) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:00:07.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:00:07.221+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:00:07.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:00:08.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:00:08.175+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:00:08.174+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:00:08.312+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:00:08.312+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:00:08.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.150 seconds
[2025-09-29T01:10:45.753+0000] {processor.py:157} INFO - Started process (PID=54338) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:10:45.770+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:10:45.802+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:10:45.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:10:47.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:10:47.390+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:10:47.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:10:47.452+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:10:47.451+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:10:47.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.756 seconds
[2025-09-29T01:11:18.222+0000] {processor.py:157} INFO - Started process (PID=54646) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:11:18.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:11:18.225+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:18.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:11:18.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:11:18.819+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:18.819+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:11:18.846+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:18.846+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:11:18.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.654 seconds
[2025-09-29T01:11:49.164+0000] {processor.py:157} INFO - Started process (PID=54953) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:11:49.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:11:49.166+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:49.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:11:49.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:11:49.784+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:49.783+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:11:49.809+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:49.808+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:11:49.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.671 seconds
[2025-09-29T01:12:20.111+0000] {processor.py:157} INFO - Started process (PID=55260) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:12:20.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:12:20.113+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:20.113+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:12:20.747+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:12:20.773+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:20.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:12:20.797+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:20.797+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:12:20.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.710 seconds
[2025-09-29T01:12:51.114+0000] {processor.py:157} INFO - Started process (PID=55567) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:12:51.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:12:51.117+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:51.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:12:51.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:12:51.760+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:51.759+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:12:51.786+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:51.786+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:12:51.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.697 seconds
[2025-09-29T01:13:22.050+0000] {processor.py:157} INFO - Started process (PID=55874) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:13:22.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:13:22.052+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:22.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:13:22.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:13:22.679+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:22.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:13:22.707+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:22.707+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:13:22.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.681 seconds
[2025-09-29T01:13:52.908+0000] {processor.py:157} INFO - Started process (PID=56181) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:13:52.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:13:52.911+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:52.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:13:53.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:13:53.559+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:53.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:13:53.585+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:53.585+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:13:53.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.701 seconds
[2025-09-29T01:14:23.677+0000] {processor.py:157} INFO - Started process (PID=56488) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:14:23.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:14:23.680+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:23.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:14:24.150+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:14:24.176+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:24.175+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:14:24.206+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:24.206+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:14:24.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.561 seconds
[2025-09-29T01:14:54.426+0000] {processor.py:157} INFO - Started process (PID=56795) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:14:54.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:14:54.429+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:54.428+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:14:54.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:14:54.936+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:54.936+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:14:54.971+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:54.971+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:14:54.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.574 seconds
[2025-09-29T01:15:25.373+0000] {processor.py:157} INFO - Started process (PID=57102) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:15:25.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:15:25.375+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:25.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:15:25.839+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:15:25.868+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:25.867+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:15:25.898+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:25.897+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:15:25.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.554 seconds
[2025-09-29T01:15:56.237+0000] {processor.py:157} INFO - Started process (PID=57409) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:15:56.238+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:15:56.239+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:56.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:15:56.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:15:56.785+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:56.785+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:15:56.812+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:56.812+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:15:56.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.603 seconds
[2025-09-29T01:16:27.315+0000] {processor.py:157} INFO - Started process (PID=57716) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:16:27.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:16:27.317+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:27.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:16:27.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:16:27.832+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:27.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:16:27.860+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:27.860+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:16:27.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.574 seconds
[2025-09-29T01:16:58.246+0000] {processor.py:157} INFO - Started process (PID=58023) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:16:58.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:16:58.250+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:58.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:16:58.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:16:58.726+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:58.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:16:58.754+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:58.754+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:16:58.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.542 seconds
[2025-09-29T01:17:29.147+0000] {processor.py:157} INFO - Started process (PID=58330) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:17:29.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:17:29.150+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:29.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:17:29.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:17:29.633+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:29.632+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:17:29.663+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:29.663+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:17:29.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.546 seconds
[2025-09-29T01:17:59.838+0000] {processor.py:157} INFO - Started process (PID=58637) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:17:59.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:17:59.841+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:59.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:18:00.305+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:18:00.337+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:00.336+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:18:00.370+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:00.370+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:18:00.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.563 seconds
[2025-09-29T01:18:30.543+0000] {processor.py:157} INFO - Started process (PID=58943) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:18:30.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:18:30.546+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:30.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:18:31.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:18:31.034+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:31.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:18:31.064+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:31.064+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:18:31.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.554 seconds
[2025-09-29T01:19:01.270+0000] {processor.py:157} INFO - Started process (PID=59250) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:19:01.271+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:19:01.273+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:01.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:19:01.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:19:01.805+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:01.804+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:19:01.832+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:01.832+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:19:01.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.586 seconds
[2025-09-29T01:19:32.567+0000] {processor.py:157} INFO - Started process (PID=59557) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:19:32.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:19:32.569+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:32.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:19:33.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:19:33.038+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:33.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:19:33.201+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:33.201+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:19:33.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.659 seconds
[2025-09-29T01:20:03.691+0000] {processor.py:157} INFO - Started process (PID=59864) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:20:03.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:20:03.694+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:03.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:20:04.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:20:04.195+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:04.195+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:20:04.234+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:04.234+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:20:04.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.582 seconds
[2025-09-29T01:20:34.519+0000] {processor.py:157} INFO - Started process (PID=60171) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:20:34.520+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:20:34.521+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:34.521+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:20:34.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:20:35.137+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:35.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:20:35.166+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:35.166+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:20:35.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.676 seconds
[2025-09-29T01:21:05.369+0000] {processor.py:157} INFO - Started process (PID=60478) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:21:05.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:21:05.372+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:21:05.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:21:05.975+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:21:06.000+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:21:06.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:21:06.026+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:21:06.026+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:21:06.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.685 seconds
[2025-09-29T01:36:18.173+0000] {processor.py:157} INFO - Started process (PID=60778) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:36:18.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:36:18.179+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:18.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:36:19.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:36:19.224+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:19.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:36:19.265+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:19.265+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:36:19.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.138 seconds
[2025-09-29T01:36:50.596+0000] {processor.py:157} INFO - Started process (PID=61082) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:36:50.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:36:50.627+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:50.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:37:03.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:37:04.624+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:37:04.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:37:05.349+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:37:05.347+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:37:05.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 15.229 seconds
[2025-09-29T01:52:05.206+0000] {processor.py:157} INFO - Started process (PID=61154) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:52:05.213+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:52:05.215+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:05.215+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:52:06.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:52:06.295+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:06.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:52:06.341+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:06.341+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:52:06.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.179 seconds
[2025-09-29T01:52:37.147+0000] {processor.py:157} INFO - Started process (PID=61461) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:52:37.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:52:37.188+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:37.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:52:50.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:52:51.295+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:51.283+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:52:51.929+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:51.926+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:52:52.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 15.261 seconds
[2025-09-29T01:53:22.832+0000] {processor.py:157} INFO - Started process (PID=61778) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:53:22.834+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:53:22.836+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:22.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:53:23.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:53:23.686+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:23.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:53:23.717+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:23.717+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:53:23.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.919 seconds
[2025-09-29T01:53:54.223+0000] {processor.py:157} INFO - Started process (PID=62075) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:53:54.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:53:54.226+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:54.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:53:55.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:53:55.126+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:55.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:53:55.173+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:55.173+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:53:55.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.991 seconds
[2025-09-29T01:54:25.731+0000] {processor.py:157} INFO - Started process (PID=62382) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:54:25.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:54:25.737+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:25.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:54:27.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:54:27.437+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:27.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:54:27.529+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:27.528+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:54:27.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.884 seconds
[2025-09-29T01:54:57.792+0000] {processor.py:157} INFO - Started process (PID=62689) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:54:57.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:54:57.796+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:57.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:54:58.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:54:58.678+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:58.678+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:54:58.721+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:58.721+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:54:58.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.974 seconds
[2025-09-29T01:55:29.327+0000] {processor.py:157} INFO - Started process (PID=62996) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:55:29.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:55:29.330+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:55:29.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:55:30.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:55:30.384+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:55:30.383+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:55:30.480+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:55:30.479+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:55:30.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.246 seconds
[2025-09-29T01:56:00.694+0000] {processor.py:157} INFO - Started process (PID=63303) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:56:00.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:56:00.696+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:00.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:56:01.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:56:01.524+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:01.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:56:01.562+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:01.562+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:56:01.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.906 seconds
[2025-09-29T01:56:31.782+0000] {processor.py:157} INFO - Started process (PID=63610) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:56:31.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:56:31.785+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:31.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:56:32.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:56:32.423+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:32.422+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:56:32.472+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:32.471+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:56:32.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.727 seconds
[2025-09-29T01:57:02.600+0000] {processor.py:157} INFO - Started process (PID=63917) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:57:02.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T01:57:02.602+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:57:02.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:57:03.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T01:57:03.240+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:57:03.239+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:57:03.277+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:57:03.276+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T01:57:03.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.709 seconds
[2025-09-29T02:12:06.710+0000] {processor.py:157} INFO - Started process (PID=63957) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:12:06.714+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:12:06.717+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:06.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:12:07.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:12:07.725+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:07.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:12:07.763+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:07.763+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:12:07.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.091 seconds
[2025-09-29T02:12:38.662+0000] {processor.py:157} INFO - Started process (PID=64264) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:12:38.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:12:38.708+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:38.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:12:49.935+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:12:50.512+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:50.502+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:12:51.113+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:51.110+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:12:51.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 13.145 seconds
[2025-09-29T02:27:58.490+0000] {processor.py:157} INFO - Started process (PID=64558) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:27:58.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:27:58.497+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:27:58.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:27:59.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:27:59.103+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:27:59.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:27:59.141+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:27:59.141+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:27:59.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.693 seconds
[2025-09-29T02:28:36.111+0000] {processor.py:157} INFO - Started process (PID=64682) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:28:36.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:28:36.155+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:28:36.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:28:47.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:28:48.427+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:28:48.420+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:28:49.183+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:28:49.181+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:28:49.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 13.686 seconds
[2025-09-29T02:29:20.218+0000] {processor.py:157} INFO - Started process (PID=64991) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:29:20.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:29:20.224+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:20.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:29:21.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:29:21.142+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:21.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:29:21.200+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:21.199+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:29:21.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.046 seconds
[2025-09-29T02:29:51.454+0000] {processor.py:157} INFO - Started process (PID=65298) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:29:51.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:29:51.462+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:51.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:29:53.107+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:29:53.225+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:53.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:29:53.474+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:53.473+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:29:53.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.194 seconds
[2025-09-29T02:30:23.846+0000] {processor.py:157} INFO - Started process (PID=65605) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:30:23.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:30:23.850+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:23.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:30:24.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:30:24.866+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:24.865+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:30:24.933+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:24.933+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:30:24.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.149 seconds
[2025-09-29T02:30:55.251+0000] {processor.py:157} INFO - Started process (PID=65912) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:30:55.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:30:55.257+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:55.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:30:56.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:30:56.606+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:56.605+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:30:56.692+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:56.691+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:30:56.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.518 seconds
[2025-09-29T02:31:27.500+0000] {processor.py:157} INFO - Started process (PID=66226) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:31:27.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:31:27.504+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:27.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:31:28.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:31:28.519+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:28.517+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:31:28.649+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:28.649+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:31:28.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.236 seconds
[2025-09-29T02:31:59.223+0000] {processor.py:157} INFO - Started process (PID=66533) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:31:59.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:31:59.226+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:59.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:32:00.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:32:00.098+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:00.097+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:32:00.198+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:00.198+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:32:00.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.065 seconds
[2025-09-29T02:32:30.786+0000] {processor.py:157} INFO - Started process (PID=66840) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:32:30.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:32:30.789+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:30.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:32:31.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:32:31.524+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:31.523+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:32:31.736+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:31.735+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:32:31.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.991 seconds
[2025-09-29T02:33:02.171+0000] {processor.py:157} INFO - Started process (PID=67147) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:33:02.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:33:02.174+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:02.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:33:02.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:33:02.833+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:02.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:33:02.875+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:02.875+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:33:02.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.741 seconds
[2025-09-29T02:33:33.661+0000] {processor.py:157} INFO - Started process (PID=67453) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:33:33.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:33:33.664+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:33.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:33:34.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:33:34.462+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:34.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:33:34.498+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:34.498+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:33:34.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.873 seconds
[2025-09-29T02:34:05.249+0000] {processor.py:157} INFO - Started process (PID=67760) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:34:05.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:34:05.251+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:05.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:34:05.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:34:05.927+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:05.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:34:05.957+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:05.957+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:34:05.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.741 seconds
[2025-09-29T02:34:36.196+0000] {processor.py:157} INFO - Started process (PID=68067) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:34:36.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:34:36.199+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:36.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:34:36.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:34:36.890+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:36.889+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:34:36.921+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:36.921+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:34:36.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.755 seconds
[2025-09-29T02:35:07.793+0000] {processor.py:157} INFO - Started process (PID=68374) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:35:07.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T02:35:07.795+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:35:07.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:35:08.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T02:35:08.561+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:35:08.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:35:08.592+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:35:08.592+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T02:35:08.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.831 seconds
[2025-09-29T03:05:27.584+0000] {processor.py:157} INFO - Started process (PID=68688) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:05:27.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:05:27.597+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:27.592+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:05:28.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:05:28.452+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:28.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:05:28.522+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:28.521+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:05:28.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.992 seconds
[2025-09-29T03:05:59.283+0000] {processor.py:157} INFO - Started process (PID=68995) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:05:59.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:05:59.336+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:59.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:06:12.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:06:12.785+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:12.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:06:13.930+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:13.921+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:06:14.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 15.253 seconds
[2025-09-29T03:06:44.836+0000] {processor.py:157} INFO - Started process (PID=69302) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:06:44.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:06:44.840+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:44.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:06:46.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:06:46.079+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:46.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:06:46.150+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:46.150+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:06:46.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.380 seconds
[2025-09-29T03:07:16.593+0000] {processor.py:157} INFO - Started process (PID=69609) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:07:16.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:07:16.598+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:16.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:07:18.299+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:07:18.412+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:18.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:07:18.509+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:18.508+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:07:18.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.006 seconds
[2025-09-29T03:07:48.876+0000] {processor.py:157} INFO - Started process (PID=69916) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:07:48.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:07:48.883+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:48.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:07:50.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:07:50.419+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:50.418+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:07:50.488+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:50.487+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:07:50.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.683 seconds
[2025-09-29T03:08:20.894+0000] {processor.py:157} INFO - Started process (PID=70223) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:08:20.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:08:20.900+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:20.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:08:22.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:08:22.574+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:22.572+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:08:22.663+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:22.663+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:08:22.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.843 seconds
[2025-09-29T03:08:52.815+0000] {processor.py:157} INFO - Started process (PID=70530) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:08:52.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:08:52.821+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:52.821+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:08:54.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:08:54.625+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:54.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:08:54.700+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:54.699+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:08:54.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.954 seconds
[2025-09-29T03:09:24.902+0000] {processor.py:157} INFO - Started process (PID=70837) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:09:24.905+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:09:24.908+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:24.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:09:26.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:09:26.549+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:26.548+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:09:26.628+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:26.627+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:09:26.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.800 seconds
[2025-09-29T03:09:56.814+0000] {processor.py:157} INFO - Started process (PID=71144) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:09:56.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:09:56.819+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:56.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:09:57.851+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:09:57.895+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:57.895+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:09:57.947+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:57.946+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:09:57.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.185 seconds
[2025-09-29T03:10:28.364+0000] {processor.py:157} INFO - Started process (PID=71451) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:10:28.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:10:28.368+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:28.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:10:29.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:10:29.423+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:29.422+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:10:29.473+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:29.473+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:10:29.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.160 seconds
[2025-09-29T03:10:59.956+0000] {processor.py:157} INFO - Started process (PID=71758) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:10:59.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:10:59.958+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:59.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:11:00.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:11:00.751+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:00.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:11:00.789+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:00.788+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:11:00.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.881 seconds
[2025-09-29T03:11:31.156+0000] {processor.py:157} INFO - Started process (PID=72072) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:11:31.158+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:11:31.159+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:31.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:11:31.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:11:31.973+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:31.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:11:32.011+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:32.011+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:11:32.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.892 seconds
[2025-09-29T03:12:02.154+0000] {processor.py:157} INFO - Started process (PID=72379) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:12:02.156+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:12:02.157+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:02.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:12:02.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:12:02.886+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:02.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:12:02.918+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:02.917+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:12:02.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.797 seconds
[2025-09-29T03:12:33.318+0000] {processor.py:157} INFO - Started process (PID=72686) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:12:33.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:12:33.322+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:33.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:12:34.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:12:34.362+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:34.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:12:34.404+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:34.404+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:12:34.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.128 seconds
[2025-09-29T03:13:05.034+0000] {processor.py:157} INFO - Started process (PID=72993) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:13:05.035+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:13:05.037+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:05.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:13:05.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:13:05.837+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:05.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:13:05.877+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:05.876+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:13:05.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.879 seconds
[2025-09-29T03:13:35.962+0000] {processor.py:157} INFO - Started process (PID=73300) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:13:35.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:13:35.966+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:35.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:13:36.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:13:36.867+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:36.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:13:36.936+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:36.936+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:13:36.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.017 seconds
[2025-09-29T03:14:07.842+0000] {processor.py:157} INFO - Started process (PID=73607) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:14:07.844+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:14:07.846+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:14:07.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:14:08.505+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:14:08.546+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:14:08.545+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:14:08.592+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:14:08.592+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:14:08.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.798 seconds
[2025-09-29T03:16:51.416+0000] {processor.py:157} INFO - Started process (PID=73793) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:16:51.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:16:51.420+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:16:51.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:16:52.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:16:52.103+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:16:52.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:16:52.144+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:16:52.144+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:16:52.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.761 seconds
[2025-09-29T03:17:27.767+0000] {processor.py:157} INFO - Started process (PID=74098) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:17:27.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:17:27.862+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:27.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:17:38.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:17:39.266+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:39.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:17:39.919+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:39.914+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:17:40.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 12.699 seconds
[2025-09-29T03:17:51.972+0000] {processor.py:157} INFO - Started process (PID=74163) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:17:51.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:17:51.986+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:51.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:44:24.929+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:44:24.928+0000] {timeout.py:68} ERROR - Process timed out, PID: 74163
[2025-09-29T03:44:25.153+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:44:24.952+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistic_dag2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistic_dag2.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 129, in <module>
    from pandas.core import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 144, in <module>
    from pandas.core.window import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/window/__init__.py", line 1, in <module>
    from pandas.core.window.ewm import (  # noqa:F401
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/window/ewm.py", line 48, in <module>
    from pandas.core.window.rolling import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/window/rolling.py", line 1487, in <module>
    class Rolling(RollingAndExpandingMixin):
  File "/usr/local/lib/python3.7/typing.py", line 855, in __init_subclass__
    error = Generic in cls.__bases__ and cls.__name__ != '_Protocol'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistic_dag2.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 74163
[2025-09-29T03:44:25.163+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:44:56.295+0000] {processor.py:157} INFO - Started process (PID=74481) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:44:56.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:44:56.328+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:44:56.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:45:12.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:45:12.690+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:12.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:45:13.482+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:13.478+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:45:13.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 17.653 seconds
[2025-09-29T03:45:49.215+0000] {processor.py:157} INFO - Started process (PID=74786) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:45:49.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:45:49.221+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:49.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:45:50.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:45:50.651+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:50.650+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:45:50.750+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:50.749+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:45:50.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.617 seconds
[2025-09-29T03:46:22.892+0000] {processor.py:157} INFO - Started process (PID=75083) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:46:22.895+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:46:22.901+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:22.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:46:24.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:46:24.739+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:24.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:46:24.909+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:24.908+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:46:25.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.176 seconds
[2025-09-29T03:46:55.767+0000] {processor.py:157} INFO - Started process (PID=75390) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:46:55.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:46:55.771+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:55.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:46:56.937+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:46:57.005+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:57.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:46:57.084+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:57.083+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:46:57.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.391 seconds
[2025-09-29T03:47:29.255+0000] {processor.py:157} INFO - Started process (PID=75704) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:47:29.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:47:29.264+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:47:29.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:47:30.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:47:30.450+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:47:30.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:47:30.542+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:47:30.542+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:47:30.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.374 seconds
[2025-09-29T03:48:00.802+0000] {processor.py:157} INFO - Started process (PID=76011) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:48:00.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:48:00.808+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:00.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:48:02.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:48:02.452+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:02.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:48:02.528+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:02.527+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:48:02.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.801 seconds
[2025-09-29T03:48:32.778+0000] {processor.py:157} INFO - Started process (PID=76318) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:48:32.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:48:32.784+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:32.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:48:33.856+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:48:33.923+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:33.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:48:33.994+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:33.993+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:48:34.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.283 seconds
[2025-09-29T03:49:04.862+0000] {processor.py:157} INFO - Started process (PID=76625) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:49:04.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:49:04.867+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:04.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:49:05.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:49:05.923+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:05.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:49:05.991+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:05.991+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:49:06.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.187 seconds
[2025-09-29T03:49:36.486+0000] {processor.py:157} INFO - Started process (PID=76932) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:49:36.488+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:49:36.490+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:36.490+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:49:37.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:49:37.404+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:37.404+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:49:37.461+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:37.460+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:49:37.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.029 seconds
[2025-09-29T03:50:07.790+0000] {processor.py:157} INFO - Started process (PID=77239) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:50:07.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:50:07.793+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:07.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:50:08.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:50:08.565+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:08.564+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:50:08.614+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:08.614+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:50:08.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.870 seconds
[2025-09-29T03:50:38.948+0000] {processor.py:157} INFO - Started process (PID=77546) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:50:38.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:50:38.951+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:38.950+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:50:39.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:50:39.642+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:39.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:50:39.685+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:39.685+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:50:39.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.779 seconds
[2025-09-29T03:51:10.135+0000] {processor.py:157} INFO - Started process (PID=77854) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:51:10.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:51:10.139+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:10.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:51:10.850+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:51:10.898+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:10.897+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:51:10.946+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:10.946+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:51:10.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.855 seconds
[2025-09-29T03:51:41.810+0000] {processor.py:157} INFO - Started process (PID=78161) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:51:41.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:51:41.817+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:41.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:51:42.611+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:51:42.663+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:42.662+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:51:42.748+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:42.748+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:51:42.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.010 seconds
[2025-09-29T03:52:13.233+0000] {processor.py:157} INFO - Started process (PID=78468) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:52:13.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:52:13.236+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:13.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:52:13.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:52:14.079+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:14.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:52:14.156+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:14.156+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:52:14.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.017 seconds
[2025-09-29T03:52:44.632+0000] {processor.py:157} INFO - Started process (PID=78775) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:52:44.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:52:44.635+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:44.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:52:45.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:52:45.294+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:45.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:52:45.335+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:45.335+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:52:45.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.906 seconds
[2025-09-29T03:53:15.868+0000] {processor.py:157} INFO - Started process (PID=79082) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:53:15.871+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T03:53:15.873+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:53:15.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:53:16.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T03:53:16.665+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:53:16.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:53:16.699+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:53:16.699+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T03:53:16.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.868 seconds
[2025-09-29T04:17:53.274+0000] {processor.py:157} INFO - Started process (PID=79132) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:17:53.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:17:53.277+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:17:53.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:17:54.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:17:54.180+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:17:54.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:17:54.221+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:17:54.220+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:17:54.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.981 seconds
[2025-09-29T04:18:24.993+0000] {processor.py:157} INFO - Started process (PID=79439) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:18:25.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:18:25.101+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:18:25.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:18:38.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:18:39.194+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:18:39.185+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:18:40.191+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:18:40.189+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:18:40.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 15.804 seconds
[2025-09-29T04:19:16.354+0000] {processor.py:157} INFO - Started process (PID=79511) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:19:16.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:19:16.360+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:16.360+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:19:17.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:19:17.427+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:17.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:19:17.495+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:17.494+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:19:17.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.198 seconds
[2025-09-29T04:19:48.313+0000] {processor.py:157} INFO - Started process (PID=79820) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:19:48.315+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:19:48.316+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:48.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:19:48.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:19:48.890+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:48.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:19:48.920+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:48.919+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:19:48.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.635 seconds
[2025-09-29T04:20:19.371+0000] {processor.py:157} INFO - Started process (PID=80127) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:20:19.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:20:19.374+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:19.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:20:19.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:20:19.852+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:19.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:20:19.881+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:19.881+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:20:19.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.546 seconds
[2025-09-29T04:20:50.272+0000] {processor.py:157} INFO - Started process (PID=80434) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:20:50.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:20:50.274+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:50.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:20:50.748+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:20:50.776+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:50.776+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:20:50.812+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:50.812+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:20:50.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.572 seconds
[2025-09-29T04:23:19.852+0000] {processor.py:157} INFO - Started process (PID=80705) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:23:19.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:23:19.859+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:19.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:23:20.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:23:20.703+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:20.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:23:20.740+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:20.740+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:23:20.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.933 seconds
[2025-09-29T04:23:51.010+0000] {processor.py:157} INFO - Started process (PID=81012) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:23:51.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:23:51.012+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:51.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:23:51.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:23:51.559+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:51.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:23:51.587+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:51.587+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:23:51.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.610 seconds
[2025-09-29T04:24:22.171+0000] {processor.py:157} INFO - Started process (PID=81319) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:24:22.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:24:22.173+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:22.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:24:22.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:24:22.690+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:22.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:24:22.724+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:22.724+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:24:22.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.588 seconds
[2025-09-29T04:24:53.085+0000] {processor.py:157} INFO - Started process (PID=81626) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:24:53.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:24:53.090+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:53.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:24:53.566+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:24:53.598+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:53.597+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:24:53.631+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:53.631+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:24:53.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.581 seconds
[2025-09-29T04:25:24.048+0000] {processor.py:157} INFO - Started process (PID=81963) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:25:24.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:25:24.051+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:24.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:25:24.510+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:25:24.536+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:24.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:25:24.571+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:24.571+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:25:24.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.555 seconds
[2025-09-29T04:25:54.687+0000] {processor.py:157} INFO - Started process (PID=82271) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:25:54.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:25:54.689+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:54.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:25:55.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:25:55.240+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:55.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:25:55.276+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:55.275+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:25:55.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.616 seconds
[2025-09-29T04:26:25.541+0000] {processor.py:157} INFO - Started process (PID=82578) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:26:25.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:26:25.543+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:25.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:26:25.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:26:26.031+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:26.030+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:26:26.057+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:26.057+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:26:26.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.546 seconds
[2025-09-29T04:26:56.373+0000] {processor.py:157} INFO - Started process (PID=82885) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:26:56.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:26:56.376+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:56.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:26:56.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:26:56.861+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:56.860+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:26:56.890+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:56.890+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:26:56.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.546 seconds
[2025-09-29T04:27:27.312+0000] {processor.py:157} INFO - Started process (PID=83192) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:27:27.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:27:27.314+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:27.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:27:27.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:27:27.803+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:27.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:27:27.831+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:27.831+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:27:27.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.545 seconds
[2025-09-29T04:27:57.974+0000] {processor.py:157} INFO - Started process (PID=83499) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:27:57.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:27:57.976+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:57.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:27:58.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:27:58.433+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:58.433+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:27:58.464+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:58.463+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:27:58.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.518 seconds
[2025-09-29T04:28:29.083+0000] {processor.py:157} INFO - Started process (PID=83806) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:28:29.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:28:29.086+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:28:29.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:28:29.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:28:29.682+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:28:29.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:28:29.713+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:28:29.713+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:28:29.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.792 seconds
[2025-09-29T04:29:00.333+0000] {processor.py:157} INFO - Started process (PID=84113) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:29:00.334+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:29:00.335+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:00.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:29:00.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:29:00.796+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:00.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:29:00.822+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:00.822+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:29:00.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.517 seconds
[2025-09-29T04:29:30.910+0000] {processor.py:157} INFO - Started process (PID=84429) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:29:30.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:29:30.912+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:30.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:29:31.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:29:31.416+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:31.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:29:31.577+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:31.577+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:29:31.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.693 seconds
[2025-09-29T04:30:01.941+0000] {processor.py:157} INFO - Started process (PID=84736) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:30:01.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:30:01.943+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:01.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:30:02.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:30:02.760+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:02.760+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:30:02.796+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:02.796+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:30:02.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.882 seconds
[2025-09-29T04:30:33.321+0000] {processor.py:157} INFO - Started process (PID=85073) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:30:33.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:30:33.324+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:33.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:30:34.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:30:34.285+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:34.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:30:34.336+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:34.336+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:30:34.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.055 seconds
[2025-09-29T04:31:04.643+0000] {processor.py:157} INFO - Started process (PID=85380) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:31:04.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:31:04.645+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:04.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:31:05.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:31:05.350+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:05.349+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:31:05.380+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:05.380+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:31:05.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.766 seconds
[2025-09-29T04:31:36.158+0000] {processor.py:157} INFO - Started process (PID=85687) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:31:36.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:31:36.161+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:36.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:31:36.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:31:36.797+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:36.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:31:36.825+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:36.824+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:31:36.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.691 seconds
[2025-09-29T04:32:06.884+0000] {processor.py:157} INFO - Started process (PID=85994) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:32:06.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:32:06.886+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:06.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:32:07.530+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:32:07.554+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:07.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:32:07.578+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:07.578+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:32:07.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.717 seconds
[2025-09-29T04:32:37.813+0000] {processor.py:157} INFO - Started process (PID=86301) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:32:37.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:32:37.815+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:37.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:32:38.423+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:32:38.446+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:38.445+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:32:38.470+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:38.470+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:32:38.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.683 seconds
[2025-09-29T04:33:09.241+0000] {processor.py:157} INFO - Started process (PID=86623) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:33:09.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:33:09.244+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:09.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:33:10.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:33:10.306+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:10.306+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:33:10.350+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:10.350+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:33:10.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.139 seconds
[2025-09-29T04:33:40.654+0000] {processor.py:157} INFO - Started process (PID=86940) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:33:40.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:33:40.656+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:40.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:33:41.488+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:33:41.520+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:41.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:33:41.559+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:41.559+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:33:41.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.941 seconds
[2025-09-29T04:34:12.059+0000] {processor.py:157} INFO - Started process (PID=87237) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:34:12.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:34:12.063+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:12.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:34:12.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:34:13.455+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:34:43.652+0000] {processor.py:157} INFO - Started process (PID=87553) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:34:43.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:34:43.654+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:43.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:34:44.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:34:44.493+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:44.493+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:34:44.518+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:44.518+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:34:44.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.893 seconds
[2025-09-29T04:35:15.440+0000] {processor.py:157} INFO - Started process (PID=87869) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:35:15.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:35:15.442+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:15.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:35:16.072+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:35:16.097+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:16.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:35:16.121+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:16.120+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:35:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.705 seconds
[2025-09-29T04:35:46.578+0000] {processor.py:157} INFO - Started process (PID=88176) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:35:46.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:35:46.580+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:46.580+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:35:47.172+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:35:47.194+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:47.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:35:47.217+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:47.217+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:35:47.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.666 seconds
[2025-09-29T04:36:17.763+0000] {processor.py:157} INFO - Started process (PID=88483) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:36:17.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:36:17.765+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:17.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:36:18.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:36:18.375+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:18.375+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:36:18.399+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:18.399+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:36:18.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.659 seconds
[2025-09-29T04:36:49.227+0000] {processor.py:157} INFO - Started process (PID=88790) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:36:49.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:36:49.230+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:49.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:36:49.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:36:50.385+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:50.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:36:50.418+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:50.418+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:36:50.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.224 seconds
[2025-09-29T04:37:21.001+0000] {processor.py:157} INFO - Started process (PID=89110) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:37:21.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:37:21.003+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:21.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:37:21.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:37:21.637+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:21.637+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:37:21.661+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:21.661+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:37:21.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.688 seconds
[2025-09-29T04:37:52.373+0000] {processor.py:157} INFO - Started process (PID=89424) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:37:52.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:37:52.375+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:52.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:37:52.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:37:52.968+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:52.968+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:37:52.993+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:52.993+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:37:53.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.645 seconds
[2025-09-29T04:38:23.061+0000] {processor.py:157} INFO - Started process (PID=89731) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:38:23.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:38:23.063+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:23.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:38:23.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:38:23.636+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:23.635+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:38:23.660+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:23.660+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:38:23.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.622 seconds
[2025-09-29T04:38:53.913+0000] {processor.py:157} INFO - Started process (PID=90038) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:38:53.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:38:53.915+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:53.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:38:54.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:38:54.690+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:54.690+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:38:54.714+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:54.713+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:38:54.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.823 seconds
[2025-09-29T04:39:25.289+0000] {processor.py:157} INFO - Started process (PID=90354) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:39:25.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:39:25.291+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:25.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:39:25.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:39:25.930+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:25.930+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:39:25.957+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:25.957+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:39:25.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.691 seconds
[2025-09-29T04:39:56.116+0000] {processor.py:157} INFO - Started process (PID=90658) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:39:56.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:39:56.118+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:56.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:39:56.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:39:56.567+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:56.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:39:56.593+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:56.593+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:39:56.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.501 seconds
[2025-09-29T04:40:27.033+0000] {processor.py:157} INFO - Started process (PID=90955) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:40:27.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:40:27.035+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:40:27.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:40:27.524+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:40:28.900+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:40:28.899+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:40:28.937+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:40:28.936+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:40:28.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.938 seconds
[2025-09-29T04:40:59.651+0000] {processor.py:157} INFO - Started process (PID=91286) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:40:59.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:40:59.653+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:40:59.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:41:00.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:41:00.122+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:41:00.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:41:00.150+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:41:00.150+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:41:00.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.523 seconds
[2025-09-29T04:41:30.696+0000] {processor.py:157} INFO - Started process (PID=91593) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:41:30.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:41:30.698+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:41:30.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:41:31.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:41:31.653+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:42:01.873+0000] {processor.py:157} INFO - Started process (PID=91905) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:42:01.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:42:01.875+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:01.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:42:02.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:42:02.554+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:02.553+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:42:02.583+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:02.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:42:02.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.733 seconds
[2025-09-29T04:42:33.979+0000] {processor.py:157} INFO - Started process (PID=92212) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:42:33.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:42:33.980+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:33.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:42:34.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:42:34.451+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:34.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:42:34.479+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:34.479+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:42:34.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.523 seconds
[2025-09-29T04:43:04.628+0000] {processor.py:157} INFO - Started process (PID=92518) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:43:04.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:43:04.630+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:04.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:43:05.056+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:43:05.082+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:05.082+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:43:05.107+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:05.107+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:43:05.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.503 seconds
[2025-09-29T04:43:35.283+0000] {processor.py:157} INFO - Started process (PID=92813) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:43:35.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:43:35.285+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:35.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:43:35.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:43:36.579+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:44:07.109+0000] {processor.py:157} INFO - Started process (PID=93122) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:44:07.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:44:07.111+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:07.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:44:07.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:44:07.580+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:07.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:44:07.607+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:07.606+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:44:07.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.528 seconds
[2025-09-29T04:44:38.176+0000] {processor.py:157} INFO - Started process (PID=93429) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:44:38.177+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:44:38.178+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:38.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:44:38.611+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:44:39.131+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:39.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:44:39.158+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:39.158+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:44:39.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.008 seconds
[2025-09-29T04:45:09.550+0000] {processor.py:157} INFO - Started process (PID=93736) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:45:09.551+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:45:09.553+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:09.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:45:09.993+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:45:11.141+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:11.140+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:45:11.187+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:11.187+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:45:11.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.676 seconds
[2025-09-29T04:45:41.503+0000] {processor.py:157} INFO - Started process (PID=94043) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:45:41.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:45:41.505+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:41.505+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:45:41.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:45:41.983+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:41.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:45:42.014+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:42.013+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:45:42.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.536 seconds
[2025-09-29T04:46:12.622+0000] {processor.py:157} INFO - Started process (PID=94350) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:46:12.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:46:12.625+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:12.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:46:13.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:46:13.095+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:13.094+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:46:13.121+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:13.121+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:46:13.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.525 seconds
[2025-09-29T04:46:43.357+0000] {processor.py:157} INFO - Started process (PID=94657) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:46:43.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:46:43.359+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:43.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:46:43.798+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:46:43.827+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:43.826+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:46:43.985+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:43.985+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:46:44.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.659 seconds
[2025-09-29T04:47:14.405+0000] {processor.py:157} INFO - Started process (PID=94964) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:47:14.406+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:47:14.407+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:14.407+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:47:14.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:47:14.867+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:14.867+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:47:14.896+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:14.896+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:47:14.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.518 seconds
[2025-09-29T04:47:44.975+0000] {processor.py:157} INFO - Started process (PID=95271) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:47:44.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:47:44.977+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:44.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:47:45.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:47:45.440+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:45.440+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:47:45.589+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:45.588+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:47:45.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.639 seconds
[2025-09-29T04:48:16.065+0000] {processor.py:157} INFO - Started process (PID=95583) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:48:16.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:48:16.067+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:16.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:48:16.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:48:16.670+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:16.669+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:48:16.693+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:16.693+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:48:16.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.651 seconds
[2025-09-29T04:48:46.879+0000] {processor.py:157} INFO - Started process (PID=95877) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:48:46.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:48:46.881+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:46.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:48:47.463+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:48:47.497+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:47.497+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:48:47.524+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:47.523+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:48:47.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.670 seconds
[2025-09-29T04:49:18.209+0000] {processor.py:157} INFO - Started process (PID=96184) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:49:18.210+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:49:18.211+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:18.211+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:49:18.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:49:18.947+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:18.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:49:18.973+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:18.973+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:49:18.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.790 seconds
[2025-09-29T04:49:49.658+0000] {processor.py:157} INFO - Started process (PID=96491) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:49:49.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:49:49.662+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:49.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:49:50.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:49:50.362+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:50.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:49:50.385+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:50.384+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:49:50.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.751 seconds
[2025-09-29T04:50:20.467+0000] {processor.py:157} INFO - Started process (PID=96798) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:50:20.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:50:20.469+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:20.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:50:21.023+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:50:21.048+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:21.047+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:50:21.071+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:21.071+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:50:21.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.629 seconds
[2025-09-29T04:50:51.857+0000] {processor.py:157} INFO - Started process (PID=97105) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:50:51.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:50:51.858+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:51.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:50:52.413+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:50:52.557+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:52.557+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:50:52.583+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:52.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:50:52.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.749 seconds
[2025-09-29T04:51:22.836+0000] {processor.py:157} INFO - Started process (PID=97412) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:51:22.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:51:22.839+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:22.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:51:23.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:51:23.547+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:23.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:51:23.572+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:23.572+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:51:23.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.761 seconds
[2025-09-29T04:51:54.144+0000] {processor.py:157} INFO - Started process (PID=97719) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:51:54.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:51:54.146+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:54.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:51:54.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:51:54.745+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:54.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:51:54.768+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:54.768+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:51:54.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.647 seconds
[2025-09-29T04:52:25.609+0000] {processor.py:157} INFO - Started process (PID=98038) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:52:25.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:52:25.611+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:25.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:52:26.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:52:26.706+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:52:57.560+0000] {processor.py:157} INFO - Started process (PID=98345) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:52:57.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:52:57.562+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:57.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:52:58.143+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:52:58.169+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:58.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:52:58.193+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:58.193+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:52:58.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.656 seconds
[2025-09-29T04:53:29.099+0000] {processor.py:157} INFO - Started process (PID=98652) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:53:29.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:53:29.101+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:29.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:53:29.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:53:29.726+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:29.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:53:29.759+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:29.759+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:53:29.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.690 seconds
[2025-09-29T04:53:59.844+0000] {processor.py:157} INFO - Started process (PID=98959) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:53:59.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:53:59.847+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:59.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:54:00.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:54:00.569+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:00.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:54:00.593+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:00.593+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:54:00.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.774 seconds
[2025-09-29T04:54:31.097+0000] {processor.py:157} INFO - Started process (PID=99266) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:54:31.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:54:31.100+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:31.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:54:31.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:54:31.750+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:31.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:54:31.778+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:31.777+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:54:31.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.707 seconds
[2025-09-29T04:55:02.399+0000] {processor.py:157} INFO - Started process (PID=99573) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:55:02.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:55:02.401+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:02.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:55:03.006+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:55:03.028+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:03.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:55:03.050+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:03.050+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:55:03.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.673 seconds
[2025-09-29T04:55:33.356+0000] {processor.py:157} INFO - Started process (PID=99880) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:55:33.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:55:33.358+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:33.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:55:33.935+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:55:33.963+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:33.963+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:55:33.986+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:33.986+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:55:34.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.654 seconds
[2025-09-29T04:56:04.640+0000] {processor.py:157} INFO - Started process (PID=488) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:56:04.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:56:04.642+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:04.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:56:05.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:56:05.585+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:05.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:56:05.608+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:05.608+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:56:05.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.993 seconds
[2025-09-29T04:56:35.962+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:56:35.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:56:35.965+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:35.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:56:36.532+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:56:36.562+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:36.562+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:56:36.590+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:36.589+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:56:36.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.658 seconds
[2025-09-29T04:57:07.226+0000] {processor.py:157} INFO - Started process (PID=1102) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:57:07.227+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:57:07.228+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:07.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:57:07.777+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:57:07.799+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:07.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:57:07.822+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:07.821+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:57:07.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.618 seconds
[2025-09-29T04:57:38.385+0000] {processor.py:157} INFO - Started process (PID=1409) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:57:38.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:57:38.388+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:38.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:57:38.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:57:39.065+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:39.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:57:39.088+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:39.088+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:57:39.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.728 seconds
[2025-09-29T04:58:09.662+0000] {processor.py:157} INFO - Started process (PID=1716) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:58:09.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:58:09.665+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:09.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:58:10.252+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:58:10.822+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:58:41.070+0000] {processor.py:157} INFO - Started process (PID=2023) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:58:41.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:58:41.072+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:41.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:58:41.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:58:41.643+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:41.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:58:41.672+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:41.672+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:58:41.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.628 seconds
[2025-09-29T04:59:11.845+0000] {processor.py:157} INFO - Started process (PID=2330) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:59:11.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:59:11.848+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:11.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:59:12.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:59:12.317+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:12.317+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:59:12.344+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:12.343+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:59:12.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.524 seconds
[2025-09-29T04:59:43.331+0000] {processor.py:157} INFO - Started process (PID=2642) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:59:43.334+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T04:59:43.335+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:43.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:59:43.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T04:59:43.810+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:43.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:59:43.836+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:43.836+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T04:59:43.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.530 seconds
[2025-09-29T05:00:14.429+0000] {processor.py:157} INFO - Started process (PID=2949) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:00:14.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:00:14.432+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:14.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:00:14.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:00:14.902+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:14.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:00:14.928+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:14.928+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:00:14.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.524 seconds
[2025-09-29T05:00:45.547+0000] {processor.py:157} INFO - Started process (PID=3256) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:00:45.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:00:45.550+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:45.550+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:00:45.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:00:46.002+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:46.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:00:46.031+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:46.030+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:00:46.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.507 seconds
[2025-09-29T05:01:16.365+0000] {processor.py:157} INFO - Started process (PID=3568) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:01:16.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:01:16.366+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:16.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:01:16.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:01:16.793+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:16.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:01:16.820+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:16.820+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:01:16.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.479 seconds
[2025-09-29T05:01:47.114+0000] {processor.py:157} INFO - Started process (PID=3870) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:01:47.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:01:47.116+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:47.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:01:47.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:01:47.559+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:47.559+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:01:47.587+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:47.586+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:01:47.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.497 seconds
[2025-09-29T05:02:17.985+0000] {processor.py:157} INFO - Started process (PID=4176) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:02:17.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:02:17.987+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:17.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:02:18.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:02:18.614+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:18.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:02:18.655+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:18.655+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:02:18.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.708 seconds
[2025-09-29T05:02:49.323+0000] {processor.py:157} INFO - Started process (PID=4483) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:02:49.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:02:49.325+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:49.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:02:49.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:02:49.777+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:49.777+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:02:49.803+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:49.803+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:02:49.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.509 seconds
[2025-09-29T05:03:20.623+0000] {processor.py:157} INFO - Started process (PID=4795) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:03:20.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:03:20.626+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:20.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:03:21.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:03:21.061+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:21.061+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:03:21.088+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:21.088+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:03:21.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.491 seconds
[2025-09-29T05:03:52.051+0000] {processor.py:157} INFO - Started process (PID=5103) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:03:52.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:03:52.052+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:52.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:03:52.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:03:52.501+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:52.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:03:52.527+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:52.527+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:03:52.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.611 seconds
[2025-09-29T05:04:23.140+0000] {processor.py:157} INFO - Started process (PID=5410) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:04:23.141+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:04:23.142+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:23.142+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:04:23.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:04:23.770+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:04:53.867+0000] {processor.py:157} INFO - Started process (PID=5732) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:04:53.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:04:53.869+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:53.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:04:54.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:04:54.301+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:54.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:04:54.441+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:54.440+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:04:54.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.601 seconds
[2025-09-29T05:05:25.063+0000] {processor.py:157} INFO - Started process (PID=6039) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:05:25.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:05:25.065+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:25.065+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:05:25.621+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:05:25.651+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:25.650+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:05:25.673+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:25.673+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:05:25.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.635 seconds
[2025-09-29T05:05:56.480+0000] {processor.py:157} INFO - Started process (PID=6351) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:05:56.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:05:56.483+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:56.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:05:57.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:05:57.169+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:57.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:05:57.194+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:57.194+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:05:57.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.745 seconds
[2025-09-29T05:06:27.403+0000] {processor.py:157} INFO - Started process (PID=6665) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:06:27.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:06:27.405+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:27.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:06:27.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:06:27.974+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:27.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:06:27.996+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:27.996+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:06:28.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.617 seconds
[2025-09-29T05:06:58.078+0000] {processor.py:157} INFO - Started process (PID=6972) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:06:58.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:06:58.080+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:58.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:06:58.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:06:59.456+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:07:30.397+0000] {processor.py:157} INFO - Started process (PID=7287) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:07:30.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:07:30.400+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:30.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:07:30.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:07:32.382+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:32.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:07:32.405+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:32.405+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:07:32.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.032 seconds
[2025-09-29T05:08:03.013+0000] {processor.py:157} INFO - Started process (PID=7609) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:08:03.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:08:03.015+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:03.015+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:08:03.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:08:04.329+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:08:34.551+0000] {processor.py:157} INFO - Started process (PID=7918) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:08:34.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:08:34.553+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:34.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:08:35.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:08:35.449+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:09:05.977+0000] {processor.py:157} INFO - Started process (PID=8233) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:09:05.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:09:05.979+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:05.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:09:06.552+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:09:07.284+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:09:37.911+0000] {processor.py:157} INFO - Started process (PID=8560) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:09:37.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:09:37.913+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:37.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:09:38.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:09:38.636+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:38.635+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:09:38.660+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:38.660+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:09:38.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.777 seconds
[2025-09-29T05:10:09.146+0000] {processor.py:157} INFO - Started process (PID=8864) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:10:09.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:10:09.148+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:09.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:10:09.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:10:09.789+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:09.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:10:09.812+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:09.812+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:10:09.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.688 seconds
[2025-09-29T05:10:40.001+0000] {processor.py:157} INFO - Started process (PID=9171) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:10:40.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:10:40.003+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:40.003+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:10:40.731+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:10:40.952+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:40.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:10:40.977+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:40.977+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:10:40.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.999 seconds
[2025-09-29T05:11:11.035+0000] {processor.py:157} INFO - Started process (PID=9479) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:11:11.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:11:11.036+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:11.036+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:11:11.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:11:11.584+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:11.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:11:11.609+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:11.609+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:11:11.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.618 seconds
[2025-09-29T05:11:41.737+0000] {processor.py:157} INFO - Started process (PID=9786) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:11:41.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:11:41.740+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:41.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:11:42.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:11:42.846+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:42.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:11:42.900+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:42.900+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:11:42.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.194 seconds
[2025-09-29T05:12:13.479+0000] {processor.py:157} INFO - Started process (PID=10093) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:12:13.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:12:13.481+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:13.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:12:14.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:12:14.507+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:14.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:12:14.549+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:14.549+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:12:14.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.148 seconds
[2025-09-29T05:12:44.701+0000] {processor.py:157} INFO - Started process (PID=10405) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:12:44.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:12:44.703+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:44.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:12:45.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:12:46.326+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:13:16.412+0000] {processor.py:157} INFO - Started process (PID=10712) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:13:16.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:13:16.414+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:16.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:13:17.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:13:17.039+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:17.039+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:13:17.064+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:17.064+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:13:17.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.677 seconds
[2025-09-29T05:13:47.665+0000] {processor.py:157} INFO - Started process (PID=11019) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:13:47.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:13:47.667+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:47.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:13:48.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:13:48.650+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:48.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:13:48.674+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:48.674+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:13:48.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.041 seconds
[2025-09-29T05:14:19.104+0000] {processor.py:157} INFO - Started process (PID=11342) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:14:19.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:14:19.106+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:19.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:14:19.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:14:19.659+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:19.659+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:14:19.682+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:19.682+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:14:19.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.600 seconds
[2025-09-29T05:14:49.978+0000] {processor.py:157} INFO - Started process (PID=11633) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:14:49.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:14:49.982+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:49.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:14:50.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:14:51.259+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:51.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:14:51.282+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:51.282+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:14:51.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.332 seconds
[2025-09-29T05:15:22.315+0000] {processor.py:157} INFO - Started process (PID=11951) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:15:22.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:15:22.318+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:22.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:15:22.789+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:15:22.954+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:15:53.657+0000] {processor.py:157} INFO - Started process (PID=12258) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:15:53.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:15:53.659+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:53.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:15:54.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:15:54.103+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:54.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:15:54.132+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:54.132+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:15:54.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.501 seconds
[2025-09-29T05:16:24.703+0000] {processor.py:157} INFO - Started process (PID=12555) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:16:24.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:16:24.705+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:24.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:16:25.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:16:25.163+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:25.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:16:25.190+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:25.190+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:16:25.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.513 seconds
[2025-09-29T05:16:55.447+0000] {processor.py:157} INFO - Started process (PID=12862) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:16:55.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:16:55.449+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:55.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:16:55.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:16:55.902+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:55.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:16:55.928+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:55.928+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:16:55.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.506 seconds
[2025-09-29T05:17:26.027+0000] {processor.py:157} INFO - Started process (PID=13169) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:17:26.028+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-09-29T05:17:26.029+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:17:26.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:17:26.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-09-29T05:17:26.715+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:17:26.714+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:17:26.744+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:17:26.744+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-09-29T10:00:00+00:00, run_after=2025-09-30T10:00:00+00:00
[2025-09-29T05:17:26.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.742 seconds
