[2025-09-29T00:13:46.020+0000] {processor.py:157} INFO - Started process (PID=45942) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:13:46.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:13:46.022+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:13:46.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:13:46.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:13:46.838+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:13:46.838+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:13:46.867+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:13:46.866+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:13:46.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.878 seconds
[2025-09-29T00:14:17.661+0000] {processor.py:157} INFO - Started process (PID=46248) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:14:17.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:14:17.666+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:14:17.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:14:20.466+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:14:20.554+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:14:20.552+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:14:20.632+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:14:20.632+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:14:20.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 3.034 seconds
[2025-09-29T00:16:58.122+0000] {processor.py:157} INFO - Started process (PID=46341) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:16:58.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:16:58.141+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:16:58.128+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:17:00.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:17:00.473+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:00.471+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:17:00.637+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:00.636+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:17:00.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.850 seconds
[2025-09-29T00:17:31.422+0000] {processor.py:157} INFO - Started process (PID=46648) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:17:31.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:17:31.427+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:31.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:17:32.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:17:32.113+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:32.113+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:17:32.137+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:17:32.137+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:17:34.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.851 seconds
[2025-09-29T00:18:04.787+0000] {processor.py:157} INFO - Started process (PID=46955) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:18:04.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:18:04.789+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:04.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:18:05.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:18:05.357+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:05.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:18:05.385+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:05.385+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:18:05.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.625 seconds
[2025-09-29T00:18:35.792+0000] {processor.py:157} INFO - Started process (PID=47262) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:18:35.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:18:35.796+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:35.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:18:36.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:18:36.451+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:36.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:18:36.476+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:18:36.476+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:18:36.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.711 seconds
[2025-09-29T00:19:06.947+0000] {processor.py:157} INFO - Started process (PID=47569) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:19:06.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:19:06.950+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:06.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:19:07.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:19:07.437+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:07.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:19:07.465+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:07.465+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:19:07.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.547 seconds
[2025-09-29T00:19:37.658+0000] {processor.py:157} INFO - Started process (PID=47876) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:19:37.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:19:37.661+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:37.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:19:38.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:19:38.126+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:38.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:19:38.154+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:19:38.154+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:19:38.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.523 seconds
[2025-09-29T00:20:08.235+0000] {processor.py:157} INFO - Started process (PID=48183) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:20:08.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:20:08.237+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:08.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:20:08.726+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:20:08.754+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:08.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:20:08.780+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:08.780+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:20:08.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.573 seconds
[2025-09-29T00:20:39.060+0000] {processor.py:157} INFO - Started process (PID=48490) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:20:39.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:20:39.062+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:39.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:20:39.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:20:39.550+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:39.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:20:39.590+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:20:39.590+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:20:39.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.558 seconds
[2025-09-29T00:21:09.934+0000] {processor.py:157} INFO - Started process (PID=48797) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:21:09.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:21:09.936+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:09.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:21:10.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:21:10.425+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:10.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:21:10.453+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:10.453+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:21:10.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.546 seconds
[2025-09-29T00:21:40.847+0000] {processor.py:157} INFO - Started process (PID=49104) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:21:40.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:21:40.849+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:40.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:21:41.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:21:41.319+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:41.319+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:21:41.345+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:21:41.345+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:21:41.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.529 seconds
[2025-09-29T00:22:11.721+0000] {processor.py:157} INFO - Started process (PID=49411) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:22:11.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:22:11.722+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:11.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:22:12.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:22:12.188+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:12.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:22:12.219+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:12.219+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:22:12.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.527 seconds
[2025-09-29T00:22:42.589+0000] {processor.py:157} INFO - Started process (PID=49718) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:22:42.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:22:42.591+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:42.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:22:43.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:22:43.056+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:43.055+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:22:43.082+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:22:43.082+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:22:43.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.518 seconds
[2025-09-29T00:23:13.306+0000] {processor.py:157} INFO - Started process (PID=50025) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:23:13.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:23:13.308+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:13.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:23:13.751+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:23:13.776+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:13.776+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:23:13.803+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:13.803+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:23:13.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.524 seconds
[2025-09-29T00:23:43.909+0000] {processor.py:157} INFO - Started process (PID=50332) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:23:43.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:23:43.910+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:43.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:23:44.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:23:44.376+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:44.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:23:44.403+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:23:44.402+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:23:44.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.522 seconds
[2025-09-29T00:24:14.564+0000] {processor.py:157} INFO - Started process (PID=50636) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:24:14.565+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:24:14.566+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:14.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:24:15.038+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:24:15.083+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:15.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:24:15.115+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:15.114+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:24:15.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.687 seconds
[2025-09-29T00:24:45.488+0000] {processor.py:157} INFO - Started process (PID=50943) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:24:45.489+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:24:45.490+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:45.490+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:24:45.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:24:46.057+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:46.057+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:24:46.085+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:24:46.085+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:24:46.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.620 seconds
[2025-09-29T00:25:16.994+0000] {processor.py:157} INFO - Started process (PID=51258) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:25:16.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:25:16.998+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:16.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:25:17.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:25:17.663+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:17.663+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:25:17.697+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:17.696+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:25:17.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.731 seconds
[2025-09-29T00:25:48.602+0000] {processor.py:157} INFO - Started process (PID=51565) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:25:48.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:25:48.604+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:48.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:25:49.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:25:49.228+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:49.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:25:49.254+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:25:49.254+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:25:49.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.679 seconds
[2025-09-29T00:26:19.994+0000] {processor.py:157} INFO - Started process (PID=51872) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:26:19.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:26:19.996+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:19.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:26:20.566+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:26:20.591+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:20.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:26:20.614+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:20.614+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:26:20.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.645 seconds
[2025-09-29T00:26:51.538+0000] {processor.py:157} INFO - Started process (PID=52179) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:26:51.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:26:51.540+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:51.540+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:26:52.134+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:26:52.161+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:52.161+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:26:52.187+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:26:52.187+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:26:52.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.675 seconds
[2025-09-29T00:27:22.835+0000] {processor.py:157} INFO - Started process (PID=52486) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:27:22.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:27:22.837+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:27:22.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:27:23.392+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:27:23.416+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:27:23.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:27:23.441+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:27:23.441+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:27:23.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.634 seconds
[2025-09-29T00:42:32.897+0000] {processor.py:157} INFO - Started process (PID=52768) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:42:32.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:42:33.036+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:42:32.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:42:34.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:42:34.162+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:42:34.161+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:42:34.197+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:42:34.196+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:42:34.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.341 seconds
[2025-09-29T00:43:04.511+0000] {processor.py:157} INFO - Started process (PID=53081) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:43:04.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:43:04.514+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:43:04.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:43:05.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:43:05.103+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:43:05.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:43:05.131+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:43:05.131+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:43:05.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.645 seconds
[2025-09-29T00:58:18.921+0000] {processor.py:157} INFO - Started process (PID=53382) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:58:18.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:58:18.950+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:18.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:58:19.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:58:19.984+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:19.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:58:20.020+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:20.020+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:58:20.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.141 seconds
[2025-09-29T00:58:50.908+0000] {processor.py:157} INFO - Started process (PID=53696) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:58:50.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:58:50.941+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:58:50.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:59:04.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:59:05.048+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:05.036+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:59:06.054+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:06.052+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:59:06.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 15.734 seconds
[2025-09-29T00:59:37.191+0000] {processor.py:157} INFO - Started process (PID=54013) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:59:37.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T00:59:37.193+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:37.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:59:37.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T00:59:37.918+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:37.918+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T00:59:37.949+0000] {logging_mixin.py:149} INFO - [2025-09-29T00:59:37.949+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T00:59:37.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.789 seconds
[2025-09-29T01:00:08.107+0000] {processor.py:157} INFO - Started process (PID=54318) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:00:08.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:00:08.114+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:00:08.113+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:10:45.441+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:10:45.439+0000] {timeout.py:68} ERROR - Process timed out, PID: 54318
[2025-09-29T01:10:45.442+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function _collection_gced at 0x7f029c58f320>
[2025-09-29T01:10:45.444+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2025-09-29T01:10:45.446+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/event/registry.py", line 53, in _collection_gced
[2025-09-29T01:10:45.447+0000] {logging_mixin.py:149} WARNING -     def _collection_gced(ref):
[2025-09-29T01:10:45.449+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2025-09-29T01:10:45.451+0000] {logging_mixin.py:149} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2025-09-29T01:10:45.451+0000] {logging_mixin.py:149} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistics_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 54318
[2025-09-29T01:11:15.628+0000] {processor.py:157} INFO - Started process (PID=54626) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:11:15.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:11:15.631+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:15.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:11:16.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:11:16.306+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:16.306+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:11:16.334+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:16.334+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:11:16.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.730 seconds
[2025-09-29T01:11:46.718+0000] {processor.py:157} INFO - Started process (PID=54940) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:11:46.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:11:46.720+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:46.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:11:47.259+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:11:47.280+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:47.280+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:11:47.304+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:11:47.304+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:11:47.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.610 seconds
[2025-09-29T01:12:17.624+0000] {processor.py:157} INFO - Started process (PID=55247) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:12:17.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:12:17.626+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:17.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:12:18.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:12:18.314+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:18.314+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:12:18.338+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:18.337+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:12:18.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.738 seconds
[2025-09-29T01:12:48.781+0000] {processor.py:157} INFO - Started process (PID=55554) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:12:48.782+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:12:48.783+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:48.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:12:49.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:12:49.379+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:49.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:12:49.408+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:12:49.408+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:12:49.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.655 seconds
[2025-09-29T01:13:19.542+0000] {processor.py:157} INFO - Started process (PID=55861) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:13:19.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:13:19.544+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:19.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:13:20.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:13:20.188+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:20.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:13:20.211+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:20.211+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:13:20.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.694 seconds
[2025-09-29T01:13:50.440+0000] {processor.py:157} INFO - Started process (PID=56168) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:13:50.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:13:50.443+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:50.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:13:51.025+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:13:51.046+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:51.046+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:13:51.068+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:13:51.068+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:13:51.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.651 seconds
[2025-09-29T01:14:21.246+0000] {processor.py:157} INFO - Started process (PID=56475) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:14:21.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:14:21.248+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:21.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:14:21.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:14:21.682+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:21.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:14:21.709+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:21.709+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:14:21.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.491 seconds
[2025-09-29T01:14:51.876+0000] {processor.py:157} INFO - Started process (PID=56782) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:14:51.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:14:51.879+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:51.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:14:52.299+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:14:52.325+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:52.325+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:14:52.352+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:14:52.352+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:14:52.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.501 seconds
[2025-09-29T01:15:22.943+0000] {processor.py:157} INFO - Started process (PID=57089) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:15:22.945+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:15:22.946+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:22.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:15:23.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:15:23.387+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:23.386+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:15:23.414+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:23.413+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:15:23.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.499 seconds
[2025-09-29T01:15:53.829+0000] {processor.py:157} INFO - Started process (PID=57396) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:15:53.830+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:15:53.832+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:53.831+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:15:54.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:15:54.315+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:54.315+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:15:54.344+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:15:54.344+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:15:54.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.543 seconds
[2025-09-29T01:16:24.761+0000] {processor.py:157} INFO - Started process (PID=57703) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:16:24.763+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:16:24.764+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:24.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:16:25.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:16:25.361+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:25.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:16:25.416+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:25.416+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:16:25.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.725 seconds
[2025-09-29T01:16:55.742+0000] {processor.py:157} INFO - Started process (PID=58010) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:16:55.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:16:55.744+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:55.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:16:56.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:16:56.202+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:56.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:16:56.229+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:16:56.229+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:16:56.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.514 seconds
[2025-09-29T01:17:26.616+0000] {processor.py:157} INFO - Started process (PID=58317) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:17:26.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:17:26.618+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:26.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:17:27.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:17:27.094+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:27.094+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:17:27.120+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:27.120+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:17:27.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.531 seconds
[2025-09-29T01:17:57.394+0000] {processor.py:157} INFO - Started process (PID=58624) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:17:57.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:17:57.397+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:57.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:17:57.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:17:57.867+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:57.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:17:57.897+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:17:57.897+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:17:57.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.531 seconds
[2025-09-29T01:18:28.093+0000] {processor.py:157} INFO - Started process (PID=58930) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:18:28.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:18:28.095+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:28.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:18:28.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:18:28.613+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:28.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:18:28.641+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:28.641+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:18:28.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.578 seconds
[2025-09-29T01:18:58.854+0000] {processor.py:157} INFO - Started process (PID=59237) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:18:58.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:18:58.856+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:58.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:18:59.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:18:59.315+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:59.314+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:18:59.344+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:18:59.344+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:18:59.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.514 seconds
[2025-09-29T01:19:29.538+0000] {processor.py:157} INFO - Started process (PID=59544) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:19:29.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:19:29.540+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:29.540+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:19:30.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:19:30.054+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:30.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:19:30.087+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:19:30.087+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:19:31.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.240 seconds
[2025-09-29T01:20:02.218+0000] {processor.py:157} INFO - Started process (PID=59851) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:20:02.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:20:02.220+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:02.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:20:02.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:20:02.669+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:02.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:20:02.698+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:02.698+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:20:02.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.505 seconds
[2025-09-29T01:20:32.958+0000] {processor.py:157} INFO - Started process (PID=60158) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:20:32.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:20:32.960+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:32.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:20:33.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:20:33.441+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:33.440+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:20:33.574+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:20:33.574+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:20:33.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.641 seconds
[2025-09-29T01:21:03.990+0000] {processor.py:157} INFO - Started process (PID=60465) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:21:03.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:21:03.992+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:21:03.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:21:04.553+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:21:04.573+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:21:04.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:21:04.596+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:21:04.596+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:21:04.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.630 seconds
[2025-09-29T01:36:18.321+0000] {processor.py:157} INFO - Started process (PID=60781) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:36:18.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:36:18.329+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:18.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:36:19.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:36:19.290+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:19.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:36:19.338+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:36:19.338+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:36:19.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.136 seconds
[2025-09-29T01:37:03.379+0000] {processor.py:157} INFO - Started process (PID=61096) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:37:03.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:37:03.407+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:37:03.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:37:15.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:37:15.493+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:37:15.489+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:37:15.645+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:37:15.644+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:37:15.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 12.461 seconds
[2025-09-29T01:52:05.237+0000] {processor.py:157} INFO - Started process (PID=61157) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:52:05.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:52:05.244+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:05.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:52:06.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:52:06.302+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:06.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:52:06.347+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:06.347+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:52:06.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.163 seconds
[2025-09-29T01:52:37.281+0000] {processor.py:157} INFO - Started process (PID=61464) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:52:37.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:52:37.312+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:37.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:52:50.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:52:51.173+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:51.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:52:51.814+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:52:51.811+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:52:52.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 14.980 seconds
[2025-09-29T01:53:22.627+0000] {processor.py:157} INFO - Started process (PID=61768) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:53:22.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:53:22.629+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:22.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:53:23.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:53:23.571+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:23.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:53:23.603+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:23.602+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:53:23.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.007 seconds
[2025-09-29T01:53:54.237+0000] {processor.py:157} INFO - Started process (PID=62078) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:53:54.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:53:54.243+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:54.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:53:55.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:53:55.150+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:55.149+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:53:55.193+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:53:55.193+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:53:55.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.002 seconds
[2025-09-29T01:54:25.757+0000] {processor.py:157} INFO - Started process (PID=62385) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:54:25.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:54:25.765+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:25.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:54:27.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:54:27.433+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:27.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:54:27.526+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:27.525+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:54:27.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.858 seconds
[2025-09-29T01:54:57.806+0000] {processor.py:157} INFO - Started process (PID=62692) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:54:57.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:54:57.811+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:57.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:54:58.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:54:58.669+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:58.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:54:58.711+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:54:58.711+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:54:58.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.945 seconds
[2025-09-29T01:55:29.341+0000] {processor.py:157} INFO - Started process (PID=62999) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:55:29.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:55:29.348+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:55:29.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:55:30.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:55:30.427+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:55:30.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:55:30.507+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:55:30.507+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:55:30.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.254 seconds
[2025-09-29T01:56:00.706+0000] {processor.py:157} INFO - Started process (PID=63306) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:56:00.708+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:56:00.709+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:00.709+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:56:01.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:56:01.538+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:01.537+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:56:01.577+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:01.576+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:56:01.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.907 seconds
[2025-09-29T01:56:31.794+0000] {processor.py:157} INFO - Started process (PID=63613) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:56:31.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:56:31.798+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:31.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:56:32.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:56:32.442+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:32.442+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:56:32.482+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:56:32.482+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:56:32.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.727 seconds
[2025-09-29T01:57:02.611+0000] {processor.py:157} INFO - Started process (PID=63920) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:57:02.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T01:57:02.614+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:57:02.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:57:03.223+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T01:57:03.255+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:57:03.254+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T01:57:03.292+0000] {logging_mixin.py:149} INFO - [2025-09-29T01:57:03.292+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T01:57:03.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.717 seconds
[2025-09-29T02:12:06.737+0000] {processor.py:157} INFO - Started process (PID=63960) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:12:06.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:12:06.749+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:06.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:12:07.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:12:07.743+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:07.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:12:07.772+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:07.772+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:12:07.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.070 seconds
[2025-09-29T02:12:38.848+0000] {processor.py:157} INFO - Started process (PID=64267) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:12:38.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:12:38.884+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:38.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:12:50.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:12:50.803+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:50.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:12:51.540+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:12:51.537+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:12:52.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 13.235 seconds
[2025-09-29T02:27:58.998+0000] {processor.py:157} INFO - Started process (PID=64572) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:27:58.999+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:27:59.000+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:27:59.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:27:59.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:27:59.558+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:27:59.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:27:59.593+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:27:59.592+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:27:59.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.625 seconds
[2025-09-29T02:28:37.098+0000] {processor.py:157} INFO - Started process (PID=64694) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:28:37.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:28:37.152+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:28:37.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:28:48.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:28:49.003+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:28:48.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:28:49.751+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:28:49.748+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:28:50.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 13.321 seconds
[2025-09-29T02:29:21.236+0000] {processor.py:157} INFO - Started process (PID=65002) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:29:21.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:29:21.242+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:21.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:29:22.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:29:22.096+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:22.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:29:22.154+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:22.153+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:29:22.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.970 seconds
[2025-09-29T02:29:52.504+0000] {processor.py:157} INFO - Started process (PID=65309) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:29:52.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:29:52.512+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:52.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:29:54.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:29:54.716+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:54.715+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:29:54.832+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:29:54.832+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:29:54.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.439 seconds
[2025-09-29T02:30:25.059+0000] {processor.py:157} INFO - Started process (PID=65618) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:30:25.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:30:25.063+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:25.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:30:26.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:30:26.160+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:26.159+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:30:26.225+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:26.224+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:30:26.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.226 seconds
[2025-09-29T02:30:56.845+0000] {processor.py:157} INFO - Started process (PID=65932) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:30:56.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:30:56.851+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:56.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:30:58.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:30:58.079+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:58.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:30:58.157+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:30:58.157+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:30:58.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.385 seconds
[2025-09-29T02:31:28.544+0000] {processor.py:157} INFO - Started process (PID=66237) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:31:28.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:31:28.550+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:28.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:31:29.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:31:29.585+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:29.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:31:29.657+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:31:29.657+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:31:29.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.178 seconds
[2025-09-29T02:32:00.272+0000] {processor.py:157} INFO - Started process (PID=66544) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:32:00.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:32:00.278+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:00.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:32:01.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:32:01.193+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:01.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:32:01.248+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:01.247+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:32:01.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.028 seconds
[2025-09-29T02:32:31.806+0000] {processor.py:157} INFO - Started process (PID=66853) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:32:31.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:32:31.811+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:31.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:32:32.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:32:32.535+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:32.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:32:32.745+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:32:32.744+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:32:32.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.981 seconds
[2025-09-29T02:33:02.962+0000] {processor.py:157} INFO - Started process (PID=67160) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:33:02.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:33:02.965+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:02.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:33:03.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:33:03.661+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:03.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:33:03.703+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:03.703+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:33:03.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.928 seconds
[2025-09-29T02:33:34.573+0000] {processor.py:157} INFO - Started process (PID=67466) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:33:34.574+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:33:34.576+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:34.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:33:35.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:33:35.316+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:35.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:33:35.348+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:33:35.348+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:33:35.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.812 seconds
[2025-09-29T02:34:06.027+0000] {processor.py:157} INFO - Started process (PID=67773) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:34:06.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:34:06.030+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:06.030+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:34:06.691+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:34:06.719+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:06.719+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:34:06.749+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:06.749+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:34:06.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.756 seconds
[2025-09-29T02:34:36.941+0000] {processor.py:157} INFO - Started process (PID=68078) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:34:36.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:34:36.946+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:36.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:34:37.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:34:37.634+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:37.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:34:37.666+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:34:37.666+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:34:37.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.755 seconds
[2025-09-29T02:35:07.805+0000] {processor.py:157} INFO - Started process (PID=68377) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:35:07.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T02:35:07.808+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:35:07.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:35:08.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T02:35:08.571+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:35:08.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T02:35:08.603+0000] {logging_mixin.py:149} INFO - [2025-09-29T02:35:08.603+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T02:35:08.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.831 seconds
[2025-09-29T03:05:27.599+0000] {processor.py:157} INFO - Started process (PID=68691) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:05:27.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:05:27.605+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:27.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:05:28.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:05:28.452+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:28.451+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:05:28.523+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:28.523+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:05:28.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.981 seconds
[2025-09-29T03:05:59.487+0000] {processor.py:157} INFO - Started process (PID=68998) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:05:59.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:05:59.516+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:05:59.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:06:12.300+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:06:13.020+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:13.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:06:14.078+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:14.076+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:06:14.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 15.248 seconds
[2025-09-29T03:06:45.866+0000] {processor.py:157} INFO - Started process (PID=69313) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:06:45.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:06:45.871+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:45.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:06:47.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:06:47.262+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:47.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:06:47.323+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:06:47.323+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:06:47.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.513 seconds
[2025-09-29T03:07:17.637+0000] {processor.py:157} INFO - Started process (PID=69620) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:07:17.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:07:17.644+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:17.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:07:19.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:07:19.364+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:19.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:07:19.438+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:19.438+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:07:19.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.879 seconds
[2025-09-29T03:07:49.897+0000] {processor.py:157} INFO - Started process (PID=69927) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:07:49.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:07:49.903+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:49.902+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:07:51.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:07:51.306+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:51.305+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:07:51.375+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:07:51.374+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:07:51.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.555 seconds
[2025-09-29T03:08:21.923+0000] {processor.py:157} INFO - Started process (PID=70234) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:08:21.926+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:08:21.929+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:21.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:08:23.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:08:23.509+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:23.508+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:08:23.583+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:23.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:08:23.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.730 seconds
[2025-09-29T03:08:53.891+0000] {processor.py:157} INFO - Started process (PID=70541) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:08:53.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:08:53.899+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:53.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:08:55.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:08:55.545+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:55.544+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:08:55.617+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:08:55.617+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:08:55.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.800 seconds
[2025-09-29T03:09:25.934+0000] {processor.py:157} INFO - Started process (PID=70848) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:09:25.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:09:25.940+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:25.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:09:27.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:09:28.000+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:27.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:09:28.077+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:28.076+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:09:28.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.215 seconds
[2025-09-29T03:09:58.847+0000] {processor.py:157} INFO - Started process (PID=71157) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:09:58.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:09:58.851+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:58.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:09:59.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:09:59.878+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:59.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:09:59.929+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:09:59.929+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:09:59.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.131 seconds
[2025-09-29T03:10:30.409+0000] {processor.py:157} INFO - Started process (PID=71464) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:10:30.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:10:30.413+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:30.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:10:31.466+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:10:31.517+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:31.516+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:10:31.579+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:10:31.579+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:10:31.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.230 seconds
[2025-09-29T03:11:01.892+0000] {processor.py:157} INFO - Started process (PID=71778) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:11:01.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:11:01.895+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:01.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:11:02.694+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:11:02.731+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:02.731+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:11:02.777+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:02.777+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:11:02.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.932 seconds
[2025-09-29T03:11:33.121+0000] {processor.py:157} INFO - Started process (PID=72085) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:11:33.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:11:33.124+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:33.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:11:33.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:11:33.956+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:33.955+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:11:34.034+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:11:34.034+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:11:34.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.978 seconds
[2025-09-29T03:12:04.536+0000] {processor.py:157} INFO - Started process (PID=72392) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:12:04.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:12:04.539+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:04.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:12:05.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:12:05.278+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:05.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:12:05.312+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:05.311+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:12:05.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.809 seconds
[2025-09-29T03:12:35.503+0000] {processor.py:157} INFO - Started process (PID=72699) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:12:35.505+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:12:35.507+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:35.506+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:12:36.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:12:36.362+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:36.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:12:36.401+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:12:36.401+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:12:36.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.939 seconds
[2025-09-29T03:13:06.968+0000] {processor.py:157} INFO - Started process (PID=73006) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:13:06.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:13:06.972+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:06.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:13:07.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:13:07.795+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:07.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:13:07.834+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:07.834+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:13:07.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.904 seconds
[2025-09-29T03:13:37.992+0000] {processor.py:157} INFO - Started process (PID=73313) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:13:37.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:13:37.995+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:37.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:13:38.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:13:38.812+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:38.811+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:13:38.852+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:13:38.851+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:13:38.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.898 seconds
[2025-09-29T03:14:09.012+0000] {processor.py:157} INFO - Started process (PID=73620) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:14:09.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:14:09.015+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:14:09.015+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:14:09.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:14:09.721+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:14:09.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:14:09.767+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:14:09.767+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:14:09.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.798 seconds
[2025-09-29T03:16:51.438+0000] {processor.py:157} INFO - Started process (PID=73796) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:16:51.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:16:51.440+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:16:51.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:16:52.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:16:52.119+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:16:52.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:16:52.155+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:16:52.155+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:16:52.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.756 seconds
[2025-09-29T03:17:29.926+0000] {processor.py:157} INFO - Started process (PID=74110) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:17:29.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:17:29.961+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:29.957+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:17:39.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:17:40.010+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:40.004+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:17:40.690+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:40.688+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:17:41.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 11.609 seconds
[2025-09-29T03:17:52.015+0000] {processor.py:157} INFO - Started process (PID=74166) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:17:52.022+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:17:52.030+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:17:52.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:44:24.956+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:44:24.955+0000] {timeout.py:68} ERROR - Process timed out, PID: 74166
[2025-09-29T03:44:25.149+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:44:24.960+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistics_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistics_dag.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 50, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/api.py", line 48, in <module>
    from pandas.core.groupby import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py", line 73, in <module>
    from pandas.core.frame import DataFrame
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/frame.py", line 129, in <module>
    from pandas.core import (
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 122, in <module>
    from pandas.core.describe import describe_ndframe
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/describe.py", line 39, in <module>
    from pandas.io.formats.format import format_percentiles
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/formats/format.py", line 99, in <module>
    from pandas.io.common import stringify_path
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 77, in <module>
    @dataclasses.dataclass
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistics_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 74166
[2025-09-29T03:44:25.159+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:44:25.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1593.598 seconds
[2025-09-29T03:44:56.467+0000] {processor.py:157} INFO - Started process (PID=74484) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:44:56.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:44:56.516+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:44:56.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:45:12.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:45:12.916+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:12.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:45:13.629+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:13.628+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:45:14.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 17.627 seconds
[2025-09-29T03:45:50.468+0000] {processor.py:157} INFO - Started process (PID=74800) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:45:50.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:45:50.475+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:50.474+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:45:52.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:45:52.439+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:52.438+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:45:52.533+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:45:52.532+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:45:52.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.148 seconds
[2025-09-29T03:46:22.962+0000] {processor.py:157} INFO - Started process (PID=75086) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:46:22.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:46:22.977+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:22.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:46:24.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:46:24.849+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:24.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:46:25.094+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:25.093+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:46:25.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.301 seconds
[2025-09-29T03:46:55.793+0000] {processor.py:157} INFO - Started process (PID=75393) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:46:55.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:46:55.802+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:55.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:46:56.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:46:57.055+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:57.054+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:46:57.138+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:46:57.137+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:46:57.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.430 seconds
[2025-09-29T03:47:29.290+0000] {processor.py:157} INFO - Started process (PID=75707) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:47:29.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:47:29.300+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:47:29.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:47:30.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:47:30.482+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:47:30.480+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:47:30.573+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:47:30.573+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:47:30.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.371 seconds
[2025-09-29T03:48:00.835+0000] {processor.py:157} INFO - Started process (PID=76014) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:48:00.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:48:00.847+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:00.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:48:02.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:48:02.480+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:02.480+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:48:02.559+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:02.559+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:48:02.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.800 seconds
[2025-09-29T03:48:32.805+0000] {processor.py:157} INFO - Started process (PID=76321) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:48:32.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:48:32.812+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:32.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:48:33.855+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:48:33.920+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:33.919+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:48:33.992+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:48:33.992+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:48:34.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.255 seconds
[2025-09-29T03:49:04.884+0000] {processor.py:157} INFO - Started process (PID=76628) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:49:04.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:49:04.890+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:04.889+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:49:05.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:49:05.926+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:05.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:49:05.992+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:05.992+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:49:06.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.167 seconds
[2025-09-29T03:49:36.504+0000] {processor.py:157} INFO - Started process (PID=76935) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:49:36.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:49:36.511+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:36.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:49:37.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:49:37.405+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:37.404+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:49:37.464+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:49:37.464+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:49:37.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.014 seconds
[2025-09-29T03:50:07.805+0000] {processor.py:157} INFO - Started process (PID=77242) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:50:07.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:50:07.809+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:07.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:50:08.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:50:08.579+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:08.578+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:50:08.627+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:08.626+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:50:08.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.865 seconds
[2025-09-29T03:50:38.961+0000] {processor.py:157} INFO - Started process (PID=77549) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:50:38.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:50:38.964+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:38.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:50:39.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:50:39.656+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:39.655+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:50:39.698+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:50:39.698+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:50:39.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.781 seconds
[2025-09-29T03:51:10.151+0000] {processor.py:157} INFO - Started process (PID=77857) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:51:10.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:51:10.154+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:10.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:51:10.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:51:10.905+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:10.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:51:10.953+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:10.953+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:51:10.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.845 seconds
[2025-09-29T03:51:41.833+0000] {processor.py:157} INFO - Started process (PID=78164) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:51:41.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:51:41.839+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:41.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:51:42.630+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:51:42.685+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:42.684+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:51:42.777+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:51:42.777+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:51:43.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.236 seconds
[2025-09-29T03:52:13.245+0000] {processor.py:157} INFO - Started process (PID=78471) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:52:13.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:52:13.249+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:13.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:52:13.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:52:13.944+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:13.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:52:13.986+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:13.986+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:52:14.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.781 seconds
[2025-09-29T03:52:44.645+0000] {processor.py:157} INFO - Started process (PID=78778) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:52:44.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:52:44.647+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:44.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:52:45.260+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:52:45.301+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:45.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:52:45.515+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:52:45.515+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:52:45.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.906 seconds
[2025-09-29T03:53:15.885+0000] {processor.py:157} INFO - Started process (PID=79085) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:53:15.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T03:53:15.887+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:53:15.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:53:16.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T03:53:16.660+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:53:16.659+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T03:53:16.694+0000] {logging_mixin.py:149} INFO - [2025-09-29T03:53:16.693+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T03:53:16.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.844 seconds
[2025-09-29T04:17:53.285+0000] {processor.py:157} INFO - Started process (PID=79135) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:17:53.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:17:53.288+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:17:53.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:17:54.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:17:54.182+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:17:54.181+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:17:54.222+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:17:54.222+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:17:54.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.974 seconds
[2025-09-29T04:18:25.210+0000] {processor.py:157} INFO - Started process (PID=79442) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:18:25.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:18:25.250+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:18:25.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:18:38.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:18:38.989+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:18:38.979+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:18:39.915+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:18:39.912+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:18:40.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 15.413 seconds
[2025-09-29T04:19:16.430+0000] {processor.py:157} INFO - Started process (PID=79516) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:19:16.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:19:16.447+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:16.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:19:17.466+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:19:17.535+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:17.534+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:19:17.600+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:17.600+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:19:17.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.223 seconds
[2025-09-29T04:19:48.327+0000] {processor.py:157} INFO - Started process (PID=79823) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:19:48.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:19:48.333+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:48.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:19:48.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:19:48.931+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:48.931+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:19:48.961+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:19:48.960+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:19:48.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.664 seconds
[2025-09-29T04:20:19.381+0000] {processor.py:157} INFO - Started process (PID=80130) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:20:19.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:20:19.385+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:19.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:20:19.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:20:19.855+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:19.855+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:20:19.885+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:19.885+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:20:19.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.533 seconds
[2025-09-29T04:20:50.282+0000] {processor.py:157} INFO - Started process (PID=80437) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:20:50.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:20:50.285+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:50.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:20:50.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:20:50.782+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:50.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:20:50.814+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:20:50.814+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:20:50.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.562 seconds
[2025-09-29T04:23:19.864+0000] {processor.py:157} INFO - Started process (PID=80708) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:23:19.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:23:19.871+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:19.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:23:20.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:23:20.723+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:20.722+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:23:20.763+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:20.763+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:23:20.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.939 seconds
[2025-09-29T04:23:51.022+0000] {processor.py:157} INFO - Started process (PID=81015) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:23:51.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:23:51.026+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:51.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:23:51.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:23:51.564+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:51.563+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:23:51.595+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:23:51.595+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:23:51.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.608 seconds
[2025-09-29T04:24:22.180+0000] {processor.py:157} INFO - Started process (PID=81322) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:24:22.183+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:24:22.188+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:22.187+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:24:22.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:24:22.700+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:22.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:24:22.733+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:22.733+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:24:22.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.584 seconds
[2025-09-29T04:24:53.098+0000] {processor.py:157} INFO - Started process (PID=81629) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:24:53.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:24:53.102+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:53.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:24:53.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:24:53.612+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:53.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:24:53.644+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:24:53.644+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:24:53.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.577 seconds
[2025-09-29T04:25:24.059+0000] {processor.py:157} INFO - Started process (PID=81966) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:25:24.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:25:24.064+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:24.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:25:24.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:25:24.553+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:24.553+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:25:24.586+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:24.585+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:25:24.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.554 seconds
[2025-09-29T04:25:54.696+0000] {processor.py:157} INFO - Started process (PID=82274) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:25:54.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:25:54.699+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:54.699+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:25:55.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:25:55.253+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:55.251+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:25:55.286+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:25:55.285+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:25:55.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.617 seconds
[2025-09-29T04:26:25.551+0000] {processor.py:157} INFO - Started process (PID=82581) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:26:25.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:26:25.554+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:25.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:26:26.021+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:26:26.050+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:26.049+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:26:26.076+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:26.076+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:26:26.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.557 seconds
[2025-09-29T04:26:56.383+0000] {processor.py:157} INFO - Started process (PID=82888) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:26:56.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:26:56.387+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:56.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:26:56.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:26:56.881+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:56.881+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:26:56.908+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:26:56.908+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:26:56.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.551 seconds
[2025-09-29T04:27:27.321+0000] {processor.py:157} INFO - Started process (PID=83195) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:27:27.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:27:27.326+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:27.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:27:27.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:27:27.823+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:27.822+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:27:27.850+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:27.850+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:27:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.555 seconds
[2025-09-29T04:27:57.983+0000] {processor.py:157} INFO - Started process (PID=83502) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:27:57.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:27:57.987+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:57.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:27:58.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:27:58.434+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:58.433+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:27:58.465+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:27:58.464+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:27:58.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.508 seconds
[2025-09-29T04:28:29.093+0000] {processor.py:157} INFO - Started process (PID=83809) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:28:29.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:28:29.095+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:28:29.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:28:29.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:28:29.688+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:28:29.688+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:28:29.721+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:28:29.721+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:28:29.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.659 seconds
[2025-09-29T04:29:00.348+0000] {processor.py:157} INFO - Started process (PID=84116) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:29:00.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:29:00.350+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:00.349+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:29:00.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:29:00.797+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:00.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:29:00.823+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:00.823+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:29:00.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.509 seconds
[2025-09-29T04:29:30.921+0000] {processor.py:157} INFO - Started process (PID=84432) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:29:30.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:29:30.924+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:30.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:29:31.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:29:31.549+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:31.548+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:29:31.581+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:29:31.580+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:29:31.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.686 seconds
[2025-09-29T04:30:01.953+0000] {processor.py:157} INFO - Started process (PID=84739) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:30:01.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:30:01.955+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:01.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:30:02.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:30:02.885+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:02.884+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:30:02.922+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:02.922+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:30:02.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.002 seconds
[2025-09-29T04:30:33.332+0000] {processor.py:157} INFO - Started process (PID=85076) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:30:33.334+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:30:33.335+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:33.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:30:34.267+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:30:34.316+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:34.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:30:34.352+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:30:34.352+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:30:34.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.060 seconds
[2025-09-29T04:31:04.656+0000] {processor.py:157} INFO - Started process (PID=85383) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:31:04.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:31:04.660+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:04.660+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:31:05.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:31:05.355+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:05.354+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:31:05.382+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:05.381+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:31:05.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.754 seconds
[2025-09-29T04:31:36.168+0000] {processor.py:157} INFO - Started process (PID=85690) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:31:36.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:31:36.172+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:36.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:31:36.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:31:36.801+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:36.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:31:36.827+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:31:36.826+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:31:36.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.684 seconds
[2025-09-29T04:32:07.372+0000] {processor.py:157} INFO - Started process (PID=86005) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:32:07.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:32:07.375+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:07.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:32:07.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:32:08.020+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:08.019+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:32:08.048+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:08.048+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:32:08.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.704 seconds
[2025-09-29T04:32:38.189+0000] {processor.py:157} INFO - Started process (PID=86327) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:32:38.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:32:38.191+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:38.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:32:38.755+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:32:38.777+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:38.776+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:32:38.802+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:32:38.802+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:32:38.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.636 seconds
[2025-09-29T04:33:09.260+0000] {processor.py:157} INFO - Started process (PID=86626) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:33:09.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:33:09.265+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:09.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:33:10.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:33:10.076+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:10.075+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:33:10.116+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:10.116+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:33:10.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.888 seconds
[2025-09-29T04:33:40.400+0000] {processor.py:157} INFO - Started process (PID=86930) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:33:40.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:33:40.402+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:33:40.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:33:41.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:33:41.757+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:34:12.072+0000] {processor.py:157} INFO - Started process (PID=87240) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:34:12.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:34:12.076+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:12.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:34:12.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:34:13.316+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:34:43.658+0000] {processor.py:157} INFO - Started process (PID=87556) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:34:43.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:34:43.661+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:43.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:34:44.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:34:44.678+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:44.677+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:34:44.718+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:34:44.718+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:34:44.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.091 seconds
[2025-09-29T04:35:15.448+0000] {processor.py:157} INFO - Started process (PID=87872) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:35:15.449+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:35:15.451+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:15.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:35:16.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:35:16.286+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:16.285+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:35:16.312+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:16.312+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:35:16.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.889 seconds
[2025-09-29T04:35:46.587+0000] {processor.py:157} INFO - Started process (PID=88179) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:35:46.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:35:46.591+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:46.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:35:47.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:35:47.204+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:47.204+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:35:47.228+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:35:47.228+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:35:47.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.666 seconds
[2025-09-29T04:36:17.776+0000] {processor.py:157} INFO - Started process (PID=88486) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:36:17.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:36:17.779+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:17.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:36:18.366+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:36:18.404+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:18.404+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:36:18.428+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:18.428+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:36:18.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.677 seconds
[2025-09-29T04:36:49.240+0000] {processor.py:157} INFO - Started process (PID=88793) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:36:49.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:36:49.243+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:49.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:36:49.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:36:49.999+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:49.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:36:50.022+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:36:50.022+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:36:50.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.808 seconds
[2025-09-29T04:37:20.379+0000] {processor.py:157} INFO - Started process (PID=89097) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:37:20.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:37:20.381+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:20.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:37:20.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:37:20.934+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:20.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:37:20.957+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:20.957+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:37:20.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.600 seconds
[2025-09-29T04:37:51.663+0000] {processor.py:157} INFO - Started process (PID=89404) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:37:51.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:37:51.665+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:51.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:37:52.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:37:52.297+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:52.296+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:37:52.320+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:37:52.320+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:37:52.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.681 seconds
[2025-09-29T04:38:22.391+0000] {processor.py:157} INFO - Started process (PID=89718) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:38:22.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:38:22.394+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:22.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:38:22.956+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:38:22.978+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:22.978+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:38:23.002+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:23.002+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:38:23.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.634 seconds
[2025-09-29T04:38:53.252+0000] {processor.py:157} INFO - Started process (PID=90025) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:38:53.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:38:53.254+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:53.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:38:53.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:38:53.836+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:53.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:38:53.861+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:38:53.861+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:38:53.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.633 seconds
[2025-09-29T04:39:24.276+0000] {processor.py:157} INFO - Started process (PID=90333) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:39:24.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:39:24.278+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:24.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:39:24.826+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:39:25.214+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:25.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:39:25.238+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:25.238+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:39:25.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.986 seconds
[2025-09-29T04:39:55.981+0000] {processor.py:157} INFO - Started process (PID=90648) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:39:55.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:39:55.983+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:55.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:39:56.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:39:56.895+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:56.894+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:39:56.922+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:39:56.922+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:39:56.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.969 seconds
[2025-09-29T04:40:27.044+0000] {processor.py:157} INFO - Started process (PID=90958) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:40:27.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:40:27.046+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:40:27.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:40:27.523+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:40:28.257+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:40:58.313+0000] {processor.py:157} INFO - Started process (PID=91262) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:40:58.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:40:58.315+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:40:58.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:40:58.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:40:59.894+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:41:29.966+0000] {processor.py:157} INFO - Started process (PID=91579) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:41:29.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:41:29.969+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:41:29.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:41:30.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:41:30.938+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:41:30.938+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:41:30.963+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:41:30.963+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:41:30.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.028 seconds
[2025-09-29T04:42:01.271+0000] {processor.py:157} INFO - Started process (PID=91876) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:42:01.272+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:42:01.274+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:01.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:42:01.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:42:01.775+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:01.774+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:42:01.801+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:01.801+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:42:01.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.553 seconds
[2025-09-29T04:42:32.533+0000] {processor.py:157} INFO - Started process (PID=92183) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:42:32.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:42:32.536+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:32.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:42:33.028+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:42:33.898+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:33.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:42:33.926+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:42:33.926+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:42:33.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.418 seconds
[2025-09-29T04:43:04.435+0000] {processor.py:157} INFO - Started process (PID=92503) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:43:04.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:43:04.437+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:04.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:43:04.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:43:05.341+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:43:35.953+0000] {processor.py:157} INFO - Started process (PID=92826) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:43:35.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:43:35.956+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:35.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:43:36.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:43:36.420+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:36.420+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:43:36.449+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:43:36.448+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:43:36.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.524 seconds
[2025-09-29T04:44:07.119+0000] {processor.py:157} INFO - Started process (PID=93125) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:44:07.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:44:07.120+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:07.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:44:07.556+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:44:07.589+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:07.589+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:44:07.620+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:07.619+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:44:07.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.525 seconds
[2025-09-29T04:44:38.186+0000] {processor.py:157} INFO - Started process (PID=93432) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:44:38.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:44:38.188+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:38.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:44:38.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:44:38.803+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:38.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:44:38.830+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:44:38.830+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:44:38.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.667 seconds
[2025-09-29T04:45:09.563+0000] {processor.py:157} INFO - Started process (PID=93739) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:45:09.565+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:45:09.569+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:09.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:45:10.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:45:10.594+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:45:41.514+0000] {processor.py:157} INFO - Started process (PID=94046) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:45:41.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:45:41.516+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:41.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:45:41.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:45:41.996+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:41.995+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:45:42.023+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:45:42.023+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:45:42.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.534 seconds
[2025-09-29T04:46:12.632+0000] {processor.py:157} INFO - Started process (PID=94353) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:46:12.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:46:12.634+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:12.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:46:13.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:46:13.104+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:13.104+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:46:13.130+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:13.129+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:46:13.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.523 seconds
[2025-09-29T04:46:43.366+0000] {processor.py:157} INFO - Started process (PID=94660) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:46:43.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:46:43.369+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:43.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:46:43.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:46:44.330+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:44.210+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:46:44.361+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:46:44.360+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:46:44.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.019 seconds
[2025-09-29T04:47:14.961+0000] {processor.py:157} INFO - Started process (PID=94980) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:47:14.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:47:14.963+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:14.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:47:15.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:47:15.419+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:15.419+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:47:15.446+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:15.446+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:47:15.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.619 seconds
[2025-09-29T04:47:45.645+0000] {processor.py:157} INFO - Started process (PID=95289) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:47:45.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:47:45.647+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:45.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:47:46.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:47:46.203+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:46.203+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:47:46.236+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:47:46.236+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:47:46.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-09-29T04:48:16.535+0000] {processor.py:157} INFO - Started process (PID=95594) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:48:16.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:48:16.538+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:16.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:48:16.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:48:16.991+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:16.991+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:48:17.137+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:17.136+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:48:17.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.629 seconds
[2025-09-29T04:48:47.575+0000] {processor.py:157} INFO - Started process (PID=95901) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:48:47.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:48:47.577+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:47.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:48:48.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:48:48.135+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:48.135+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:48:48.158+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:48:48.158+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:48:48.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.605 seconds
[2025-09-29T04:49:18.465+0000] {processor.py:157} INFO - Started process (PID=96195) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:49:18.466+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:49:18.467+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:18.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:49:19.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:49:19.196+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:19.196+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:49:19.220+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:19.220+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:49:19.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.780 seconds
[2025-09-29T04:49:49.673+0000] {processor.py:157} INFO - Started process (PID=96494) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:49:49.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:49:49.679+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:49:49.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:49:50.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:49:51.171+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:50:21.592+0000] {processor.py:157} INFO - Started process (PID=96822) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:50:21.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:50:21.595+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:21.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:50:22.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:50:22.722+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:50:53.566+0000] {processor.py:157} INFO - Started process (PID=97134) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:50:53.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:50:53.568+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:53.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:50:54.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:50:54.294+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:54.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:50:54.316+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:50:54.316+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:50:54.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.780 seconds
[2025-09-29T04:51:24.643+0000] {processor.py:157} INFO - Started process (PID=97437) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:51:24.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:51:24.646+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:24.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:51:25.237+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:51:25.260+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:25.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:51:25.282+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:25.282+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:51:25.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.662 seconds
[2025-09-29T04:51:55.361+0000] {processor.py:157} INFO - Started process (PID=97744) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:51:55.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:51:55.364+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:55.364+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:51:55.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:51:55.988+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:55.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:51:56.011+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:51:56.010+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:51:56.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.671 seconds
[2025-09-29T04:52:26.629+0000] {processor.py:157} INFO - Started process (PID=98049) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:52:26.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:52:26.631+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:26.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:52:27.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:52:28.432+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:28.432+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:52:28.457+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:28.457+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:52:28.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.852 seconds
[2025-09-29T04:52:58.811+0000] {processor.py:157} INFO - Started process (PID=98391) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:52:58.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:52:58.813+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:58.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:52:59.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:52:59.369+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:59.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:52:59.393+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:52:59.393+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:52:59.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.607 seconds
[2025-09-29T04:53:30.315+0000] {processor.py:157} INFO - Started process (PID=98696) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:53:30.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:53:30.317+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:30.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:53:30.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:53:30.878+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:30.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:53:30.907+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:53:30.907+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:53:30.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.620 seconds
[2025-09-29T04:54:00.971+0000] {processor.py:157} INFO - Started process (PID=98998) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:54:00.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:54:00.973+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:00.973+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:54:01.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:54:01.986+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:01.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:54:02.010+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:02.010+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:54:02.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.064 seconds
[2025-09-29T04:54:32.433+0000] {processor.py:157} INFO - Started process (PID=99302) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:54:32.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:54:32.435+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:32.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:54:33.013+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:54:33.035+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:33.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:54:33.061+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:54:33.061+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:54:33.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.652 seconds
[2025-09-29T04:55:03.144+0000] {processor.py:157} INFO - Started process (PID=99602) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:55:03.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:55:03.146+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:03.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:55:03.706+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:55:04.666+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:55:35.113+0000] {processor.py:157} INFO - Started process (PID=99916) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:55:35.114+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:55:35.115+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:35.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:55:35.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:55:35.699+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:35.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:55:35.722+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:55:35.722+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:55:35.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.635 seconds
[2025-09-29T04:56:05.816+0000] {processor.py:157} INFO - Started process (PID=529) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:56:05.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:56:05.817+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:05.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:56:06.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:56:07.799+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:56:38.319+0000] {processor.py:157} INFO - Started process (PID=841) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:56:38.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:56:38.321+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:56:38.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:56:38.863+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:56:39.697+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:57:09.927+0000] {processor.py:157} INFO - Started process (PID=1156) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:57:09.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:57:09.936+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:09.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:57:10.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:57:10.497+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:10.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:57:10.519+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:10.519+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:57:10.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-09-29T04:57:41.384+0000] {processor.py:157} INFO - Started process (PID=1460) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:57:41.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:57:41.387+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:41.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:57:42.043+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:57:42.551+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:42.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:57:42.586+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:57:42.585+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:57:42.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.233 seconds
[2025-09-29T04:58:13.136+0000] {processor.py:157} INFO - Started process (PID=1785) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:58:13.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:58:13.138+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:13.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:58:13.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:58:14.161+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:14.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:58:14.189+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:14.189+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:58:14.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.085 seconds
[2025-09-29T04:58:44.633+0000] {processor.py:157} INFO - Started process (PID=2092) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:58:44.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:58:44.638+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:58:44.637+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:58:45.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:58:46.068+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T04:59:16.513+0000] {processor.py:157} INFO - Started process (PID=2409) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:59:16.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:59:16.515+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:16.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:59:17.023+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:59:18.085+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:18.084+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:59:18.114+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:18.114+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:59:18.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.629 seconds
[2025-09-29T04:59:48.580+0000] {processor.py:157} INFO - Started process (PID=2728) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:59:48.581+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T04:59:48.583+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:48.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:59:49.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T04:59:49.071+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:49.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T04:59:49.098+0000] {logging_mixin.py:149} INFO - [2025-09-29T04:59:49.098+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T04:59:49.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.544 seconds
[2025-09-29T05:00:19.266+0000] {processor.py:157} INFO - Started process (PID=3035) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:00:19.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:00:19.268+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:19.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:00:19.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:00:19.746+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:19.746+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:00:19.775+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:19.774+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:00:19.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.542 seconds
[2025-09-29T05:00:49.963+0000] {processor.py:157} INFO - Started process (PID=3342) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:00:49.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:00:49.965+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:00:49.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:00:50.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:00:51.758+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:01:22.594+0000] {processor.py:157} INFO - Started process (PID=3670) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:01:22.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:01:22.598+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:22.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:01:23.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:01:23.886+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:01:54.327+0000] {processor.py:157} INFO - Started process (PID=3992) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:01:54.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:01:54.329+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:54.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:01:54.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:01:54.880+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:54.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:01:54.911+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:01:54.910+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:01:54.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.627 seconds
[2025-09-29T05:02:25.514+0000] {processor.py:157} INFO - Started process (PID=4295) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:02:25.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:02:25.516+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:25.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:02:25.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:02:26.551+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:26.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:02:26.579+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:26.579+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:02:26.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.093 seconds
[2025-09-29T05:02:57.042+0000] {processor.py:157} INFO - Started process (PID=4612) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:02:57.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:02:57.043+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:57.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:02:57.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:02:57.958+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:57.957+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:02:57.984+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:02:57.984+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:02:58.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.964 seconds
[2025-09-29T05:03:28.289+0000] {processor.py:157} INFO - Started process (PID=4917) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:03:28.290+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:03:28.291+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:28.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:03:28.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:03:28.725+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:28.724+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:03:28.877+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:28.876+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:03:28.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.616 seconds
[2025-09-29T05:03:59.120+0000] {processor.py:157} INFO - Started process (PID=5224) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:03:59.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:03:59.122+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:59.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:03:59.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:03:59.577+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:59.576+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:03:59.603+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:03:59.602+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:03:59.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.507 seconds
[2025-09-29T05:04:29.670+0000] {processor.py:157} INFO - Started process (PID=5531) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:04:29.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:04:29.673+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:29.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:04:30.171+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:04:30.195+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:30.195+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:04:30.339+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:04:30.339+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:04:30.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.693 seconds
[2025-09-29T05:05:00.701+0000] {processor.py:157} INFO - Started process (PID=5841) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:05:00.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:05:00.702+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:00.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:05:01.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:05:01.785+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:01.785+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:05:01.808+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:01.808+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:05:01.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.130 seconds
[2025-09-29T05:05:31.920+0000] {processor.py:157} INFO - Started process (PID=6148) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:05:31.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:05:31.922+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:31.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:05:32.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:05:32.523+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:32.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:05:32.546+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:05:32.545+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:05:32.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.647 seconds
[2025-09-29T05:06:02.861+0000] {processor.py:157} INFO - Started process (PID=6455) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:06:02.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:06:02.864+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:02.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:06:03.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:06:03.399+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:03.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:06:03.421+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:03.421+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:06:03.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.583 seconds
[2025-09-29T05:06:33.938+0000] {processor.py:157} INFO - Started process (PID=6757) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:06:33.939+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:06:33.940+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:33.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:06:34.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:06:35.155+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:35.153+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:06:35.178+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:06:35.178+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:06:35.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.264 seconds
[2025-09-29T05:07:05.236+0000] {processor.py:157} INFO - Started process (PID=7079) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:07:05.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:07:05.238+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:05.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:07:05.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:07:07.001+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-09-29T05:07:37.102+0000] {processor.py:157} INFO - Started process (PID=7393) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:07:37.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:07:37.104+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:37.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:07:37.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:07:38.377+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:38.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:07:38.400+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:07:38.400+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:07:38.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.322 seconds
[2025-09-29T05:08:08.633+0000] {processor.py:157} INFO - Started process (PID=7710) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:08:08.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:08:08.635+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:08.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:08:09.190+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:08:09.290+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:09.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:08:09.315+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:09.315+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:08:09.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.705 seconds
[2025-09-29T05:08:39.686+0000] {processor.py:157} INFO - Started process (PID=8017) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:08:39.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:08:39.688+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:39.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:08:40.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:08:40.309+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:40.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:08:40.333+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:08:40.333+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:08:40.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.671 seconds
[2025-09-29T05:09:10.433+0000] {processor.py:157} INFO - Started process (PID=8319) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:09:10.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:09:10.435+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:10.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:09:11.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:09:11.032+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:11.031+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:09:11.057+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:11.057+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:09:11.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.647 seconds
[2025-09-29T05:09:41.801+0000] {processor.py:157} INFO - Started process (PID=8626) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:09:41.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:09:41.803+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:41.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:09:42.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:09:42.376+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:42.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:09:42.398+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:09:42.398+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:09:42.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.620 seconds
[2025-09-29T05:10:12.577+0000] {processor.py:157} INFO - Started process (PID=8933) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:10:12.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:10:12.580+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:12.580+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:10:13.138+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:10:14.193+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:14.193+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:10:14.217+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:14.217+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:10:14.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.663 seconds
[2025-09-29T05:10:44.274+0000] {processor.py:157} INFO - Started process (PID=9250) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:10:44.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:10:44.276+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:44.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:10:44.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:10:44.818+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:44.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:10:44.840+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:10:44.840+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:10:44.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.589 seconds
[2025-09-29T05:11:14.981+0000] {processor.py:157} INFO - Started process (PID=9558) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:11:14.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:11:14.983+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:14.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:11:15.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:11:15.550+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:15.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:11:15.575+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:15.575+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:11:15.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.617 seconds
[2025-09-29T05:11:46.564+0000] {processor.py:157} INFO - Started process (PID=9865) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:11:46.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:11:46.568+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:46.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:11:47.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:11:47.206+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:47.206+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:11:47.233+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:11:47.233+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:11:47.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.695 seconds
[2025-09-29T05:12:17.367+0000] {processor.py:157} INFO - Started process (PID=10170) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:12:17.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:12:17.369+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:17.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:12:18.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:12:18.065+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:18.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:12:18.099+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:18.099+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:12:18.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.759 seconds
[2025-09-29T05:12:48.166+0000] {processor.py:157} INFO - Started process (PID=10482) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:12:48.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:12:48.168+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:48.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:12:48.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:12:49.206+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:49.206+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:12:49.232+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:12:49.231+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:12:49.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.088 seconds
[2025-09-29T05:13:19.790+0000] {processor.py:157} INFO - Started process (PID=10786) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:13:19.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:13:19.792+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:19.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:13:20.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:13:20.458+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:20.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:13:20.481+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:20.481+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:13:20.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.715 seconds
[2025-09-29T05:13:50.710+0000] {processor.py:157} INFO - Started process (PID=11093) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:13:50.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:13:50.711+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:50.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:13:51.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:13:51.561+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:51.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:13:51.585+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:13:51.584+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:13:51.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.898 seconds
[2025-09-29T05:14:22.874+0000] {processor.py:157} INFO - Started process (PID=11398) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:14:22.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:14:22.880+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:22.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:14:23.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:14:23.907+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:23.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:14:23.931+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:23.931+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:14:23.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.083 seconds
[2025-09-29T05:14:54.036+0000] {processor.py:157} INFO - Started process (PID=11712) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:14:54.037+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:14:54.039+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:54.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:14:54.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:14:54.506+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:54.506+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:14:54.532+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:14:54.532+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:14:54.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.521 seconds
[2025-09-29T05:15:24.711+0000] {processor.py:157} INFO - Started process (PID=12019) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:15:24.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:15:24.712+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:24.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:15:25.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:15:25.748+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:25.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:15:25.776+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:25.775+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:15:25.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.090 seconds
[2025-09-29T05:15:56.382+0000] {processor.py:157} INFO - Started process (PID=12334) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:15:56.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:15:56.384+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:56.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:15:56.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:15:56.826+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:56.826+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:15:56.854+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:15:56.854+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:15:56.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.497 seconds
[2025-09-29T05:16:27.725+0000] {processor.py:157} INFO - Started process (PID=12647) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:16:27.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:16:27.727+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:27.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:16:28.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:16:29.024+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:29.023+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:16:29.055+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:29.055+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:16:29.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.358 seconds
[2025-09-29T05:16:59.443+0000] {processor.py:157} INFO - Started process (PID=12978) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:16:59.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:16:59.445+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:59.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:16:59.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:16:59.940+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:59.940+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:16:59.968+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:16:59.968+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:16:59.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.549 seconds
[2025-09-29T05:17:30.627+0000] {processor.py:157} INFO - Started process (PID=13285) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:17:30.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-09-29T05:17:30.630+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:17:30.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:17:31.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-09-29T05:17:31.780+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:17:31.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-09-29T05:17:31.811+0000] {logging_mixin.py:149} INFO - [2025-09-29T05:17:31.811+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-09-29T09:00:00+00:00, run_after=2025-09-30T09:00:00+00:00
[2025-09-29T05:17:31.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.215 seconds
