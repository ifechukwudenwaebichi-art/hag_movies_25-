[2025-10-08T12:30:46.709+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:30:46.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:30:46.712+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:46.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:30:47.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:30:47.780+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:47.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:30:47.835+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:47.834+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:30:47.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.162 seconds
[2025-10-08T12:31:18.064+0000] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:31:18.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:31:18.066+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:18.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:31:18.524+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:31:18.551+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:18.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:31:18.581+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:18.581+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:31:18.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.545 seconds
[2025-10-08T12:31:49.056+0000] {processor.py:157} INFO - Started process (PID=833) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:31:49.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:31:49.058+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:49.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:31:49.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:31:49.684+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:49.683+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:31:49.717+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:49.717+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:31:49.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.690 seconds
[2025-10-08T12:32:20.205+0000] {processor.py:157} INFO - Started process (PID=1145) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:32:20.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:32:20.208+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:32:20.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:32:20.810+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:32:20.847+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.847+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:32:20.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.671 seconds
[2025-10-08T12:32:50.980+0000] {processor.py:157} INFO - Started process (PID=1449) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:32:50.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:32:50.982+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:32:51.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:32:51.621+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:51.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:32:51.654+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:51.654+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:32:51.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.703 seconds
[2025-10-08T12:33:22.143+0000] {processor.py:157} INFO - Started process (PID=1759) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:33:22.146+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:33:22.148+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:33:22.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:33:22.744+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:33:22.777+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.777+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:33:22.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.662 seconds
[2025-10-08T12:33:54.176+0000] {processor.py:157} INFO - Started process (PID=2066) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:33:54.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:33:54.179+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:54.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:33:55.201+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:33:55.251+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:55.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:33:55.386+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:55.384+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:33:55.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.316 seconds
[2025-10-08T12:34:26.047+0000] {processor.py:157} INFO - Started process (PID=2375) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:34:26.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:34:26.049+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:26.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:34:26.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:34:26.687+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:26.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:34:26.721+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:26.721+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:34:26.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.702 seconds
[2025-10-08T12:34:56.909+0000] {processor.py:157} INFO - Started process (PID=2687) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:34:56.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:34:56.911+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:56.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:34:57.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:34:57.537+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:57.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:34:57.587+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:57.587+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:34:57.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.716 seconds
[2025-10-08T12:35:27.988+0000] {processor.py:157} INFO - Started process (PID=2999) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:35:27.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:35:27.990+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.990+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:35:28.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:35:28.501+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:28.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:35:28.534+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:28.533+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:35:28.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.572 seconds
[2025-10-08T12:35:59.207+0000] {processor.py:157} INFO - Started process (PID=3314) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:35:59.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:35:59.210+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:59.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:36:00.685+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:36:00.879+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:00.877+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:36:01.479+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:01.478+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:36:01.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 2.348 seconds
[2025-10-08T12:36:31.749+0000] {processor.py:157} INFO - Started process (PID=3636) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:36:31.750+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:36:31.751+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:31.751+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:36:32.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:36:32.989+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:32.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:36:33.055+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:33.054+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:36:33.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.366 seconds
[2025-10-08T12:37:03.782+0000] {processor.py:157} INFO - Started process (PID=3948) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:37:03.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:37:03.786+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:03.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:37:04.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:37:04.472+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:04.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:37:04.509+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:04.509+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:37:04.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.756 seconds
[2025-10-08T12:37:35.104+0000] {processor.py:157} INFO - Started process (PID=4257) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:37:35.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:37:35.109+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:35.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:37:36.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:37:36.316+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:36.315+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:37:36.357+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:36.357+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:37:36.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.290 seconds
[2025-10-08T12:38:06.434+0000] {processor.py:157} INFO - Started process (PID=4579) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:38:06.435+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:38:06.436+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:06.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:38:07.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:38:07.152+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:07.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:38:07.193+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:07.193+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:38:07.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.791 seconds
[2025-10-08T12:38:37.609+0000] {processor.py:157} INFO - Started process (PID=4886) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:38:37.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:38:37.612+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:37.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:38:38.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:38:38.614+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:38.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:38:38.652+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:38.652+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:38:38.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.080 seconds
[2025-10-08T12:39:08.947+0000] {processor.py:157} INFO - Started process (PID=5201) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:39:08.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:39:08.950+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:08.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:39:09.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:39:10.298+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:10.297+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:39:10.350+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:10.350+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:39:10.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.441 seconds
[2025-10-08T12:39:41.072+0000] {processor.py:157} INFO - Started process (PID=5513) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:39:41.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:39:41.075+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:41.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:39:41.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:39:41.784+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:41.783+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:39:41.817+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:41.816+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:39:41.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.773 seconds
[2025-10-08T12:40:12.579+0000] {processor.py:157} INFO - Started process (PID=5815) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:40:12.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:40:12.581+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:12.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:40:13.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:40:13.257+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:13.256+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:40:13.287+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:13.287+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:40:13.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.734 seconds
[2025-10-08T12:40:43.782+0000] {processor.py:157} INFO - Started process (PID=6122) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:40:43.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:40:43.785+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:43.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:40:44.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:40:44.730+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:44.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:40:44.768+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:44.768+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:40:44.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.022 seconds
[2025-10-08T12:41:15.489+0000] {processor.py:157} INFO - Started process (PID=6440) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:41:15.490+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:41:15.491+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:15.491+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:41:16.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:41:16.188+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:16.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:41:16.215+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:16.215+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:41:16.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.751 seconds
[2025-10-08T12:41:46.355+0000] {processor.py:157} INFO - Started process (PID=6750) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:41:46.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:41:46.358+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:46.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:41:46.891+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:41:46.914+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:46.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:41:46.940+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:46.940+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:41:46.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.609 seconds
[2025-10-08T12:42:17.355+0000] {processor.py:157} INFO - Started process (PID=7057) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:42:17.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:42:17.360+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:17.359+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:42:18.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:42:18.951+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:18.951+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:42:18.981+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:18.980+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:42:18.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.653 seconds
[2025-10-08T12:42:49.710+0000] {processor.py:157} INFO - Started process (PID=7366) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:42:49.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:42:49.712+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:49.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:42:50.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:42:50.350+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:50.350+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:42:50.378+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:50.378+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:42:50.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.693 seconds
[2025-10-08T12:43:21.251+0000] {processor.py:157} INFO - Started process (PID=7695) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:43:21.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:43:21.252+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:21.252+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:43:21.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:43:22.836+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:22.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:43:22.866+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:22.866+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:43:22.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.643 seconds
[2025-10-08T12:43:52.929+0000] {processor.py:157} INFO - Started process (PID=8032) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:43:52.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:43:52.932+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:52.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:43:53.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:43:53.617+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:53.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:43:53.695+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:53.692+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:43:53.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.815 seconds
[2025-10-08T12:44:24.011+0000] {processor.py:157} INFO - Started process (PID=8339) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:44:24.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:44:24.014+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:24.014+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:44:24.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:44:24.715+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:24.714+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:44:24.758+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:24.757+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:44:24.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.773 seconds
[2025-10-08T12:44:55.772+0000] {processor.py:157} INFO - Started process (PID=8644) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:44:55.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:44:55.774+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:55.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:44:56.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:44:56.800+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:56.800+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:44:56.830+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:56.830+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:44:56.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.087 seconds
[2025-10-08T12:45:27.197+0000] {processor.py:157} INFO - Started process (PID=8951) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:45:27.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:45:27.199+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:27.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:45:27.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:45:28.777+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:28.777+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:45:28.808+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:28.808+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:45:28.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.637 seconds
[2025-10-08T12:45:59.513+0000] {processor.py:157} INFO - Started process (PID=9260) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:45:59.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:45:59.515+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:59.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:46:00.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:46:00.229+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:00.228+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:46:00.262+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:00.262+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:46:00.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.783 seconds
[2025-10-08T12:46:30.427+0000] {processor.py:157} INFO - Started process (PID=9567) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:46:30.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:46:30.429+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:30.429+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:46:30.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:46:30.907+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:30.906+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:46:30.939+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:30.939+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:46:30.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.541 seconds
[2025-10-08T12:47:01.116+0000] {processor.py:157} INFO - Started process (PID=9872) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:47:01.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:47:01.119+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:01.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:47:01.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:47:01.638+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:01.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:47:01.674+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:01.674+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:47:01.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.591 seconds
[2025-10-08T12:47:31.884+0000] {processor.py:157} INFO - Started process (PID=10176) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:47:31.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:47:31.888+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:31.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:47:32.349+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:47:32.375+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:32.375+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:47:32.405+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:32.404+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:47:32.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.547 seconds
[2025-10-08T12:48:02.516+0000] {processor.py:157} INFO - Started process (PID=10471) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:48:02.517+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:48:02.518+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:02.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:48:02.947+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:48:03.842+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:48:35.124+0000] {processor.py:157} INFO - Started process (PID=10783) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:48:35.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:48:35.126+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:35.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:48:35.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:48:35.727+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:35.726+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:48:35.760+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:35.760+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:48:35.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.666 seconds
[2025-10-08T12:49:06.352+0000] {processor.py:157} INFO - Started process (PID=11087) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:49:06.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:49:06.356+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:06.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:49:06.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:49:06.860+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:06.859+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:49:06.891+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:06.890+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:49:06.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.565 seconds
[2025-10-08T12:49:37.592+0000] {processor.py:157} INFO - Started process (PID=11394) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:49:37.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:49:37.595+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:37.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:49:38.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:49:38.096+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:38.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:49:38.126+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:38.126+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:49:38.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.559 seconds
[2025-10-08T12:50:08.981+0000] {processor.py:157} INFO - Started process (PID=11701) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:50:08.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:50:08.983+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:08.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:50:09.433+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:50:09.459+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:09.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:50:09.489+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:09.489+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:50:09.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.534 seconds
[2025-10-08T12:50:40.219+0000] {processor.py:157} INFO - Started process (PID=12008) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:50:40.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:50:40.222+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:40.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:50:40.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:50:40.742+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:40.742+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:50:40.775+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:40.775+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:50:40.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.587 seconds
[2025-10-08T12:51:11.697+0000] {processor.py:157} INFO - Started process (PID=12324) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:51:11.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:51:11.700+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:11.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:51:12.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:51:12.215+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:12.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:51:12.252+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:12.252+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:51:12.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.584 seconds
[2025-10-08T12:51:42.353+0000] {processor.py:157} INFO - Started process (PID=12631) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:51:42.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:51:42.355+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:42.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:51:42.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:51:43.278+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:43.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:51:43.449+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:43.448+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:51:43.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.125 seconds
[2025-10-08T12:52:13.823+0000] {processor.py:157} INFO - Started process (PID=12936) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:52:13.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:52:13.825+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:13.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:52:14.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:52:14.370+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:14.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:52:14.434+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:14.434+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:52:14.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.660 seconds
[2025-10-08T12:52:44.628+0000] {processor.py:157} INFO - Started process (PID=13235) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:52:44.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:52:44.631+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:44.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:52:45.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:52:45.682+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:53:16.014+0000] {processor.py:157} INFO - Started process (PID=13549) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:53:16.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:53:16.019+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:16.019+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:53:16.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:53:16.695+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:16.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:53:16.728+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:16.728+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:53:16.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.747 seconds
[2025-10-08T12:53:46.886+0000] {processor.py:157} INFO - Started process (PID=13846) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:53:46.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:53:46.888+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:46.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:53:47.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:53:48.127+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:54:18.865+0000] {processor.py:157} INFO - Started process (PID=14156) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:54:18.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:54:18.867+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:18.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:54:19.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:54:19.560+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:19.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:54:19.591+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:19.591+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:54:19.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.757 seconds
[2025-10-08T12:54:50.157+0000] {processor.py:157} INFO - Started process (PID=14463) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:54:50.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:54:50.161+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:50.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:54:50.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:54:50.800+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:50.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:54:50.829+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:50.828+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:54:50.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.702 seconds
[2025-10-08T12:55:21.481+0000] {processor.py:157} INFO - Started process (PID=14770) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:55:21.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:55:21.484+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:21.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:55:22.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:55:22.275+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:22.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:55:22.308+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:22.308+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:55:22.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.853 seconds
[2025-10-08T12:55:52.412+0000] {processor.py:157} INFO - Started process (PID=15081) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:55:52.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:55:52.415+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:52.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:55:53.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:55:54.005+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:54.005+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:55:54.058+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:54.058+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:55:54.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.702 seconds
[2025-10-08T12:56:24.188+0000] {processor.py:157} INFO - Started process (PID=15403) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:56:24.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:56:24.189+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:24.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:56:24.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:56:24.790+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:24.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:56:24.819+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:24.819+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:56:24.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.656 seconds
[2025-10-08T12:56:54.954+0000] {processor.py:157} INFO - Started process (PID=15715) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:56:54.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:56:54.957+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:54.957+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:56:55.532+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:56:55.555+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:55.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:56:55.587+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:55.587+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:56:55.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.669 seconds
[2025-10-08T12:57:25.728+0000] {processor.py:157} INFO - Started process (PID=16022) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:57:25.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:57:25.731+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:25.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:57:26.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:57:26.438+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:26.437+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:57:26.468+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:26.468+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:57:26.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.765 seconds
[2025-10-08T12:57:57.068+0000] {processor.py:157} INFO - Started process (PID=16329) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:57:57.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:57:57.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:57.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:57:57.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:57:57.662+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:57.661+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:57:57.689+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:57.688+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:57:57.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.646 seconds
[2025-10-08T12:58:28.477+0000] {processor.py:157} INFO - Started process (PID=16641) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:58:28.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:58:28.479+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:28.479+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:58:29.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:58:30.164+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:59:00.391+0000] {processor.py:157} INFO - Started process (PID=16956) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:59:00.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:59:00.393+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:00.393+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:59:01.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:59:02.031+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:59:32.091+0000] {processor.py:157} INFO - Started process (PID=17278) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:59:32.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T12:59:32.093+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:32.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:59:32.707+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T12:59:33.493+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:33.493+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:59:33.531+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:33.531+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T12:59:33.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.472 seconds
[2025-10-08T13:00:03.682+0000] {processor.py:157} INFO - Started process (PID=17585) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:00:03.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:00:03.683+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:03.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:00:04.273+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:00:05.478+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:00:35.736+0000] {processor.py:157} INFO - Started process (PID=17910) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:00:35.738+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:00:35.740+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:35.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:00:36.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:00:37.063+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:37.062+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:00:37.091+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:37.091+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:00:37.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.381 seconds
[2025-10-08T13:01:07.395+0000] {processor.py:157} INFO - Started process (PID=18217) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:01:07.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:01:07.397+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:07.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:01:07.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:01:07.999+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:07.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:08.028+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:08.028+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:01:08.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.658 seconds
[2025-10-08T13:01:38.688+0000] {processor.py:157} INFO - Started process (PID=18521) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:01:38.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:01:38.690+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:38.690+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:01:39.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:01:39.300+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:39.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:39.333+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:39.333+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:01:39.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.670 seconds
[2025-10-08T13:02:09.452+0000] {processor.py:157} INFO - Started process (PID=18831) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:02:09.453+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:02:09.454+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:09.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:02:10.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:02:10.077+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:10.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:02:10.116+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:10.116+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:02:10.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.704 seconds
[2025-10-08T13:02:41.023+0000] {processor.py:157} INFO - Started process (PID=19135) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:02:41.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:02:41.025+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:41.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:02:41.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:02:41.964+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:41.964+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:02:41.991+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:41.991+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:02:42.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.994 seconds
[2025-10-08T13:04:37.707+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:04:37.708+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:04:37.710+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:04:38.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:04:39.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:39.070+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:04:39.135+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:39.135+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:04:39.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.481 seconds
[2025-10-08T13:05:09.687+0000] {processor.py:157} INFO - Started process (PID=518) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:05:09.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:05:09.690+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:09.690+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:05:10.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:05:10.174+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:10.173+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:05:10.217+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:10.217+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:05:10.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.555 seconds
[2025-10-08T13:05:40.927+0000] {processor.py:157} INFO - Started process (PID=825) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:05:40.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:05:40.929+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:40.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:05:41.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:05:42.570+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.4), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:06:13.143+0000] {processor.py:157} INFO - Started process (PID=1132) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:06:13.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:06:13.145+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:13.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:06:13.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:06:13.691+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:13.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:06:13.722+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:13.722+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:06:13.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.607 seconds
[2025-10-08T13:06:44.320+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:06:44.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:06:44.332+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:44.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:06:44.903+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:06:44.938+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:44.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:06:44.987+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:44.986+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:06:45.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.712 seconds
[2025-10-08T13:07:51.455+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:07:51.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:07:51.459+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:51.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:07:52.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:07:52.511+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:52.510+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:07:52.551+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:52.550+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:07:52.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.137 seconds
[2025-10-08T13:08:22.790+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:08:22.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:08:22.793+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:22.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:08:23.441+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:08:23.480+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:23.480+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:08:23.525+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:23.525+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:08:23.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.774 seconds
[2025-10-08T13:08:53.915+0000] {processor.py:157} INFO - Started process (PID=816) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:08:53.917+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:08:53.918+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:53.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:08:54.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:08:54.646+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:54.645+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:08:54.701+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:54.701+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:08:54.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.831 seconds
[2025-10-08T13:09:25.168+0000] {processor.py:157} INFO - Started process (PID=1115) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:09:25.170+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:09:25.172+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:25.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:09:26.080+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:09:26.709+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:26.708+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:09:26.798+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:26.797+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:09:26.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.694 seconds
[2025-10-08T13:09:56.910+0000] {processor.py:157} INFO - Started process (PID=1435) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:09:56.911+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:09:56.912+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:56.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:09:57.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:09:57.373+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:57.373+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:09:57.403+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:57.402+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:09:57.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.518 seconds
[2025-10-08T13:10:28.241+0000] {processor.py:157} INFO - Started process (PID=1742) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:10:28.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:10:28.244+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:28.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:10:28.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:10:28.730+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:28.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:10:28.775+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:28.775+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:10:28.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.598 seconds
[2025-10-08T13:10:59.160+0000] {processor.py:157} INFO - Started process (PID=2054) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:10:59.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:10:59.162+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:59.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:10:59.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:10:59.589+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:59.589+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:10:59.619+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:59.619+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:10:59.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.487 seconds
[2025-10-08T13:11:30.051+0000] {processor.py:157} INFO - Started process (PID=2356) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:11:30.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:11:30.053+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:30.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:11:30.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:11:30.590+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:30.590+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:11:30.624+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:30.624+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:11:30.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.598 seconds
[2025-10-08T13:17:29.771+0000] {processor.py:157} INFO - Started process (PID=2661) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:17:29.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:17:29.778+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:29.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:17:31.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:17:32.049+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:32.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:17:32.138+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:32.138+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:17:32.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 2.709 seconds
[2025-10-08T13:18:02.816+0000] {processor.py:157} INFO - Started process (PID=2968) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:18:02.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:18:02.819+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:02.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:18:03.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:18:03.305+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:03.304+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:18:03.336+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:03.336+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:18:03.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.544 seconds
[2025-10-08T13:18:34.360+0000] {processor.py:157} INFO - Started process (PID=3275) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:18:34.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:18:34.363+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:34.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:18:34.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:18:34.867+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:34.867+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:18:34.901+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:34.901+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:18:35.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.699 seconds
[2025-10-08T13:19:05.258+0000] {processor.py:157} INFO - Started process (PID=3591) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:19:05.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:19:05.261+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:05.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:19:05.719+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:19:06.195+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:06.195+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:19:06.227+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:06.227+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:19:06.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.993 seconds
[2025-10-08T13:19:36.569+0000] {processor.py:157} INFO - Started process (PID=3906) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:19:36.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:19:36.572+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:36.571+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:19:37.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:19:37.670+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:20:07.882+0000] {processor.py:157} INFO - Started process (PID=4218) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:20:07.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:20:07.885+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:07.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:20:08.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:20:08.484+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:08.484+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:20:08.519+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:08.518+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:20:08.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.668 seconds
[2025-10-08T13:20:39.040+0000] {processor.py:157} INFO - Started process (PID=4517) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:20:39.043+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:20:39.044+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:39.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:20:39.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:20:39.773+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:39.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:20:39.807+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:39.806+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:20:39.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.793 seconds
[2025-10-08T13:21:10.065+0000] {processor.py:157} INFO - Started process (PID=4824) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:21:10.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:21:10.072+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:10.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:21:10.672+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:21:10.695+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:10.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:21:10.725+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:10.724+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:21:10.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.696 seconds
[2025-10-08T13:21:41.453+0000] {processor.py:157} INFO - Started process (PID=5139) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:21:41.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:21:41.455+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:41.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:21:41.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:21:42.224+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:42.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:21:42.255+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:42.254+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:21:42.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.831 seconds
[2025-10-08T13:22:12.570+0000] {processor.py:157} INFO - Started process (PID=5453) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:22:12.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:22:12.573+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:12.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:22:13.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:22:13.126+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:13.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:22:13.152+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:13.152+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:22:13.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.605 seconds
[2025-10-08T13:22:43.323+0000] {processor.py:157} INFO - Started process (PID=5758) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:22:43.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:22:43.325+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:43.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:22:43.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:22:43.859+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:43.859+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:22:43.886+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:43.886+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:22:43.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.586 seconds
[2025-10-08T13:23:14.455+0000] {processor.py:157} INFO - Started process (PID=6060) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:23:14.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:23:14.457+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:14.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:23:15.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:23:15.025+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:15.024+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:23:15.054+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:15.054+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:23:15.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.628 seconds
[2025-10-08T13:23:45.641+0000] {processor.py:157} INFO - Started process (PID=6369) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:23:45.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:23:45.643+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:45.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:23:46.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:23:47.206+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:24:17.707+0000] {processor.py:157} INFO - Started process (PID=6690) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:24:17.708+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:24:17.709+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:17.709+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:24:18.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:24:18.272+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:18.272+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:24:18.301+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:18.300+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:24:18.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.620 seconds
[2025-10-08T13:24:48.578+0000] {processor.py:157} INFO - Started process (PID=6997) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:24:48.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:24:48.581+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:48.580+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:24:49.134+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:24:49.156+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:49.156+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:24:49.184+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:49.183+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:24:49.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.630 seconds
[2025-10-08T13:25:19.453+0000] {processor.py:157} INFO - Started process (PID=7302) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:25:19.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:25:19.455+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:19.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:25:19.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:25:19.983+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:19.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:25:20.015+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:20.015+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:25:20.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.587 seconds
[2025-10-08T13:25:50.346+0000] {processor.py:157} INFO - Started process (PID=7601) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:25:50.347+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:25:50.348+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:50.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:25:50.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:25:51.512+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:26:21.927+0000] {processor.py:157} INFO - Started process (PID=7921) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:26:21.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:26:21.930+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:21.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:26:22.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:26:22.461+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:22.461+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:26:22.488+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:22.488+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:26:22.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.583 seconds
[2025-10-08T13:26:52.959+0000] {processor.py:157} INFO - Started process (PID=8228) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:26:52.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:26:52.961+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:52.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:26:53.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:26:53.650+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:53.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:26:53.690+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:53.690+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:26:53.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.760 seconds
[2025-10-08T13:27:24.184+0000] {processor.py:157} INFO - Started process (PID=8535) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:27:24.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:27:24.185+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:24.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:27:24.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:27:24.732+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:24.732+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:27:24.758+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:24.758+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:27:24.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.597 seconds
[2025-10-08T13:27:55.076+0000] {processor.py:157} INFO - Started process (PID=8837) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:27:55.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:27:55.077+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:55.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:27:55.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:27:55.630+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:55.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:27:55.658+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:55.658+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:27:55.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.613 seconds
[2025-10-08T13:28:25.782+0000] {processor.py:157} INFO - Started process (PID=9143) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:28:25.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:28:25.784+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:25.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:28:26.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:28:26.316+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:26.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:28:26.344+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:26.343+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:28:26.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.586 seconds
[2025-10-08T13:28:56.968+0000] {processor.py:157} INFO - Started process (PID=9451) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:28:56.969+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:28:56.970+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:56.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:28:57.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:28:58.333+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:29:28.412+0000] {processor.py:157} INFO - Started process (PID=9782) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:29:28.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:29:28.414+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:28.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:29:29.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:29:29.145+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:29.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:29:29.173+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:29.173+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:29:29.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.786 seconds
[2025-10-08T13:29:59.745+0000] {processor.py:157} INFO - Started process (PID=10088) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:29:59.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:29:59.747+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:59.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:30:00.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:30:00.865+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:00.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:30:00.895+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:00.895+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:30:00.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.181 seconds
[2025-10-08T13:30:31.752+0000] {processor.py:157} INFO - Started process (PID=10414) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:30:31.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:30:31.753+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:31.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:30:32.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:30:32.769+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:32.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:30:32.808+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:32.808+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:30:32.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.089 seconds
[2025-10-08T13:31:03.446+0000] {processor.py:157} INFO - Started process (PID=10726) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:31:03.449+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:31:03.450+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:03.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:31:03.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:31:03.898+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:03.897+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:31:03.927+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:03.927+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:31:03.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.506 seconds
[2025-10-08T13:31:33.991+0000] {processor.py:157} INFO - Started process (PID=11033) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:31:33.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:31:33.993+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:33.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:31:34.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:31:34.447+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:34.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:31:34.478+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:34.478+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:31:34.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.513 seconds
[2025-10-08T13:32:05.324+0000] {processor.py:157} INFO - Started process (PID=11349) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:32:05.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:32:05.326+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:05.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:32:05.761+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:32:06.124+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:06.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:32:06.159+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:06.158+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:32:06.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.864 seconds
[2025-10-08T13:32:36.730+0000] {processor.py:157} INFO - Started process (PID=11661) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:32:36.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:32:36.733+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:36.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:32:37.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:32:37.182+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:37.182+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:32:37.213+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:37.213+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:32:37.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.511 seconds
[2025-10-08T13:33:07.338+0000] {processor.py:157} INFO - Started process (PID=11968) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:33:07.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:33:07.340+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:07.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:33:07.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:33:07.798+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:07.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:33:07.828+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:07.828+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:33:07.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.516 seconds
[2025-10-08T13:33:38.522+0000] {processor.py:157} INFO - Started process (PID=12273) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:33:38.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:33:38.524+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:38.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:33:39.054+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:33:39.540+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:39.539+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:33:39.572+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:39.572+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:33:39.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.074 seconds
[2025-10-08T13:34:10.489+0000] {processor.py:157} INFO - Started process (PID=12597) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:34:10.490+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:34:10.491+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:10.491+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:34:10.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:34:11.400+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:11.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:34:11.432+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:11.432+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:34:11.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.969 seconds
[2025-10-08T13:34:41.565+0000] {processor.py:157} INFO - Started process (PID=12915) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:34:41.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:34:41.569+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:41.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:34:42.015+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:34:42.040+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:42.040+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:34:42.182+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:42.182+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:34:42.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.647 seconds
[2025-10-08T13:35:12.530+0000] {processor.py:157} INFO - Started process (PID=13211) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:35:12.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:35:12.532+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:12.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:35:12.951+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:35:13.456+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:13.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:35:13.488+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:13.488+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:35:13.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.987 seconds
[2025-10-08T13:35:43.740+0000] {processor.py:157} INFO - Started process (PID=13534) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:35:43.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:35:43.742+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:43.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:35:44.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:35:44.457+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:44.457+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:35:44.604+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:44.604+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:35:44.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.895 seconds
[2025-10-08T13:44:17.200+0000] {processor.py:157} INFO - Started process (PID=13780) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:44:17.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:44:17.203+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:17.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:44:18.443+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:44:18.693+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:18.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:44:18.754+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:18.753+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:44:18.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.602 seconds
[2025-10-08T13:44:48.868+0000] {processor.py:157} INFO - Started process (PID=14096) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:44:48.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:44:48.870+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:48.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:44:49.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:44:49.428+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:49.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:44:49.457+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:49.457+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:44:49.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.612 seconds
[2025-10-08T13:45:19.777+0000] {processor.py:157} INFO - Started process (PID=14401) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:45:19.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:45:19.779+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:19.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:45:20.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:45:20.341+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:20.340+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:45:20.367+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:20.367+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:45:20.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.614 seconds
[2025-10-08T13:45:51.046+0000] {processor.py:157} INFO - Started process (PID=14708) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:45:51.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:45:51.047+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:51.047+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:45:51.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:45:51.619+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:51.619+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:45:51.651+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:51.650+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:45:51.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.634 seconds
[2025-10-08T13:46:22.497+0000] {processor.py:157} INFO - Started process (PID=15015) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:46:22.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:46:22.499+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:22.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:46:23.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:46:23.049+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:23.048+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:46:23.078+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:23.078+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:46:23.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.605 seconds
[2025-10-08T13:46:53.312+0000] {processor.py:157} INFO - Started process (PID=15322) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:46:53.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:46:53.314+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:46:53.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:46:53.922+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:46:53.949+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.949+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:46:53.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.660 seconds
[2025-10-08T13:47:24.411+0000] {processor.py:157} INFO - Started process (PID=15629) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:47:24.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:47:24.413+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:47:24.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:47:24.984+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:47:25.012+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:25.012+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:47:25.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.633 seconds
[2025-10-08T13:47:55.143+0000] {processor.py:157} INFO - Started process (PID=15928) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:47:55.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:47:55.145+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:47:55.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:47:55.868+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.867+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:47:55.895+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.895+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:47:55.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.777 seconds
[2025-10-08T13:48:26.119+0000] {processor.py:157} INFO - Started process (PID=16235) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:48:26.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:48:26.122+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:26.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:48:26.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:48:27.843+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:48:57.984+0000] {processor.py:157} INFO - Started process (PID=16555) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:48:57.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:48:57.985+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:57.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:48:58.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:48:58.525+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:58.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:48:58.552+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:58.552+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:48:58.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.592 seconds
[2025-10-08T13:49:28.648+0000] {processor.py:157} INFO - Started process (PID=16861) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:49:28.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:49:28.650+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:28.650+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:49:29.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:49:30.379+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:30.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:49:30.411+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:30.411+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:49:30.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.791 seconds
[2025-10-08T13:50:00.775+0000] {processor.py:157} INFO - Started process (PID=17171) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:50:00.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:50:00.778+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:00.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:50:01.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:50:01.338+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:01.338+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:50:01.364+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:01.364+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:50:01.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.613 seconds
[2025-10-08T13:50:32.202+0000] {processor.py:157} INFO - Started process (PID=17475) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:50:32.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:50:32.205+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:32.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:50:32.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:50:33.250+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:33.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:50:33.281+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:33.281+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:50:33.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.105 seconds
[2025-10-08T13:51:03.592+0000] {processor.py:157} INFO - Started process (PID=17794) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:51:03.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:51:03.594+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:03.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:51:04.116+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:51:04.150+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:04.149+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:51:04.190+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:04.190+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:51:04.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.635 seconds
[2025-10-08T13:51:34.278+0000] {processor.py:157} INFO - Started process (PID=18098) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:51:34.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:51:34.283+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:34.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:51:34.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:51:35.221+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:35.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:51:35.249+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:35.248+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:51:35.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.000 seconds
[2025-10-08T13:52:05.621+0000] {processor.py:157} INFO - Started process (PID=18405) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:52:05.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:52:05.624+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:05.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:52:06.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:52:06.163+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:06.163+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:52:06.191+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:06.191+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:52:06.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.594 seconds
[2025-10-08T13:52:36.419+0000] {processor.py:157} INFO - Started process (PID=18712) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:52:36.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:52:36.422+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:36.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:52:36.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:52:37.872+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:53:08.456+0000] {processor.py:157} INFO - Started process (PID=19029) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:53:08.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:53:08.458+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:08.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:53:08.977+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:53:09.494+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:09.494+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:53:09.521+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:09.521+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:53:09.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.089 seconds
[2025-10-08T13:53:39.930+0000] {processor.py:157} INFO - Started process (PID=19336) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:53:39.931+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:53:39.933+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:39.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:53:40.469+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:53:40.490+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:40.490+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:53:40.517+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:40.516+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:53:40.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.611 seconds
[2025-10-08T13:54:10.735+0000] {processor.py:157} INFO - Started process (PID=19643) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:54:10.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:54:10.737+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:10.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:54:11.269+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:54:11.292+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:11.291+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:54:11.320+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:11.320+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:54:11.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.612 seconds
[2025-10-08T13:54:41.398+0000] {processor.py:157} INFO - Started process (PID=19950) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:54:41.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:54:41.401+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:41.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:54:41.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:54:41.954+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:41.954+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:54:41.982+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:41.982+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:54:42.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.613 seconds
[2025-10-08T13:55:12.327+0000] {processor.py:157} INFO - Started process (PID=20257) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:55:12.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:55:12.329+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:12.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:55:12.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:55:12.774+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:12.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:55:12.804+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:12.804+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:55:12.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.501 seconds
[2025-10-08T13:55:42.893+0000] {processor.py:157} INFO - Started process (PID=20564) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:55:42.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:55:42.895+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:42.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:55:43.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:55:43.778+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:43.778+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:55:43.812+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:43.812+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:55:43.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.944 seconds
[2025-10-08T13:56:14.741+0000] {processor.py:157} INFO - Started process (PID=20881) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:56:14.742+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:56:14.743+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:14.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:56:15.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:56:15.600+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:15.599+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:56:15.631+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:15.631+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:56:15.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.916 seconds
[2025-10-08T13:56:45.970+0000] {processor.py:157} INFO - Started process (PID=21188) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:56:45.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:56:45.972+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:45.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:56:46.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:56:46.532+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:46.531+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:56:46.562+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:46.562+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:56:46.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.618 seconds
[2025-10-08T13:57:16.939+0000] {processor.py:157} INFO - Started process (PID=21500) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:57:16.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:57:16.941+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:16.941+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:57:17.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:57:17.442+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:17.442+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:57:17.473+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:17.473+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:57:17.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.559 seconds
[2025-10-08T13:57:47.556+0000] {processor.py:157} INFO - Started process (PID=21802) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:57:47.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:57:47.559+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:47.559+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:57:47.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:57:48.004+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:48.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:57:48.036+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:48.036+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:57:48.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.505 seconds
[2025-10-08T13:58:18.400+0000] {processor.py:157} INFO - Started process (PID=22109) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:58:18.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:58:18.402+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:18.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:58:18.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:58:19.223+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:19.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:58:19.256+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:19.255+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:58:19.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.994 seconds
[2025-10-08T13:58:49.679+0000] {processor.py:157} INFO - Started process (PID=22413) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:58:49.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:58:49.681+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:49.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:58:50.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:58:50.235+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:50.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:58:50.266+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:50.266+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:58:50.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.616 seconds
[2025-10-08T13:59:20.947+0000] {processor.py:157} INFO - Started process (PID=22725) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:59:20.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:59:20.949+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:20.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:59:21.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:59:21.401+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:21.400+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:59:21.540+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:21.540+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:59:21.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.624 seconds
[2025-10-08T13:59:51.665+0000] {processor.py:157} INFO - Started process (PID=23032) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:59:51.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T13:59:51.668+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:51.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:59:52.110+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T13:59:52.634+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:52.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:59:52.661+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:52.661+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T13:59:52.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.020 seconds
[2025-10-08T14:00:22.936+0000] {processor.py:157} INFO - Started process (PID=23344) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:00:22.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:00:22.939+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:22.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:00:23.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:00:23.965+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:23.964+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:00:23.997+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:23.997+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T14:00:24.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.089 seconds
[2025-10-08T14:00:54.474+0000] {processor.py:157} INFO - Started process (PID=23661) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:00:54.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:00:54.478+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:54.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:00:55.028+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:00:55.534+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:55.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:00:55.561+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:55.561+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T14:00:55.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.117 seconds
[2025-10-08T14:01:26.245+0000] {processor.py:157} INFO - Started process (PID=23973) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:01:26.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:01:26.247+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:26.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:01:26.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:01:26.815+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:26.814+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:01:26.842+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:26.842+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T14:01:26.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.621 seconds
[2025-10-08T14:01:57.081+0000] {processor.py:157} INFO - Started process (PID=24280) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:01:57.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:01:57.085+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:57.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:01:57.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:01:58.661+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T14:02:29.222+0000] {processor.py:157} INFO - Started process (PID=24602) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:02:29.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:02:29.224+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:29.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:02:29.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:02:29.757+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:29.757+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:02:29.785+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:29.785+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T14:02:29.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.585 seconds
[2025-10-08T14:03:00.293+0000] {processor.py:157} INFO - Started process (PID=24909) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:03:00.295+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:03:00.296+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:00.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:03:00.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:03:01.712+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T14:03:32.216+0000] {processor.py:157} INFO - Started process (PID=25231) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:03:32.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:03:32.218+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:32.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:03:32.742+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:03:33.267+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:33.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:03:33.297+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:33.297+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T14:03:33.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 1.105 seconds
[2025-10-08T14:04:03.488+0000] {processor.py:157} INFO - Started process (PID=25543) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:04:03.489+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:04:03.490+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:03.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:04:03.984+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:04:05.126+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T14:04:35.645+0000] {processor.py:157} INFO - Started process (PID=25850) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:04:35.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:04:35.647+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:35.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:04:36.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:04:36.766+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T14:14:56.983+0000] {processor.py:157} INFO - Started process (PID=26195) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:14:56.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:14:56.986+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:56.986+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:14:57.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:14:58.824+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T14:15:29.072+0000] {processor.py:157} INFO - Started process (PID=26504) to work on /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:15:29.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/superstore_dag.py for tasks to queue
[2025-10-08T14:15:29.075+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:29.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:15:29.554+0000] {processor.py:836} INFO - DAG(s) dict_keys(['superstore_etl_pipeline']) retrieved from /opt/airflow/dags/superstore_dag.py
[2025-10-08T14:15:29.586+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:29.585+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:15:29.613+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:29.613+0000] {dag.py:3490} INFO - Setting next_dagrun for superstore_etl_pipeline to 2025-10-08T00:00:00+00:00, run_after=2025-10-09T00:00:00+00:00
[2025-10-08T14:15:29.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/superstore_dag.py took 0.569 seconds
