[2025-10-08T12:30:44.393+0000] {processor.py:157} INFO - Started process (PID=177) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:30:44.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:30:44.399+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:44.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:30:46.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:30:46.572+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:46.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:30:46.618+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:46.618+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:30:46.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.281 seconds
[2025-10-08T12:31:16.898+0000] {processor.py:157} INFO - Started process (PID=495) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:31:16.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:31:16.901+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:16.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:31:17.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:31:17.851+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:17.850+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:31:17.886+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:17.886+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:31:17.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.021 seconds
[2025-10-08T12:31:48.312+0000] {processor.py:157} INFO - Started process (PID=809) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:31:48.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:31:48.314+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:48.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:31:48.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:31:48.957+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:48.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:31:48.995+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:48.995+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:31:49.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.714 seconds
[2025-10-08T12:32:19.430+0000] {processor.py:157} INFO - Started process (PID=1116) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:32:19.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:32:19.433+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:19.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:32:20.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:32:20.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:32:20.107+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.107+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:32:20.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.717 seconds
[2025-10-08T12:32:50.202+0000] {processor.py:157} INFO - Started process (PID=1423) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:32:50.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:32:50.205+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:32:50.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:32:50.854+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.853+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:32:50.906+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.905+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:32:50.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.745 seconds
[2025-10-08T12:33:21.383+0000] {processor.py:157} INFO - Started process (PID=1730) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:33:21.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:33:21.385+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:21.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:33:21.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:33:22.013+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:33:22.051+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.051+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:33:22.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.708 seconds
[2025-10-08T12:33:52.848+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:33:52.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:33:52.853+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:52.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:33:53.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:33:53.819+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:53.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:33:53.887+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:53.887+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:33:53.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.090 seconds
[2025-10-08T12:34:24.364+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:34:24.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:34:24.367+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:24.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:34:24.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:34:24.926+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:24.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:34:24.960+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:24.960+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:34:24.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.625 seconds
[2025-10-08T12:34:55.290+0000] {processor.py:157} INFO - Started process (PID=2651) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:34:55.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:34:55.294+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:55.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:34:56.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:34:56.494+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:56.494+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:34:56.531+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:56.531+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:34:56.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.300 seconds
[2025-10-08T12:35:27.018+0000] {processor.py:157} INFO - Started process (PID=2958) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:35:27.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:35:27.021+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:35:27.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:35:27.601+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.601+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:35:27.640+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.639+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:35:27.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.651 seconds
[2025-10-08T12:35:57.804+0000] {processor.py:157} INFO - Started process (PID=3275) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:35:57.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:35:57.807+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:57.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:35:58.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:35:58.629+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:58.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:35:58.748+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:58.747+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:35:58.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.014 seconds
[2025-10-08T12:36:29.079+0000] {processor.py:157} INFO - Started process (PID=3582) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:36:29.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:36:29.082+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:29.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:36:29.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:36:29.785+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:29.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:36:30.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:30.071+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:36:30.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.027 seconds
[2025-10-08T12:37:00.413+0000] {processor.py:157} INFO - Started process (PID=3889) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:37:00.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:37:00.417+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:00.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:37:00.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:37:01.089+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:01.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:37:01.124+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:01.124+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:37:01.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.742 seconds
[2025-10-08T12:37:31.584+0000] {processor.py:157} INFO - Started process (PID=4196) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:37:31.585+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:37:31.586+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:31.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:37:32.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:37:32.337+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:32.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:37:32.370+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:32.370+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:37:32.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.814 seconds
[2025-10-08T12:38:02.693+0000] {processor.py:157} INFO - Started process (PID=4511) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:38:02.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:38:02.695+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:02.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:38:03.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:38:03.416+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:03.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:38:03.450+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:03.450+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:38:03.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.795 seconds
[2025-10-08T12:38:34.252+0000] {processor.py:157} INFO - Started process (PID=4818) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:38:34.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:38:34.254+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:34.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:38:35.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:38:35.039+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:35.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:38:35.074+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:35.074+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:38:35.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.853 seconds
[2025-10-08T12:39:05.498+0000] {processor.py:157} INFO - Started process (PID=5127) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:39:05.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:39:05.501+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:05.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:39:06.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:39:06.685+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:06.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:39:06.715+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:06.715+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:39:06.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.243 seconds
[2025-10-08T12:39:37.201+0000] {processor.py:157} INFO - Started process (PID=5455) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:39:37.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:39:37.204+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:37.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:39:37.839+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:39:38.085+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:40:08.777+0000] {processor.py:157} INFO - Started process (PID=5762) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:40:08.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:40:08.779+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:08.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:40:09.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:40:10.214+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:10.214+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:40:10.242+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:10.242+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:40:10.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.489 seconds
[2025-10-08T12:40:40.592+0000] {processor.py:157} INFO - Started process (PID=6071) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:40:40.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:40:40.594+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:40.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:40:41.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:40:41.414+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:41.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:40:41.442+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:41.441+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:40:41.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.876 seconds
[2025-10-08T12:41:11.566+0000] {processor.py:157} INFO - Started process (PID=6390) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:41:11.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:41:11.568+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:11.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:41:12.126+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:41:12.148+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:12.147+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:41:12.174+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:12.174+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:41:12.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.638 seconds
[2025-10-08T12:41:42.272+0000] {processor.py:157} INFO - Started process (PID=6694) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:41:42.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:41:42.274+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:42.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:41:42.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:41:42.830+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:42.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:41:42.858+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:42.857+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:41:42.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.608 seconds
[2025-10-08T12:42:13.176+0000] {processor.py:157} INFO - Started process (PID=7001) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:42:13.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:42:13.179+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:13.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:42:13.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:42:13.820+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:13.820+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:42:13.852+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:13.852+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:42:13.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.703 seconds
[2025-10-08T12:42:43.994+0000] {processor.py:157} INFO - Started process (PID=7305) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:42:43.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:42:43.998+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:43.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:42:44.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:42:44.656+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:44.656+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:42:44.684+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:44.684+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:42:44.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.713 seconds
[2025-10-08T12:43:15.235+0000] {processor.py:157} INFO - Started process (PID=7602) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:43:15.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:43:15.238+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:15.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:43:15.953+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:43:16.121+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:16.120+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:43:16.148+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:16.148+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:43:16.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.947 seconds
[2025-10-08T12:43:46.801+0000] {processor.py:157} INFO - Started process (PID=7914) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:43:46.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:43:46.803+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:46.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:43:47.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:43:48.032+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:44:18.848+0000] {processor.py:157} INFO - Started process (PID=8221) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:44:18.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:44:18.850+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:18.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:44:19.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:44:19.624+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:19.623+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:44:19.662+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:19.662+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:44:19.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.850 seconds
[2025-10-08T12:44:49.957+0000] {processor.py:157} INFO - Started process (PID=8528) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:44:49.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:44:49.960+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:49.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:44:50.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:44:50.793+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:50.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:44:50.824+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:50.823+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:44:50.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.894 seconds
[2025-10-08T12:45:21.082+0000] {processor.py:157} INFO - Started process (PID=8842) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:45:21.083+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:45:21.084+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:21.084+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:45:21.619+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:45:21.641+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:21.640+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:45:21.670+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:21.670+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:45:21.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.613 seconds
[2025-10-08T12:45:52.173+0000] {processor.py:157} INFO - Started process (PID=9149) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:45:52.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:45:52.176+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:52.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:45:52.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:45:53.429+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:53.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:45:53.491+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:53.491+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:45:53.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.377 seconds
[2025-10-08T12:46:23.858+0000] {processor.py:157} INFO - Started process (PID=9456) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:46:23.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:46:23.860+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:23.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:46:24.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:46:24.402+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:24.401+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:46:24.439+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:24.439+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:46:24.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.614 seconds
[2025-10-08T12:46:54.810+0000] {processor.py:157} INFO - Started process (PID=9773) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:46:54.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:46:54.811+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:54.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:46:55.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:46:55.409+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:47:26.122+0000] {processor.py:157} INFO - Started process (PID=10080) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:47:26.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:47:26.124+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:26.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:47:26.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:47:26.603+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:26.603+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:47:26.640+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:26.640+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:47:26.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.547 seconds
[2025-10-08T12:47:56.793+0000] {processor.py:157} INFO - Started process (PID=10387) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:47:56.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:47:56.795+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:56.795+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:47:57.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:47:57.746+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:57.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:47:57.777+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:57.777+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:47:57.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.016 seconds
[2025-10-08T12:48:28.308+0000] {processor.py:157} INFO - Started process (PID=10694) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:48:28.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:48:28.310+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:28.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:48:28.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:48:29.370+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:48:59.970+0000] {processor.py:157} INFO - Started process (PID=11001) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:48:59.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:48:59.972+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:59.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:49:00.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:49:00.802+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:00.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:49:00.832+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:00.831+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:49:00.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.887 seconds
[2025-10-08T12:49:31.368+0000] {processor.py:157} INFO - Started process (PID=11308) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:49:31.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:49:31.371+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:31.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:49:31.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:49:31.881+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:31.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:49:31.913+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:31.913+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:49:31.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.572 seconds
[2025-10-08T12:50:02.170+0000] {processor.py:157} INFO - Started process (PID=11615) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:50:02.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:50:02.172+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:02.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:50:02.614+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:50:03.082+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:50:34.056+0000] {processor.py:157} INFO - Started process (PID=11922) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:50:34.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:50:34.058+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:34.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:50:34.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:50:35.371+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:51:05.532+0000] {processor.py:157} INFO - Started process (PID=12239) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:51:05.533+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:51:05.534+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:05.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:51:06.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:51:06.176+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:06.175+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:51:06.331+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:06.330+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:51:06.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.834 seconds
[2025-10-08T12:51:36.739+0000] {processor.py:157} INFO - Started process (PID=12555) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:51:36.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:51:36.741+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:36.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:51:37.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:51:38.035+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:38.034+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:51:38.070+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:38.070+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:51:38.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.366 seconds
[2025-10-08T12:52:08.991+0000] {processor.py:157} INFO - Started process (PID=12872) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:52:08.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:52:08.993+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:08.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:52:09.460+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:52:09.488+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:09.488+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:52:09.642+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:09.642+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:52:09.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.686 seconds
[2025-10-08T12:52:39.902+0000] {processor.py:157} INFO - Started process (PID=13179) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:52:39.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:52:39.904+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:39.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:52:40.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:52:41.064+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:41.063+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:52:41.103+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:41.103+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:52:41.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.234 seconds
[2025-10-08T12:53:11.713+0000] {processor.py:157} INFO - Started process (PID=13496) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:53:11.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:53:11.716+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:11.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:53:12.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:53:13.373+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:53:43.486+0000] {processor.py:157} INFO - Started process (PID=13808) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:53:43.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:53:43.489+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:43.488+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:53:43.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:53:44.551+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:44.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:53:44.583+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:44.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:53:44.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.122 seconds
[2025-10-08T12:54:15.201+0000] {processor.py:157} INFO - Started process (PID=14123) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:54:15.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:54:15.203+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:15.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:54:15.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:54:16.019+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:54:46.098+0000] {processor.py:157} INFO - Started process (PID=14442) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:54:46.099+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:54:46.100+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:46.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:54:46.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:54:47.058+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:47.058+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:54:47.088+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:47.088+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:54:47.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.022 seconds
[2025-10-08T12:55:17.643+0000] {processor.py:157} INFO - Started process (PID=14754) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:55:17.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:55:17.644+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:17.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:55:18.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:55:18.302+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:18.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:55:18.370+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:18.370+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:55:18.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.766 seconds
[2025-10-08T12:55:48.498+0000] {processor.py:157} INFO - Started process (PID=15061) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:55:48.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:55:48.501+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:48.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:55:49.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:55:49.270+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:49.269+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:55:49.310+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:49.310+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:55:49.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.851 seconds
[2025-10-08T12:56:19.484+0000] {processor.py:157} INFO - Started process (PID=15378) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:56:19.488+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:56:19.489+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:19.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:56:20.182+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:56:20.211+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:20.211+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:56:20.247+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:20.246+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:56:20.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.796 seconds
[2025-10-08T12:56:50.773+0000] {processor.py:157} INFO - Started process (PID=15685) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:56:50.774+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:56:50.776+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:50.776+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:56:51.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:56:51.835+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:57:22.064+0000] {processor.py:157} INFO - Started process (PID=15992) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:57:22.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:57:22.066+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:22.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:57:22.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:57:23.126+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:57:53.905+0000] {processor.py:157} INFO - Started process (PID=16306) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:57:53.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:57:53.907+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:53.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:57:54.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:57:55.005+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:58:25.362+0000] {processor.py:157} INFO - Started process (PID=16613) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:58:25.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:58:25.367+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:25.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:58:26.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:58:26.175+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:26.174+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:58:26.205+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:26.204+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:58:26.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.874 seconds
[2025-10-08T12:58:56.760+0000] {processor.py:157} INFO - Started process (PID=16925) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:58:56.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:58:56.763+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:56.763+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:58:57.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:58:57.739+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:57.737+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:58:57.769+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:57.768+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:58:57.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.037 seconds
[2025-10-08T12:59:27.993+0000] {processor.py:157} INFO - Started process (PID=17232) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:59:27.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:59:27.996+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:27.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:59:28.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:59:28.806+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:28.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:59:28.839+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:28.838+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:59:28.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.874 seconds
[2025-10-08T12:59:59.083+0000] {processor.py:157} INFO - Started process (PID=17549) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:59:59.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T12:59:59.086+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:59.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:59:59.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T12:59:59.847+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:59.847+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:59:59.875+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:59.875+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T12:59:59.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.817 seconds
[2025-10-08T13:00:29.976+0000] {processor.py:157} INFO - Started process (PID=17851) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:00:29.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:00:29.979+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:29.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:00:30.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:00:31.528+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:01:01.818+0000] {processor.py:157} INFO - Started process (PID=18163) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:01:01.820+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:01:01.820+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:01.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:01:02.393+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:01:02.533+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:02.532+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:02.568+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:02.568+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:01:02.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.778 seconds
[2025-10-08T13:01:32.633+0000] {processor.py:157} INFO - Started process (PID=18483) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:01:32.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:01:32.636+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:32.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:01:33.374+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:01:33.585+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:33.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:33.623+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:33.622+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:01:33.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.020 seconds
[2025-10-08T13:02:03.760+0000] {processor.py:157} INFO - Started process (PID=18790) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:02:03.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:02:03.762+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:03.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:02:04.399+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:02:04.916+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:02:35.244+0000] {processor.py:157} INFO - Started process (PID=19102) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:02:35.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:02:35.246+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:35.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:02:35.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:02:36.868+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:36.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:02:36.903+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:36.903+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:02:36.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.686 seconds
[2025-10-08T13:04:36.472+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:04:36.473+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:04:36.474+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:36.474+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:04:37.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:04:37.570+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:04:37.614+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.614+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:04:37.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.186 seconds
[2025-10-08T13:05:07.799+0000] {processor.py:157} INFO - Started process (PID=488) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:05:07.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:05:07.811+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:07.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:05:08.463+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:05:08.486+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:08.486+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:05:08.518+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:08.518+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:05:08.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.752 seconds
[2025-10-08T13:05:39.061+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:05:39.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:05:39.064+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:39.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:05:39.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:05:39.793+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:39.793+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:05:39.839+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:39.838+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:05:39.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.816 seconds
[2025-10-08T13:06:10.142+0000] {processor.py:157} INFO - Started process (PID=1109) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:06:10.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:06:10.145+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:10.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:06:10.949+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:06:11.004+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:11.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:06:11.061+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:11.061+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:06:11.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.960 seconds
[2025-10-08T13:06:41.277+0000] {processor.py:157} INFO - Started process (PID=1413) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:06:41.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:06:41.280+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:41.280+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:06:42.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:06:42.137+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:42.136+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:06:42.196+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:42.195+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:06:42.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.974 seconds
[2025-10-08T13:07:50.066+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:07:50.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:07:50.069+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:50.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:07:51.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:07:51.321+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:51.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:07:51.362+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:51.362+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:07:51.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.337 seconds
[2025-10-08T13:08:21.777+0000] {processor.py:157} INFO - Started process (PID=488) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:08:21.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:08:21.780+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:21.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:08:22.545+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:08:22.576+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:22.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:08:22.613+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:22.612+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:08:22.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.869 seconds
[2025-10-08T13:08:52.913+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:08:52.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:08:52.916+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:52.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:08:53.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:08:53.744+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:53.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:08:53.815+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:53.814+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:08:53.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.949 seconds
[2025-10-08T13:09:24.232+0000] {processor.py:157} INFO - Started process (PID=1099) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:09:24.234+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:09:24.235+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:24.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:09:24.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:09:24.997+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:24.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:09:25.053+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:25.053+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:09:25.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.866 seconds
[2025-10-08T13:09:55.328+0000] {processor.py:157} INFO - Started process (PID=1406) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:09:55.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:09:55.331+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:55.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:09:55.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:09:55.770+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:55.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:09:55.800+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:55.800+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:09:55.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.500 seconds
[2025-10-08T13:10:26.555+0000] {processor.py:157} INFO - Started process (PID=1713) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:10:26.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:10:26.557+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:26.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:10:26.998+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:10:27.122+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:27.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:10:27.153+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:27.153+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:10:27.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.630 seconds
[2025-10-08T13:10:57.603+0000] {processor.py:157} INFO - Started process (PID=2020) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:10:57.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:10:57.606+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:57.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:10:58.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:10:58.936+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:11:28.999+0000] {processor.py:157} INFO - Started process (PID=2332) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:11:29.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:11:29.001+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:29.001+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:11:29.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:11:29.456+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:29.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:11:29.487+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:29.487+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:11:29.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.513 seconds
[2025-10-08T13:11:59.542+0000] {processor.py:157} INFO - Started process (PID=2639) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:11:59.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:11:59.544+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:59.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:17:27.531+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:27.531+0000] {timeout.py:68} ERROR - Process timed out, PID: 2639
[2025-10-08T13:17:28.761+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:27.598+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/mock_logistic_dag2.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/mock_logistic_dag2.py", line 7, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/__init__.py", line 11, in <module>
    __import__(dependency)
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/__init__.py", line 150, in <module>
    from . import core
  File "/home/airflow/.local/lib/python3.7/site-packages/numpy/core/__init__.py", line 70, in <module>
    from . import numerictypes as nt
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 857, in get_code
  File "<frozen importlib._bootstrap_external>", line 525, in _compile_bytecode
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/mock_logistic_dag2.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 2639
[2025-10-08T13:17:28.804+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:17:29.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 329.972 seconds
[2025-10-08T13:18:00.072+0000] {processor.py:157} INFO - Started process (PID=2952) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:18:00.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:18:00.074+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:00.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:18:00.480+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:18:00.576+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:00.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:18:00.607+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:00.607+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:18:00.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.678 seconds
[2025-10-08T13:18:31.326+0000] {processor.py:157} INFO - Started process (PID=3259) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:18:31.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:18:31.329+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:31.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:18:31.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:18:32.279+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:32.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:18:32.318+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:32.318+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:18:32.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.024 seconds
[2025-10-08T13:19:02.416+0000] {processor.py:157} INFO - Started process (PID=3575) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:19:02.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:19:02.419+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:02.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:19:02.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:19:03.011+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:03.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:19:03.156+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:03.155+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:19:03.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.773 seconds
[2025-10-08T13:19:33.586+0000] {processor.py:157} INFO - Started process (PID=3882) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:19:33.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:19:33.588+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:33.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:19:33.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:19:34.457+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:34.456+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:19:34.494+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:34.494+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:19:34.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.936 seconds
[2025-10-08T13:20:04.660+0000] {processor.py:157} INFO - Started process (PID=4189) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:20:04.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:20:04.663+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:04.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:20:05.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:20:05.223+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:05.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:20:05.254+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:05.254+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:20:05.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.619 seconds
[2025-10-08T13:20:35.808+0000] {processor.py:157} INFO - Started process (PID=4496) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:20:35.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:20:35.810+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:35.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:20:36.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:20:37.203+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:37.202+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:20:37.235+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:37.235+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:20:37.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.454 seconds
[2025-10-08T13:21:07.365+0000] {processor.py:157} INFO - Started process (PID=4803) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:21:07.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:21:07.367+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:07.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:21:07.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:21:07.933+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:07.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:21:07.960+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:07.960+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:21:07.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.620 seconds
[2025-10-08T13:21:38.322+0000] {processor.py:157} INFO - Started process (PID=5110) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:21:38.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:21:38.324+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:38.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:21:38.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:21:38.952+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:38.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:21:38.978+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:38.978+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:21:38.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.679 seconds
[2025-10-08T13:22:09.364+0000] {processor.py:157} INFO - Started process (PID=5417) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:22:09.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:22:09.366+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:09.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:22:09.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:22:09.992+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:09.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:22:10.020+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:10.019+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:22:10.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.679 seconds
[2025-10-08T13:22:40.317+0000] {processor.py:157} INFO - Started process (PID=5724) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:22:40.319+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:22:40.320+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:40.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:22:40.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:22:40.917+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:40.916+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:22:40.944+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:40.944+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:22:40.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.652 seconds
[2025-10-08T13:23:11.010+0000] {processor.py:157} INFO - Started process (PID=6031) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:23:11.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:23:11.012+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:11.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:23:11.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:23:11.840+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:23:42.191+0000] {processor.py:157} INFO - Started process (PID=6338) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:23:42.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:23:42.193+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:42.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:23:42.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:23:42.871+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:42.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:23:42.899+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:42.899+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:23:42.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.733 seconds
[2025-10-08T13:24:13.005+0000] {processor.py:157} INFO - Started process (PID=6654) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:24:13.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:24:13.007+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:13.007+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:24:13.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:24:14.473+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:24:44.514+0000] {processor.py:157} INFO - Started process (PID=6966) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:24:44.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:24:44.516+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:44.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:24:45.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:24:45.829+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:25:16.714+0000] {processor.py:157} INFO - Started process (PID=7273) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:25:16.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:25:16.717+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:16.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:25:17.249+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:25:17.346+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:17.345+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:25:17.375+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:17.375+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:25:17.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.685 seconds
[2025-10-08T13:25:47.442+0000] {processor.py:157} INFO - Started process (PID=7580) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:25:47.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:25:47.444+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:47.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:25:47.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:25:48.750+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:26:19.704+0000] {processor.py:157} INFO - Started process (PID=7887) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:26:19.706+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:26:19.706+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:19.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:26:20.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:26:20.275+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:20.274+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:26:20.303+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:20.303+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:26:20.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.622 seconds
[2025-10-08T13:26:50.736+0000] {processor.py:157} INFO - Started process (PID=8199) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:26:50.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:26:50.737+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:50.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:26:51.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:26:51.612+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:51.612+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:26:51.639+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:51.639+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:26:51.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.929 seconds
[2025-10-08T13:27:21.918+0000] {processor.py:157} INFO - Started process (PID=8506) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:27:21.919+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:27:21.920+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:21.920+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:27:22.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:27:22.458+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:22.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:27:22.485+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:22.485+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:27:22.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.591 seconds
[2025-10-08T13:27:52.975+0000] {processor.py:157} INFO - Started process (PID=8813) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:27:52.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:27:52.977+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:52.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:27:53.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:27:53.526+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:53.525+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:27:53.553+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:53.552+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:27:53.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.603 seconds
[2025-10-08T13:28:24.142+0000] {processor.py:157} INFO - Started process (PID=9120) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:28:24.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:28:24.144+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:24.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:28:24.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:28:24.687+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:24.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:28:24.714+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:24.714+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:28:24.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.595 seconds
[2025-10-08T13:28:55.259+0000] {processor.py:157} INFO - Started process (PID=9427) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:28:55.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:28:55.261+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:55.261+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:28:55.859+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:28:55.881+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:55.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:28:55.909+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:55.909+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:28:55.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.674 seconds
[2025-10-08T13:29:26.107+0000] {processor.py:157} INFO - Started process (PID=9743) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:29:26.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:29:26.109+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:26.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:29:26.614+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:29:26.800+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:26.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:29:26.826+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:26.826+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:29:26.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.744 seconds
[2025-10-08T13:29:57.416+0000] {processor.py:157} INFO - Started process (PID=10047) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:29:57.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:29:57.418+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:57.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:29:57.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:29:58.466+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:58.465+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:29:58.570+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:58.570+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:29:58.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.182 seconds
[2025-10-08T13:30:28.670+0000] {processor.py:157} INFO - Started process (PID=10354) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:30:28.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:30:28.672+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:28.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:30:29.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:30:30.579+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:31:01.231+0000] {processor.py:157} INFO - Started process (PID=10688) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:31:01.233+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:31:01.234+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:01.233+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:31:01.715+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:31:01.740+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:01.740+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:31:01.770+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:01.770+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:31:01.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.564 seconds
[2025-10-08T13:31:32.004+0000] {processor.py:157} INFO - Started process (PID=10998) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:31:32.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:31:32.006+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:32.006+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:31:32.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:31:32.499+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:32.498+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:31:32.550+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:32.550+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:31:32.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.576 seconds
[2025-10-08T13:32:03.067+0000] {processor.py:157} INFO - Started process (PID=11314) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:32:03.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:32:03.069+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:03.068+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:32:03.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:32:04.085+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:04.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:32:04.128+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:04.128+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:32:04.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.090 seconds
[2025-10-08T13:32:34.380+0000] {processor.py:157} INFO - Started process (PID=11631) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:32:34.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:32:34.382+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:34.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:32:34.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:32:35.053+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:35.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:32:35.083+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:35.083+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:32:35.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.727 seconds
[2025-10-08T13:33:05.634+0000] {processor.py:157} INFO - Started process (PID=11938) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:33:05.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:33:05.636+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:05.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:33:06.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:33:06.083+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:06.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:33:06.115+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:06.114+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:33:06.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.506 seconds
[2025-10-08T13:33:36.714+0000] {processor.py:157} INFO - Started process (PID=12237) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:33:36.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:33:36.716+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:36.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:33:37.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:33:37.414+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:37.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:33:37.446+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:37.446+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:33:37.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.758 seconds
[2025-10-08T13:34:07.824+0000] {processor.py:157} INFO - Started process (PID=12554) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:34:07.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:34:07.825+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:07.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:34:08.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:34:08.255+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:08.254+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:34:08.285+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:08.285+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:34:08.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.485 seconds
[2025-10-08T13:34:38.385+0000] {processor.py:157} INFO - Started process (PID=12851) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:34:38.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:34:38.387+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:38.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:34:38.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:34:38.881+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:38.881+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:34:38.930+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:38.930+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:34:38.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.584 seconds
[2025-10-08T13:35:09.055+0000] {processor.py:157} INFO - Started process (PID=13164) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:35:09.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:35:09.059+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:09.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:35:09.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:35:10.424+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:35:40.794+0000] {processor.py:157} INFO - Started process (PID=13475) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:35:40.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:35:40.798+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:40.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:35:41.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:35:41.261+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:41.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:35:41.292+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:41.291+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:35:41.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.524 seconds
[2025-10-08T13:44:14.860+0000] {processor.py:157} INFO - Started process (PID=13749) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:44:14.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:44:14.870+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:14.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:44:16.383+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:44:16.735+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:16.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:44:17.036+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:17.035+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:44:17.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 2.249 seconds
[2025-10-08T13:44:47.985+0000] {processor.py:157} INFO - Started process (PID=14073) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:44:47.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:44:47.988+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:47.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:44:48.477+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:44:48.718+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:48.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:44:48.756+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:48.756+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:44:48.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.807 seconds
[2025-10-08T13:45:19.081+0000] {processor.py:157} INFO - Started process (PID=14380) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:45:19.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:45:19.082+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:19.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:45:19.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:45:19.696+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:19.696+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:45:19.724+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:19.724+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:45:19.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.668 seconds
[2025-10-08T13:45:50.323+0000] {processor.py:157} INFO - Started process (PID=14687) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:45:50.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:45:50.330+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:50.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:45:50.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:45:51.518+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:46:21.843+0000] {processor.py:157} INFO - Started process (PID=15002) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:46:21.844+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:46:21.845+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:21.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:46:22.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:46:22.416+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:22.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:46:22.444+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:22.444+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:46:22.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.627 seconds
[2025-10-08T13:46:52.591+0000] {processor.py:157} INFO - Started process (PID=15298) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:46:52.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:46:52.594+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:52.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:46:53.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:46:53.206+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.205+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:46:53.234+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.233+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:46:53.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.672 seconds
[2025-10-08T13:47:23.663+0000] {processor.py:157} INFO - Started process (PID=15605) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:47:23.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:47:23.665+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:23.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:47:24.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:47:24.328+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.327+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:47:24.356+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.356+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:47:24.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.718 seconds
[2025-10-08T13:47:54.511+0000] {processor.py:157} INFO - Started process (PID=15912) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:47:54.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:47:54.512+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:54.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:47:55.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:47:55.054+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:47:55.081+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.081+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:47:55.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.596 seconds
[2025-10-08T13:48:25.483+0000] {processor.py:157} INFO - Started process (PID=16219) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:48:25.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:48:25.485+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:25.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:48:26.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:48:26.032+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:26.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:48:26.059+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:26.059+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:48:26.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.599 seconds
[2025-10-08T13:48:56.293+0000] {processor.py:157} INFO - Started process (PID=16526) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:48:56.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:48:56.295+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:56.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:48:56.826+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:48:56.851+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:56.851+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:48:56.913+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:56.913+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:48:56.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.644 seconds
[2025-10-08T13:49:27.067+0000] {processor.py:157} INFO - Started process (PID=16843) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:49:27.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:49:27.069+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:27.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:49:27.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:49:27.621+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:27.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:49:27.648+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:27.647+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:49:27.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.604 seconds
[2025-10-08T13:49:57.764+0000] {processor.py:157} INFO - Started process (PID=17150) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:49:57.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:49:57.766+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:57.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:49:58.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:49:58.658+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:58.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:49:58.686+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:58.686+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:49:58.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.948 seconds
[2025-10-08T13:50:29.117+0000] {processor.py:157} INFO - Started process (PID=17462) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:50:29.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:50:29.120+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:29.119+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:50:29.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:50:30.180+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:30.180+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:50:30.208+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:30.207+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:50:30.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.115 seconds
[2025-10-08T13:51:00.380+0000] {processor.py:157} INFO - Started process (PID=17768) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:51:00.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:51:00.382+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:00.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:51:00.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:51:01.228+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:01.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:51:01.259+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:01.259+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:51:01.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.906 seconds
[2025-10-08T13:51:31.571+0000] {processor.py:157} INFO - Started process (PID=18075) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:51:31.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:51:31.573+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:31.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:51:32.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:51:32.561+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:32.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:51:32.591+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:32.590+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:51:32.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.045 seconds
[2025-10-08T13:52:03.148+0000] {processor.py:157} INFO - Started process (PID=18382) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:52:03.150+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:52:03.150+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:03.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:52:03.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:52:03.697+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:03.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:52:03.724+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:03.724+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:52:03.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.598 seconds
[2025-10-08T13:52:34.484+0000] {processor.py:157} INFO - Started process (PID=18694) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:52:34.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:52:34.486+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:34.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:52:35.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:52:35.324+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:35.323+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:52:35.352+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:35.352+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:52:35.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.892 seconds
[2025-10-08T13:53:05.513+0000] {processor.py:157} INFO - Started process (PID=19001) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:53:05.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:53:05.515+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:05.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:53:06.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:53:06.070+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:06.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:53:06.097+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:06.097+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:53:06.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.609 seconds
[2025-10-08T13:53:36.492+0000] {processor.py:157} INFO - Started process (PID=19313) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:53:36.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:53:36.494+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:36.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:53:37.044+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:53:37.357+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:37.356+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:53:37.386+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:37.386+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:53:37.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.919 seconds
[2025-10-08T13:54:08.188+0000] {processor.py:157} INFO - Started process (PID=19620) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:54:08.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:54:08.190+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:08.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:54:08.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:54:08.714+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:08.713+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:54:08.741+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:08.741+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:54:08.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.577 seconds
[2025-10-08T13:54:38.835+0000] {processor.py:157} INFO - Started process (PID=19927) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:54:38.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:54:38.837+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:38.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:54:39.388+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:54:39.422+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:39.422+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:54:39.465+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:39.465+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:54:39.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.652 seconds
[2025-10-08T13:55:09.689+0000] {processor.py:157} INFO - Started process (PID=20234) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:55:09.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:55:09.691+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:09.691+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:55:10.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:55:10.649+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:10.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:55:10.681+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:10.680+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:55:10.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.019 seconds
[2025-10-08T13:55:40.865+0000] {processor.py:157} INFO - Started process (PID=20551) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:55:40.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:55:40.867+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:40.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:55:41.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:55:41.289+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:41.288+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:55:41.320+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:41.320+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:55:41.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.480 seconds
[2025-10-08T13:56:11.383+0000] {processor.py:157} INFO - Started process (PID=20858) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:56:11.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:56:11.385+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:11.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:56:11.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:56:12.688+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:56:43.187+0000] {processor.py:157} INFO - Started process (PID=21165) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:56:43.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:56:43.190+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:43.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:56:43.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:56:43.622+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:43.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:56:43.653+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:43.653+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:56:43.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.491 seconds
[2025-10-08T13:57:13.831+0000] {processor.py:157} INFO - Started process (PID=21472) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:57:13.833+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:57:13.834+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:13.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:57:14.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:57:14.818+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:14.817+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:57:14.849+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:14.848+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:57:14.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.049 seconds
[2025-10-08T13:57:44.993+0000] {processor.py:157} INFO - Started process (PID=21779) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:57:44.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:57:44.996+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:44.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:57:45.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:57:45.437+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:45.437+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:57:45.468+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:45.467+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:57:45.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.500 seconds
[2025-10-08T13:58:15.842+0000] {processor.py:157} INFO - Started process (PID=22086) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:58:15.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:58:15.844+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:15.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:58:16.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:58:16.296+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:16.295+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:58:16.324+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:16.324+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:58:16.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.506 seconds
[2025-10-08T13:58:46.453+0000] {processor.py:157} INFO - Started process (PID=22393) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:58:46.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:58:46.455+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:46.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:58:46.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:58:46.914+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:46.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:58:47.059+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:47.058+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:58:47.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.635 seconds
[2025-10-08T13:59:17.633+0000] {processor.py:157} INFO - Started process (PID=22707) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:59:17.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:59:17.635+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:17.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:59:18.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:59:18.522+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:18.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:59:18.554+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:18.554+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:59:18.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.945 seconds
[2025-10-08T13:59:49.009+0000] {processor.py:157} INFO - Started process (PID=23014) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:59:49.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T13:59:49.011+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:49.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:59:49.420+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T13:59:49.446+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:49.445+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:59:49.583+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:49.583+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T13:59:49.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.600 seconds
[2025-10-08T14:00:19.761+0000] {processor.py:157} INFO - Started process (PID=23321) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:00:19.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:00:19.762+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:19.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:00:20.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:00:20.325+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:20.325+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:00:20.352+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:20.352+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:00:20.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.614 seconds
[2025-10-08T14:00:50.482+0000] {processor.py:157} INFO - Started process (PID=23628) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:00:50.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:00:50.485+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:50.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:00:51.009+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:00:51.091+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:51.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:00:51.119+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:51.119+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:00:51.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.664 seconds
[2025-10-08T14:01:21.234+0000] {processor.py:157} INFO - Started process (PID=23935) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:01:21.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:01:21.236+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:21.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:01:21.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:01:22.104+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:22.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:01:22.134+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:22.134+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:01:22.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.930 seconds
[2025-10-08T14:01:52.338+0000] {processor.py:157} INFO - Started process (PID=24242) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:01:52.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:01:52.341+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:52.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:01:52.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:01:53.043+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:53.043+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:01:53.076+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:53.075+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:01:53.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.762 seconds
[2025-10-08T14:02:23.269+0000] {processor.py:157} INFO - Started process (PID=24549) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:02:23.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:02:23.272+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:23.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:02:23.829+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:02:24.131+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:24.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:02:24.159+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:24.158+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:02:24.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.915 seconds
[2025-10-08T14:02:54.795+0000] {processor.py:157} INFO - Started process (PID=24856) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:02:54.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:02:54.798+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:54.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:02:55.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:02:55.361+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:55.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:02:55.391+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:55.391+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:02:55.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.623 seconds
[2025-10-08T14:03:25.550+0000] {processor.py:157} INFO - Started process (PID=25163) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:03:25.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:03:25.553+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:25.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:03:26.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:03:26.465+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:26.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:03:26.496+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:26.495+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:03:26.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.971 seconds
[2025-10-08T14:03:56.909+0000] {processor.py:157} INFO - Started process (PID=25478) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:03:56.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:03:56.910+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:56.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:03:57.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:03:57.486+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:57.486+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:03:57.513+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:57.513+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:03:57.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.628 seconds
[2025-10-08T14:04:28.130+0000] {processor.py:157} INFO - Started process (PID=25787) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:04:28.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:04:28.132+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:28.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:04:28.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:04:28.698+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:28.698+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:04:28.725+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:28.725+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:04:28.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.621 seconds
[2025-10-08T14:04:58.793+0000] {processor.py:157} INFO - Started process (PID=26094) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:04:58.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:04:58.795+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:58.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:04:59.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:04:59.338+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:59.337+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:04:59.365+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:59.365+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:04:59.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.596 seconds
[2025-10-08T14:14:55.338+0000] {processor.py:157} INFO - Started process (PID=26174) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:14:55.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:14:55.345+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:55.344+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:14:56.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:14:56.809+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:56.808+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:14:56.862+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:56.862+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:14:56.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 1.570 seconds
[2025-10-08T14:15:27.400+0000] {processor.py:157} INFO - Started process (PID=26481) to work on /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:15:27.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistic_dag2.py for tasks to queue
[2025-10-08T14:15:27.402+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:27.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:15:27.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_v4']) retrieved from /opt/airflow/dags/mock_logistic_dag2.py
[2025-10-08T14:15:27.974+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:27.973+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:15:28.004+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:28.004+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_v4 to 2025-10-08T10:00:00+00:00, run_after=2025-10-09T10:00:00+00:00
[2025-10-08T14:15:28.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistic_dag2.py took 0.633 seconds
