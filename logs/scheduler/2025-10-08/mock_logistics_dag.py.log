[2025-10-08T12:30:44.412+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:30:44.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:30:44.418+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:44.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:30:46.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:30:46.576+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:46.576+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:30:46.619+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:30:46.619+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:30:46.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.253 seconds
[2025-10-08T12:31:16.908+0000] {processor.py:157} INFO - Started process (PID=498) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:31:16.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:31:16.911+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:16.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:31:17.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:31:17.857+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:17.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:31:17.894+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:17.894+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:31:17.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.014 seconds
[2025-10-08T12:31:48.324+0000] {processor.py:157} INFO - Started process (PID=812) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:31:48.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:31:48.327+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:48.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:31:48.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:31:48.975+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:48.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:31:49.019+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:31:49.019+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:31:49.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.729 seconds
[2025-10-08T12:32:19.445+0000] {processor.py:157} INFO - Started process (PID=1119) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:32:19.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:32:19.449+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:19.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:32:20.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:32:20.098+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:32:20.135+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:20.135+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:32:20.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.725 seconds
[2025-10-08T12:32:50.213+0000] {processor.py:157} INFO - Started process (PID=1426) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:32:50.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:32:50.218+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:32:50.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:32:50.862+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:32:50.911+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:32:50.911+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:32:50.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.732 seconds
[2025-10-08T12:33:21.390+0000] {processor.py:157} INFO - Started process (PID=1733) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:33:21.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:33:21.398+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:21.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:33:21.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:33:22.032+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:33:22.074+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:22.074+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:33:22.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.713 seconds
[2025-10-08T12:33:52.863+0000] {processor.py:157} INFO - Started process (PID=2040) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:33:52.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:33:52.869+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:52.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:33:53.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:33:53.920+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:53.919+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:33:54.004+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:33:54.004+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:33:54.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.212 seconds
[2025-10-08T12:34:24.375+0000] {processor.py:157} INFO - Started process (PID=2347) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:34:24.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:34:24.381+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:24.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:34:24.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:34:24.936+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:24.936+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:34:24.970+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:24.970+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:34:24.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.627 seconds
[2025-10-08T12:34:55.381+0000] {processor.py:157} INFO - Started process (PID=2654) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:34:55.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:34:55.389+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:55.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:34:56.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:34:56.494+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:56.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:34:56.532+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:34:56.532+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:34:56.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.196 seconds
[2025-10-08T12:35:27.029+0000] {processor.py:157} INFO - Started process (PID=2961) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:35:27.030+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:35:27.031+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.031+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:35:27.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:35:27.625+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:35:27.663+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:27.663+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:35:27.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.669 seconds
[2025-10-08T12:35:57.817+0000] {processor.py:157} INFO - Started process (PID=3278) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:35:57.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:35:57.819+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:57.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:35:58.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:35:58.628+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:58.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:35:58.789+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:35:58.789+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:35:58.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.037 seconds
[2025-10-08T12:36:29.091+0000] {processor.py:157} INFO - Started process (PID=3585) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:36:29.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:36:29.098+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:29.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:36:29.747+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:36:30.118+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:30.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:36:30.333+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:36:30.333+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:36:30.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.282 seconds
[2025-10-08T12:37:00.423+0000] {processor.py:157} INFO - Started process (PID=3892) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:37:00.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:37:00.426+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:00.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:37:00.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:37:01.392+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:01.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:37:01.430+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:01.429+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:37:01.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.218 seconds
[2025-10-08T12:37:31.913+0000] {processor.py:157} INFO - Started process (PID=4217) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:37:31.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:37:31.915+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:31.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:37:32.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:37:32.598+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:32.597+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:37:32.628+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:37:32.628+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:37:32.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.740 seconds
[2025-10-08T12:38:02.916+0000] {processor.py:157} INFO - Started process (PID=4523) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:38:02.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:38:02.918+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:02.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:38:03.662+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:38:03.693+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:03.692+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:38:03.736+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:03.736+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:38:03.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.857 seconds
[2025-10-08T12:38:34.385+0000] {processor.py:157} INFO - Started process (PID=4830) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:38:34.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:38:34.387+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:34.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:38:35.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:38:35.122+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:35.120+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:38:35.189+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:38:35.189+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:38:35.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.849 seconds
[2025-10-08T12:39:05.514+0000] {processor.py:157} INFO - Started process (PID=5130) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:39:05.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:39:05.516+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:05.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:39:06.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:39:06.354+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:06.353+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:39:06.388+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:06.388+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:39:06.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.900 seconds
[2025-10-08T12:39:36.530+0000] {processor.py:157} INFO - Started process (PID=5434) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:39:36.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:39:36.532+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:39:36.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:39:37.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:39:37.492+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:40:07.762+0000] {processor.py:157} INFO - Started process (PID=5746) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:40:07.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:40:07.765+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:07.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:40:08.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:40:09.149+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:09.149+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:40:09.191+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:09.191+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:40:09.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.463 seconds
[2025-10-08T12:40:39.907+0000] {processor.py:157} INFO - Started process (PID=6058) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:40:39.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:40:39.909+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:39.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:40:40.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:40:40.509+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:40.509+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:40:40.538+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:40:40.538+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:40:40.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.654 seconds
[2025-10-08T12:41:10.635+0000] {processor.py:157} INFO - Started process (PID=6374) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:41:10.637+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:41:10.640+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:10.639+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:41:11.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:41:11.470+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:11.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:41:11.504+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:11.504+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:41:11.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.895 seconds
[2025-10-08T12:41:41.616+0000] {processor.py:157} INFO - Started process (PID=6681) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:41:41.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:41:41.618+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:41.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:41:42.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:41:42.191+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:42.190+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:41:42.217+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:41:42.217+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:41:42.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.625 seconds
[2025-10-08T12:42:12.429+0000] {processor.py:157} INFO - Started process (PID=6986) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:42:12.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:42:12.431+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:12.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:42:13.053+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:42:13.077+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:13.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:42:13.109+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:13.109+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:42:13.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.711 seconds
[2025-10-08T12:42:43.822+0000] {processor.py:157} INFO - Started process (PID=7295) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:42:43.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:42:43.825+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:42:43.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:42:44.454+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:42:45.422+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:43:15.492+0000] {processor.py:157} INFO - Started process (PID=7617) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:43:15.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:43:15.494+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:15.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:43:16.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:43:16.098+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:16.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:43:16.126+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:16.126+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:43:16.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.658 seconds
[2025-10-08T12:43:46.811+0000] {processor.py:157} INFO - Started process (PID=7917) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:43:46.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:43:46.816+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:46.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:43:47.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:43:48.682+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:48.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:43:48.925+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:43:48.924+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:43:48.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.181 seconds
[2025-10-08T12:44:19.738+0000] {processor.py:157} INFO - Started process (PID=8234) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:44:19.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:44:19.740+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:19.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:44:20.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:44:20.890+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:20.888+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:44:20.930+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:20.930+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:44:20.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.227 seconds
[2025-10-08T12:44:51.660+0000] {processor.py:157} INFO - Started process (PID=8548) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:44:51.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:44:51.662+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:51.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:44:52.320+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:44:52.345+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:52.344+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:44:52.374+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:44:52.374+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:44:52.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.742 seconds
[2025-10-08T12:45:22.461+0000] {processor.py:157} INFO - Started process (PID=8855) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:45:22.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:45:22.463+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:22.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:45:23.032+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:45:24.353+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:24.352+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:45:24.381+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:24.381+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:45:24.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.944 seconds
[2025-10-08T12:45:54.614+0000] {processor.py:157} INFO - Started process (PID=9172) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:45:54.616+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:45:54.619+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:54.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:45:55.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:45:55.755+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:55.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:45:55.798+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:45:55.798+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:45:55.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.221 seconds
[2025-10-08T12:46:26.519+0000] {processor.py:157} INFO - Started process (PID=9484) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:46:26.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:46:26.522+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:26.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:46:26.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:46:27.015+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:27.015+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:46:27.046+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:27.046+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:46:27.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.559 seconds
[2025-10-08T12:46:57.477+0000] {processor.py:157} INFO - Started process (PID=9791) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:46:57.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:46:57.478+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:57.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:46:57.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:46:58.980+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:58.979+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:46:59.013+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:46:59.013+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:46:59.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.566 seconds
[2025-10-08T12:47:29.614+0000] {processor.py:157} INFO - Started process (PID=10103) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:47:29.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:47:29.617+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:29.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:47:30.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:47:30.306+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:30.305+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:47:30.341+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:47:30.341+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:47:30.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.765 seconds
[2025-10-08T12:48:00.559+0000] {processor.py:157} INFO - Started process (PID=10410) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:48:00.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:48:00.561+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:00.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:48:01.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:48:01.038+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:01.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:48:01.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:01.071+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:48:01.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.537 seconds
[2025-10-08T12:48:31.438+0000] {processor.py:157} INFO - Started process (PID=10712) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:48:31.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:48:31.443+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:31.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:48:32.133+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:48:32.192+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:32.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:48:32.261+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:48:32.261+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:48:32.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.864 seconds
[2025-10-08T12:49:03.020+0000] {processor.py:157} INFO - Started process (PID=11024) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:49:03.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:49:03.022+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:03.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:49:03.477+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:49:04.622+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:04.621+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:49:04.656+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:04.656+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:49:04.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.664 seconds
[2025-10-08T12:49:35.255+0000] {processor.py:157} INFO - Started process (PID=11351) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:49:35.256+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:49:35.258+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:35.257+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:49:36.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:49:36.843+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:36.842+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:49:36.879+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:49:36.879+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:49:36.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.653 seconds
[2025-10-08T12:50:07.095+0000] {processor.py:157} INFO - Started process (PID=11681) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:50:07.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:50:07.098+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:07.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:50:07.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:50:08.038+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:08.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:50:08.070+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:08.069+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:50:08.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.005 seconds
[2025-10-08T12:50:38.657+0000] {processor.py:157} INFO - Started process (PID=11990) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:50:38.658+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:50:38.660+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:38.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:50:39.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:50:39.112+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:39.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:50:39.147+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:50:39.147+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:50:39.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.518 seconds
[2025-10-08T12:51:09.387+0000] {processor.py:157} INFO - Started process (PID=12297) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:51:09.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:51:09.389+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:09.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:51:09.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:51:10.671+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:10.670+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:51:10.716+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:10.715+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:51:10.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.366 seconds
[2025-10-08T12:51:41.269+0000] {processor.py:157} INFO - Started process (PID=12618) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:51:41.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:51:41.270+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:41.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:51:41.720+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:51:42.045+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:42.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:51:42.081+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:51:42.081+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:51:42.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.842 seconds
[2025-10-08T12:52:12.802+0000] {processor.py:157} INFO - Started process (PID=12925) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:52:12.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:52:12.804+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:12.804+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:52:13.249+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:52:13.931+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T12:52:44.618+0000] {processor.py:157} INFO - Started process (PID=13232) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:52:44.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:52:44.620+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:44.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:52:45.107+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:52:45.137+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:45.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:52:45.170+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:52:45.169+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:52:45.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.596 seconds
[2025-10-08T12:53:15.644+0000] {processor.py:157} INFO - Started process (PID=13539) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:53:15.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:53:15.653+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:15.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:53:16.554+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:53:16.846+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:16.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:53:17.003+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:17.003+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:53:17.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.392 seconds
[2025-10-08T12:53:47.904+0000] {processor.py:157} INFO - Started process (PID=13857) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:53:47.905+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:53:47.906+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:47.906+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:53:48.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:53:48.597+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:48.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:53:48.760+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:53:48.760+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:53:48.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.884 seconds
[2025-10-08T12:54:18.852+0000] {processor.py:157} INFO - Started process (PID=14153) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:54:18.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:54:18.856+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:18.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:54:19.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:54:19.753+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:19.752+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:54:19.784+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:19.784+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:54:19.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.959 seconds
[2025-10-08T12:54:50.141+0000] {processor.py:157} INFO - Started process (PID=14460) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:54:50.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:54:50.144+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:50.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:54:50.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:54:50.799+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:50.799+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:54:50.828+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:54:50.828+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:54:50.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.715 seconds
[2025-10-08T12:55:21.467+0000] {processor.py:157} INFO - Started process (PID=14767) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:55:21.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:55:21.471+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:21.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:55:22.133+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:55:22.653+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:22.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:55:22.685+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:22.685+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:55:22.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.246 seconds
[2025-10-08T12:55:53.991+0000] {processor.py:157} INFO - Started process (PID=15102) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:55:53.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:55:53.993+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:53.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:55:54.612+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:55:54.644+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:54.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:55:54.679+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:55:54.678+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:55:54.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.722 seconds
[2025-10-08T12:56:24.875+0000] {processor.py:157} INFO - Started process (PID=15421) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:56:24.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:56:24.880+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:24.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:56:25.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:56:25.609+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:25.608+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:56:25.657+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:25.656+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:56:25.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.817 seconds
[2025-10-08T12:56:55.774+0000] {processor.py:157} INFO - Started process (PID=15733) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:56:55.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:56:55.776+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:55.776+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:56:56.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:56:56.363+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:56.363+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:56:56.391+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:56:56.391+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:56:56.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.646 seconds
[2025-10-08T12:57:26.523+0000] {processor.py:157} INFO - Started process (PID=16040) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:57:26.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:57:26.525+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:26.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:57:27.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:57:27.517+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:27.517+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:57:27.547+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:27.547+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:57:27.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.050 seconds
[2025-10-08T12:57:57.755+0000] {processor.py:157} INFO - Started process (PID=16347) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:57:57.756+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:57:57.757+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:57.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:57:58.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:57:58.882+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:58.882+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:57:58.912+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:57:58.912+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:57:58.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.185 seconds
[2025-10-08T12:58:29.560+0000] {processor.py:157} INFO - Started process (PID=16657) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:58:29.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:58:29.562+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:29.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:58:30.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:58:30.167+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:30.167+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:58:30.204+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:58:30.204+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:58:30.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.673 seconds
[2025-10-08T12:59:00.375+0000] {processor.py:157} INFO - Started process (PID=16953) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:59:00.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:59:00.380+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:00.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:59:01.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:59:01.099+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:01.099+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:59:01.127+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:01.127+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:59:01.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.778 seconds
[2025-10-08T12:59:31.331+0000] {processor.py:157} INFO - Started process (PID=17260) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:59:31.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T12:59:31.333+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:31.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:59:31.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T12:59:31.975+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:31.974+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T12:59:32.017+0000] {logging_mixin.py:149} INFO - [2025-10-08T12:59:32.017+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T12:59:32.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.720 seconds
[2025-10-08T13:00:02.714+0000] {processor.py:157} INFO - Started process (PID=17567) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:00:02.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:00:02.717+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:02.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:00:03.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:00:03.588+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:03.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:00:03.625+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:03.624+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:00:03.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.936 seconds
[2025-10-08T13:00:34.425+0000] {processor.py:157} INFO - Started process (PID=17879) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:00:34.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:00:34.427+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:34.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:00:35.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:00:35.491+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:35.491+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:00:35.522+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:00:35.522+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:00:35.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.123 seconds
[2025-10-08T13:01:05.980+0000] {processor.py:157} INFO - Started process (PID=18186) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:05.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:01:05.983+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:05.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:06.584+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:06.612+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:06.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:06.641+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:06.641+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:01:06.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.689 seconds
[2025-10-08T13:01:16.421+0000] {processor.py:157} INFO - Started process (PID=18365) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:16.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:01:16.422+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:16.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:17.021+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:17.050+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.049+0000] {taskinstance.py:1826} ERROR - {'DAG Id': 'logistics_data_etl_pipeline', 'Task Id': 'create_schema', 'Run Id': 'manual__2025-10-08T12:51:08.851297+00:00', 'Hostname': '6f1bff8c6eb0'}
[2025-10-08T13:01:17.068+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.068+0000] {taskinstance.py:1350} INFO - Marking task as UP_FOR_RETRY. dag_id=logistics_data_etl_pipeline, task_id=create_schema, execution_date=20251008T125108, start_date=20251008T125616, end_date=20251008T130117
[2025-10-08T13:01:17.084+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.084+0000] {configuration.py:674} WARNING - section/key [smtp/smtp_user] not found in config
[2025-10-08T13:01:17.085+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.084+0000] {email.py:268} INFO - Email alerting: attempt 1
[2025-10-08T13:01:17.088+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.088+0000] {configuration.py:674} WARNING - section/key [smtp/smtp_user] not found in config
[2025-10-08T13:01:17.089+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.088+0000] {email.py:268} INFO - Email alerting: attempt 1
[2025-10-08T13:01:17.091+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.089+0000] {taskinstance.py:1889} ERROR - Failed to send email to: random@gmail.com
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2295, in email_alert
    send_email(task.email, subject, html_content)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 91, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 152, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 270, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 317, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1887, in handle_failure
    self.email_alert(error, task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2297, in email_alert
    send_email(task.email, subject, html_content_err)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 91, in send_email
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 152, in send_email_smtp
    send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 270, in send_mime_email
    smtp_conn = _get_smtp_connection(smtp_host, smtp_port, smtp_timeout, smtp_ssl)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/email.py", line 317, in _get_smtp_connection
    else smtplib.SMTP(host=host, port=port, timeout=timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 251, in __init__
    (code, msg) = self.connect(host, port)
  File "/usr/local/lib/python3.7/smtplib.py", line 336, in connect
    self.sock = self._get_socket(host, port, self.timeout)
  File "/usr/local/lib/python3.7/smtplib.py", line 307, in _get_socket
    self.source_address)
  File "/usr/local/lib/python3.7/socket.py", line 728, in create_connection
    raise err
  File "/usr/local/lib/python3.7/socket.py", line 716, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-10-08T13:01:17.108+0000] {processor.py:787} INFO - Executed failure callback for <TaskInstance: logistics_data_etl_pipeline.create_schema manual__2025-10-08T12:51:08.851297+00:00 [up_for_retry]> in state up_for_retry
[2025-10-08T13:01:17.131+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:17.168+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:17.168+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:01:17.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.775 seconds
[2025-10-08T13:01:48.490+0000] {processor.py:157} INFO - Started process (PID=18672) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:48.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:01:48.493+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:48.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:49.126+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:01:49.155+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:49.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:01:49.192+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:01:49.192+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:01:49.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.733 seconds
[2025-10-08T13:02:19.462+0000] {processor.py:157} INFO - Started process (PID=18987) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:02:19.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:02:19.463+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:19.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:02:20.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:02:20.402+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:20.402+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:02:20.432+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:20.432+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:02:20.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.996 seconds
[2025-10-08T13:02:50.591+0000] {processor.py:157} INFO - Started process (PID=19291) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:02:50.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:02:50.595+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:50.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:02:51.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:02:51.192+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:51.191+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:02:51.220+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:02:51.220+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:02:51.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.653 seconds
[2025-10-08T13:04:36.456+0000] {processor.py:157} INFO - Started process (PID=177) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:04:36.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:04:36.461+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:36.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:04:37.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:04:37.543+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.542+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:logistics_data_etl_pipeline_V1
[2025-10-08T13:04:37.562+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.561+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:logistics_data_etl_pipeline_V1
[2025-10-08T13:04:37.578+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.578+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:logistics_data_etl_pipeline_V1
[2025-10-08T13:04:37.608+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:04:37.630+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.630+0000] {dag.py:2747} INFO - Creating ORM DAG for logistics_data_etl_pipeline_V1
[2025-10-08T13:04:37.652+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:04:37.652+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:04:37.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.245 seconds
[2025-10-08T13:05:07.776+0000] {processor.py:157} INFO - Started process (PID=485) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:05:07.780+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:05:07.783+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:07.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:05:08.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:05:08.478+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:08.477+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:05:08.506+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:08.506+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:05:08.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.762 seconds
[2025-10-08T13:05:39.050+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:05:39.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:05:39.052+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:39.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:05:39.732+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:05:39.884+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:39.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:05:39.922+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:05:39.921+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:05:39.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.898 seconds
[2025-10-08T13:06:10.126+0000] {processor.py:157} INFO - Started process (PID=1106) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:06:10.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:06:10.129+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:10.129+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:06:10.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:06:11.260+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:11.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:06:11.297+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:11.297+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:06:11.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.206 seconds
[2025-10-08T13:06:41.436+0000] {processor.py:157} INFO - Started process (PID=1423) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:06:41.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:06:41.441+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:41.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:06:42.186+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:06:42.239+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:42.238+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:06:42.295+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:06:42.294+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:06:42.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.917 seconds
[2025-10-08T13:07:12.676+0000] {processor.py:157} INFO - Started process (PID=1724) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:07:12.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:07:12.679+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:12.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:07:13.306+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:07:13.338+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:13.338+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:07:13.380+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:13.379+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:07:13.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.738 seconds
[2025-10-08T13:07:50.055+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:07:50.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:07:50.058+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:50.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:07:51.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:07:51.334+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:51.334+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:07:51.381+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:07:51.380+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:07:51.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.369 seconds
[2025-10-08T13:08:21.769+0000] {processor.py:157} INFO - Started process (PID=485) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:08:21.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:08:21.772+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:21.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:08:22.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:08:22.570+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:22.570+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:08:22.606+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:22.606+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:08:22.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.870 seconds
[2025-10-08T13:08:52.901+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:08:52.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:08:52.904+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:08:52.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:08:53.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:08:54.882+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:09:25.148+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:09:25.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:09:25.151+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:25.151+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:09:26.009+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:09:26.140+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:26.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:09:26.202+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:26.202+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:09:26.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.100 seconds
[2025-10-08T13:09:56.348+0000] {processor.py:157} INFO - Started process (PID=1419) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:09:56.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:09:56.351+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:56.351+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:09:56.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:09:57.026+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:57.026+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:09:57.063+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:09:57.063+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:09:57.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.741 seconds
[2025-10-08T13:10:27.213+0000] {processor.py:157} INFO - Started process (PID=1726) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:10:27.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:10:27.216+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:27.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:10:27.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:10:28.581+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:10:58.628+0000] {processor.py:157} INFO - Started process (PID=2036) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:10:58.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:10:58.630+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:58.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:10:59.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:10:59.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:59.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:10:59.103+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:10:59.103+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:10:59.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.502 seconds
[2025-10-08T13:11:29.539+0000] {processor.py:157} INFO - Started process (PID=2345) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:11:29.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:11:29.541+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:29.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:11:29.955+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:11:29.983+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:29.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:11:30.014+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:11:30.014+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:11:30.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.505 seconds
[2025-10-08T13:17:29.757+0000] {processor.py:157} INFO - Started process (PID=2658) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:17:29.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:17:29.762+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:29.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:17:31.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:17:32.336+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:32.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:17:32.422+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:17:32.421+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:17:32.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 2.725 seconds
[2025-10-08T13:18:02.804+0000] {processor.py:157} INFO - Started process (PID=2965) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:18:02.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:18:02.806+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:02.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:18:03.264+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:18:03.854+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:18:34.348+0000] {processor.py:157} INFO - Started process (PID=3272) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:18:34.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:18:34.351+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:34.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:18:34.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:18:34.863+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:34.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:18:34.901+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:18:34.901+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:18:34.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.583 seconds
[2025-10-08T13:19:05.245+0000] {processor.py:157} INFO - Started process (PID=3588) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:19:05.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:19:05.248+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:05.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:19:05.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:19:05.732+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:05.731+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:19:05.874+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:05.874+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:19:05.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.658 seconds
[2025-10-08T13:19:35.933+0000] {processor.py:157} INFO - Started process (PID=3895) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:19:35.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:19:35.934+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:35.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:19:36.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:19:36.491+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:36.490+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:19:36.528+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:19:36.528+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:19:36.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.627 seconds
[2025-10-08T13:20:06.854+0000] {processor.py:157} INFO - Started process (PID=4202) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:20:06.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:20:06.856+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:06.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:20:07.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:20:08.360+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:20:39.031+0000] {processor.py:157} INFO - Started process (PID=4514) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:20:39.033+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:20:39.034+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:39.034+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:20:39.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:20:39.809+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:39.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:20:39.838+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:20:39.838+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:20:39.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.833 seconds
[2025-10-08T13:21:10.038+0000] {processor.py:157} INFO - Started process (PID=4821) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:21:10.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:21:10.041+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:10.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:21:10.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:21:10.677+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:10.677+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:21:10.705+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:10.705+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:21:10.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.694 seconds
[2025-10-08T13:21:41.055+0000] {processor.py:157} INFO - Started process (PID=5126) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:21:41.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:21:41.057+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:41.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:21:41.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:21:41.658+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:41.657+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:21:41.686+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:21:41.686+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:21:41.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.655 seconds
[2025-10-08T13:22:11.920+0000] {processor.py:157} INFO - Started process (PID=5430) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:22:11.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:22:11.923+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:11.923+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:22:12.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:22:12.489+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:12.488+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:22:12.518+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:12.517+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:22:12.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.622 seconds
[2025-10-08T13:22:42.644+0000] {processor.py:157} INFO - Started process (PID=5737) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:22:42.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:22:42.646+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:42.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:22:43.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:22:43.202+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:43.201+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:22:43.228+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:22:43.228+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:22:43.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.608 seconds
[2025-10-08T13:23:13.438+0000] {processor.py:157} INFO - Started process (PID=6044) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:23:13.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:23:13.441+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:13.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:23:13.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:23:14.707+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:23:44.976+0000] {processor.py:157} INFO - Started process (PID=6356) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:23:44.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:23:44.978+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:23:44.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:23:45.510+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:23:45.602+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:24:16.086+0000] {processor.py:157} INFO - Started process (PID=6672) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:24:16.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:24:16.088+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:16.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:24:16.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:24:17.097+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:17.097+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:24:17.128+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:17.128+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:24:17.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.067 seconds
[2025-10-08T13:24:47.896+0000] {processor.py:157} INFO - Started process (PID=6984) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:24:47.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:24:47.898+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:47.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:24:48.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:24:48.469+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:48.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:24:48.504+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:24:48.504+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:24:48.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.642 seconds
[2025-10-08T13:25:18.751+0000] {processor.py:157} INFO - Started process (PID=7291) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:25:18.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:25:18.753+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:18.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:25:19.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:25:20.107+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:20.107+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:25:20.135+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:20.135+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:25:20.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.411 seconds
[2025-10-08T13:25:50.335+0000] {processor.py:157} INFO - Started process (PID=7598) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:25:50.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:25:50.337+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:50.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:25:50.914+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:25:51.093+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:51.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:25:51.123+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:25:51.123+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:25:51.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.813 seconds
[2025-10-08T13:26:21.206+0000] {processor.py:157} INFO - Started process (PID=7905) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:26:21.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:26:21.209+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:21.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:26:21.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:26:21.864+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:21.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:26:21.894+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:21.894+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:26:21.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.715 seconds
[2025-10-08T13:26:52.301+0000] {processor.py:157} INFO - Started process (PID=8212) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:26:52.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:26:52.303+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:52.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:26:52.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:26:52.863+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:52.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:26:52.898+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:26:52.898+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:26:52.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.625 seconds
[2025-10-08T13:27:23.552+0000] {processor.py:157} INFO - Started process (PID=8519) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:27:23.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:27:23.554+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:23.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:27:24.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:27:24.106+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:24.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:27:24.132+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:24.132+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:27:24.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.605 seconds
[2025-10-08T13:27:54.612+0000] {processor.py:157} INFO - Started process (PID=8826) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:27:54.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:27:54.614+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:54.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:27:55.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:27:55.241+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:55.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:27:55.269+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:27:55.269+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:27:55.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.680 seconds
[2025-10-08T13:28:25.459+0000] {processor.py:157} INFO - Started process (PID=9133) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:28:25.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:28:25.461+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:25.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:28:26.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:28:26.071+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:26.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:28:26.102+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:26.101+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:28:26.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.667 seconds
[2025-10-08T13:28:56.373+0000] {processor.py:157} INFO - Started process (PID=9440) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:28:56.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:28:56.375+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:56.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:28:56.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:28:56.923+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:56.922+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:28:56.949+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:28:56.949+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:28:56.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.601 seconds
[2025-10-08T13:29:27.645+0000] {processor.py:157} INFO - Started process (PID=9756) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:29:27.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:29:27.647+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:27.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:29:28.186+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:29:28.208+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:28.207+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:29:28.235+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:28.235+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:29:28.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.611 seconds
[2025-10-08T13:29:58.450+0000] {processor.py:157} INFO - Started process (PID=10060) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:29:58.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:29:58.455+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:58.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:29:59.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:29:59.086+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:59.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:29:59.116+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:29:59.115+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:29:59.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.689 seconds
[2025-10-08T13:30:29.223+0000] {processor.py:157} INFO - Started process (PID=10372) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:30:29.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:30:29.225+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:29.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:30:29.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:30:30.372+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:30.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:30:30.399+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:30:30.399+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:30:30.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.202 seconds
[2025-10-08T13:31:00.675+0000] {processor.py:157} INFO - Started process (PID=10675) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:31:00.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:31:00.677+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:00.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:31:01.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:31:01.145+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:01.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:31:01.177+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:01.177+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:31:01.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.529 seconds
[2025-10-08T13:31:31.569+0000] {processor.py:157} INFO - Started process (PID=10982) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:31:31.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:31:31.575+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:31.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:31:32.013+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:31:32.059+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:32.058+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:31:32.121+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:31:32.120+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:31:32.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.581 seconds
[2025-10-08T13:32:02.555+0000] {processor.py:157} INFO - Started process (PID=11298) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:32:02.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:32:02.558+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:02.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:32:02.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:32:03.262+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:03.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:32:03.295+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:03.295+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:32:03.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.769 seconds
[2025-10-08T13:32:33.928+0000] {processor.py:157} INFO - Started process (PID=11605) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:32:33.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:32:33.930+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:33.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:32:34.374+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:32:34.408+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:34.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:32:34.501+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:32:34.501+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:32:34.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.601 seconds
[2025-10-08T13:33:04.797+0000] {processor.py:157} INFO - Started process (PID=11920) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:33:04.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:33:04.798+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:04.798+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:33:05.218+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:33:06.103+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:06.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:33:06.133+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:06.133+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:33:06.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.365 seconds
[2025-10-08T13:33:36.704+0000] {processor.py:157} INFO - Started process (PID=12234) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:33:36.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:33:36.706+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:36.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:33:37.153+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:33:37.198+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:37.197+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:33:37.227+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:33:37.227+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:33:37.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.551 seconds
[2025-10-08T13:34:07.292+0000] {processor.py:157} INFO - Started process (PID=12541) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:34:07.293+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:34:07.294+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:07.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:34:07.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:34:07.739+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:07.739+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:34:07.770+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:07.770+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:34:07.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.503 seconds
[2025-10-08T13:34:38.374+0000] {processor.py:157} INFO - Started process (PID=12848) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:34:38.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:34:38.376+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:38.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:34:38.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:34:38.850+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:38.849+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:34:38.904+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:34:38.904+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:34:38.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.571 seconds
[2025-10-08T13:35:09.011+0000] {processor.py:157} INFO - Started process (PID=13155) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:35:09.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:35:09.013+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:09.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:35:09.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:35:09.519+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:09.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:35:09.550+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:09.550+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:35:09.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.672 seconds
[2025-10-08T13:35:39.792+0000] {processor.py:157} INFO - Started process (PID=13462) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:35:39.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:35:39.794+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:39.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:35:40.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:35:40.709+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:40.601+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:35:40.741+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:35:40.740+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:35:40.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.972 seconds
[2025-10-08T13:44:14.804+0000] {processor.py:157} INFO - Started process (PID=13746) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:44:14.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:44:14.815+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:14.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:44:16.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:44:17.092+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:44:47.971+0000] {processor.py:157} INFO - Started process (PID=14070) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:44:47.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:44:47.974+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:47.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:44:48.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:44:48.763+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:48.763+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:44:48.804+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:44:48.804+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:44:48.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.867 seconds
[2025-10-08T13:45:19.070+0000] {processor.py:157} INFO - Started process (PID=14377) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:45:19.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:45:19.072+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:19.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:45:19.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:45:20.078+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:20.078+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:45:20.108+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:20.108+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:45:20.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.078 seconds
[2025-10-08T13:45:50.311+0000] {processor.py:157} INFO - Started process (PID=14684) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:45:50.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:45:50.314+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:50.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:45:50.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:45:50.968+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:50.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:45:50.994+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:45:50.994+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:45:51.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.708 seconds
[2025-10-08T13:46:21.402+0000] {processor.py:157} INFO - Started process (PID=14991) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:46:21.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:46:21.404+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:21.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:46:21.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:46:22.897+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:22.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:46:22.927+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:22.926+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:46:22.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.557 seconds
[2025-10-08T13:46:53.033+0000] {processor.py:157} INFO - Started process (PID=15309) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:46:53.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:46:53.035+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:46:53.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:46:53.731+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.731+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:46:53.759+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:46:53.758+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:46:53.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.752 seconds
[2025-10-08T13:47:24.065+0000] {processor.py:157} INFO - Started process (PID=15616) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:47:24.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:47:24.068+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.068+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:47:24.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:47:24.920+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.920+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:47:24.947+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:24.947+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:47:24.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.909 seconds
[2025-10-08T13:47:55.134+0000] {processor.py:157} INFO - Started process (PID=15925) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:47:55.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:47:55.136+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:47:55.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:47:55.745+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.744+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:47:55.773+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:47:55.772+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:47:55.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.662 seconds
[2025-10-08T13:48:26.110+0000] {processor.py:157} INFO - Started process (PID=16232) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:48:26.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:48:26.112+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:26.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:48:26.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:48:26.688+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:26.687+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:48:26.714+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:26.714+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:48:26.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.627 seconds
[2025-10-08T13:48:56.965+0000] {processor.py:157} INFO - Started process (PID=16539) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:48:56.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:48:56.966+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:48:56.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:48:57.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:48:58.736+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:49:29.659+0000] {processor.py:157} INFO - Started process (PID=16872) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:49:29.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:49:29.661+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:29.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:49:30.179+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:49:30.314+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:30.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:49:30.341+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:49:30.340+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:49:30.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.704 seconds
[2025-10-08T13:50:00.764+0000] {processor.py:157} INFO - Started process (PID=17168) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:50:00.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:50:00.767+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:00.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:50:01.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:50:02.426+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:50:32.904+0000] {processor.py:157} INFO - Started process (PID=17501) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:50:32.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:50:32.907+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:32.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:50:33.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:50:34.650+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:34.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:50:34.678+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:50:34.678+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:50:34.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.802 seconds
[2025-10-08T13:51:05.427+0000] {processor.py:157} INFO - Started process (PID=17814) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:51:05.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:51:05.430+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:05.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:51:05.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:51:05.998+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:05.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:51:06.027+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:06.027+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:51:06.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.628 seconds
[2025-10-08T13:51:36.338+0000] {processor.py:157} INFO - Started process (PID=18121) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:51:36.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:51:36.341+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:36.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:51:36.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:51:36.950+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:36.949+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:51:36.978+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:51:36.978+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:51:36.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.664 seconds
[2025-10-08T13:52:07.256+0000] {processor.py:157} INFO - Started process (PID=18428) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:52:07.257+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:52:07.258+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:07.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:52:07.788+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:52:08.122+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:08.122+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:52:08.151+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:08.151+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:52:08.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.921 seconds
[2025-10-08T13:52:38.778+0000] {processor.py:157} INFO - Started process (PID=18735) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:52:38.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:52:38.780+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:38.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:52:39.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:52:40.248+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:40.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:52:40.279+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:52:40.279+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:52:40.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.525 seconds
[2025-10-08T13:53:10.410+0000] {processor.py:157} INFO - Started process (PID=19062) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:53:10.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:53:10.412+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:10.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:53:10.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:53:11.164+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:11.164+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:53:11.198+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:11.197+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:53:11.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.815 seconds
[2025-10-08T13:53:41.697+0000] {processor.py:157} INFO - Started process (PID=19369) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:53:41.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:53:41.699+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:53:41.699+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:53:42.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:53:43.535+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:54:13.631+0000] {processor.py:157} INFO - Started process (PID=19686) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:54:13.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:54:13.634+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:13.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:54:14.257+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:54:14.292+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:14.291+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:54:14.328+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:14.328+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:54:14.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.730 seconds
[2025-10-08T13:54:45.209+0000] {processor.py:157} INFO - Started process (PID=19994) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:54:45.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:54:45.212+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:45.211+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:54:45.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:54:45.661+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:45.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:54:45.691+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:54:45.690+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:54:45.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.507 seconds
[2025-10-08T13:55:16.013+0000] {processor.py:157} INFO - Started process (PID=20290) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:55:16.015+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:55:16.016+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:16.016+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:55:16.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:55:17.431+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:17.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:55:17.463+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:17.463+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:55:17.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.475 seconds
[2025-10-08T13:55:47.964+0000] {processor.py:157} INFO - Started process (PID=20622) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:55:47.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:55:47.966+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:47.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:55:48.370+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:55:48.842+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:48.842+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:55:48.872+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:55:48.872+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:55:48.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.934 seconds
[2025-10-08T13:56:18.956+0000] {processor.py:157} INFO - Started process (PID=20916) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:56:18.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:56:18.959+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:18.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:56:19.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:56:19.415+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:19.414+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:56:19.444+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:19.444+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:56:19.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.514 seconds
[2025-10-08T13:56:49.777+0000] {processor.py:157} INFO - Started process (PID=21223) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:56:49.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:56:49.779+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:49.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:56:50.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:56:50.924+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:50.924+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:56:50.957+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:56:50.957+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:56:50.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.207 seconds
[2025-10-08T13:57:21.977+0000] {processor.py:157} INFO - Started process (PID=21546) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:57:21.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:57:21.980+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:21.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:57:22.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:57:22.816+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:57:52.902+0000] {processor.py:157} INFO - Started process (PID=21855) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:57:52.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:57:52.904+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:52.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:57:53.322+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:57:53.769+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:53.768+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:57:53.802+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:57:53.802+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:57:53.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.928 seconds
[2025-10-08T13:58:24.209+0000] {processor.py:157} INFO - Started process (PID=22170) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:58:24.210+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:58:24.211+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:24.211+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:58:24.748+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:58:25.731+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:58:56.626+0000] {processor.py:157} INFO - Started process (PID=22507) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:58:56.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:58:56.627+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:58:56.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:58:57.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:58:58.150+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T13:59:28.799+0000] {processor.py:157} INFO - Started process (PID=22819) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:59:28.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:59:28.801+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:28.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:59:29.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:59:29.482+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:29.482+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T13:59:29.508+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:29.508+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T13:59:29.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.734 seconds
[2025-10-08T13:59:59.910+0000] {processor.py:157} INFO - Started process (PID=23123) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T13:59:59.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T13:59:59.913+0000] {logging_mixin.py:149} INFO - [2025-10-08T13:59:59.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:00:00.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:00:01.188+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 162, in _handle_dag_file_processing
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    pickle_dags=pickle_dags,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 890, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 659, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 671, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 641, in _serialize_dag_capturing_errors
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 73, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/serialized_dag.py", line 149, in write_dag
    (timezone.utcnow() - timedelta(seconds=min_update_interval)) < cls.last_updated,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2893, in scalar
    ret = self.one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2870, in one
    return self._iter().one()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/query.py", line 2919, in _iter
    execution_options={"_sa_orm_load_options": self.load_options},
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (172.22.0.7), port 5432 failed: FATAL:  password authentication failed for user "airflow"

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-08T14:00:31.733+0000] {processor.py:157} INFO - Started process (PID=23430) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:00:31.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:00:31.735+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:31.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:00:32.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:00:32.720+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:32.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:00:32.748+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:00:32.747+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:00:32.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.038 seconds
[2025-10-08T14:01:03.094+0000] {processor.py:157} INFO - Started process (PID=23752) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:01:03.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:01:03.096+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:03.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:01:03.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:01:04.492+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:04.491+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:01:04.526+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:04.525+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:01:04.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.456 seconds
[2025-10-08T14:01:34.680+0000] {processor.py:157} INFO - Started process (PID=24069) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:01:34.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:01:34.682+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:34.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:01:35.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:01:35.234+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:35.233+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:01:35.260+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:01:35.260+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:01:35.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.604 seconds
[2025-10-08T14:02:05.411+0000] {processor.py:157} INFO - Started process (PID=24374) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:02:05.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:02:05.413+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:05.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:02:05.949+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:02:05.970+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:05.970+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:02:05.997+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:05.997+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:02:06.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.610 seconds
[2025-10-08T14:02:36.842+0000] {processor.py:157} INFO - Started process (PID=24678) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:02:36.844+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:02:36.845+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:36.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:02:37.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:02:37.837+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:37.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:02:37.865+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:02:37.865+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:02:37.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.047 seconds
[2025-10-08T14:03:08.524+0000] {processor.py:157} INFO - Started process (PID=24995) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:03:08.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:03:08.526+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:08.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:03:09.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:03:09.070+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:09.069+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:03:09.100+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:09.100+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:03:09.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.600 seconds
[2025-10-08T14:03:39.869+0000] {processor.py:157} INFO - Started process (PID=25310) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:03:39.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:03:39.871+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:39.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:03:40.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:03:40.805+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:40.805+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:03:40.835+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:03:40.835+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:03:40.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.989 seconds
[2025-10-08T14:04:11.544+0000] {processor.py:157} INFO - Started process (PID=25624) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:04:11.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:04:11.546+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:11.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:04:12.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:04:12.096+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:12.096+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:04:12.125+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:12.125+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:04:12.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.606 seconds
[2025-10-08T14:04:42.213+0000] {processor.py:157} INFO - Started process (PID=25931) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:04:42.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:04:42.215+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:42.215+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:04:42.726+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:04:43.951+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:43.951+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:04:43.979+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:04:43.979+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:04:43.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.789 seconds
[2025-10-08T14:14:55.309+0000] {processor.py:157} INFO - Started process (PID=26171) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:14:55.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:14:55.325+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:55.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:14:56.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:14:57.051+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:57.049+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:14:57.151+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:14:57.151+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:14:57.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 1.884 seconds
[2025-10-08T14:15:27.388+0000] {processor.py:157} INFO - Started process (PID=26478) to work on /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:15:27.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/mock_logistics_dag.py for tasks to queue
[2025-10-08T14:15:27.390+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:27.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:15:27.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['logistics_data_etl_pipeline_V1']) retrieved from /opt/airflow/dags/mock_logistics_dag.py
[2025-10-08T14:15:27.963+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:27.962+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2025-10-08T14:15:27.992+0000] {logging_mixin.py:149} INFO - [2025-10-08T14:15:27.992+0000] {dag.py:3490} INFO - Setting next_dagrun for logistics_data_etl_pipeline_V1 to 2025-10-08T09:00:00+00:00, run_after=2025-10-09T09:00:00+00:00
[2025-10-08T14:15:28.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/mock_logistics_dag.py took 0.637 seconds
